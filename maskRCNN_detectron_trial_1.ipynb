{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use yolov8 env to run this code\n"
     ]
    }
   ],
   "source": [
    "print(\"use yolov8 env to run this code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3127,
     "status": "ok",
     "timestamp": 1740392499201,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "CNptMke9OoZe",
    "outputId": "b3fabf37-4738-4df3-af9d-7fd3b1860a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "print(torch.__version__)  # Should match Colab's default (e.g., 2.x)\n",
    "print(detectron2.__version__)  # Should print a version number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1494,
     "status": "ok",
     "timestamp": 1740392500694,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "LNnbO8EcSkJr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer, HookBase\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.model_zoo import get_config_file, get_checkpoint_url\n",
    "import numpy as np\n",
    "import time\n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1740392500695,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "MQ8AGJf5Sr6B",
    "outputId": "fe6cbcdd-b4b4-4224-ae14-6d40c382f91f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive_folder = \"/home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train\"  # Change as needed\n",
    "os.makedirs(drive_folder, exist_ok=True)\n",
    "\n",
    "print(\"Training started...\")\n",
    "setup_logger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740392500695,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "FRYCW7JGTDe9"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "dataset_folder = \"/home/ai_train/skyhub_project/june/23rd_new_dataset_to_train\"  # Update this if dataset is elsewhere\n",
    "train_json ='/home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/train.json' # os.path.join(dataset_folder, \"train_annotations.json\")\n",
    "val_json ='/home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json'  #os.path.join(dataset_folder, \"val_annotations.json\")\n",
    "train_images = os.path.join(dataset_folder, \"train/images\")\n",
    "val_images = os.path.join(dataset_folder, \"test/images\")\n",
    "output_dir = os.path.join(drive_folder, \"output\")  # Save output to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740392500695,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "xDXdCixhU2Yh"
   },
   "outputs": [],
   "source": [
    "# Register datasets\n",
    "register_coco_instances(\"my_dataset_train\", {}, train_json, train_images)\n",
    "register_coco_instances(\"my_dataset_val\", {}, val_json, val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740392500695,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "jMOq1NHrU7J_"
   },
   "outputs": [],
   "source": [
    "# Get metadata\n",
    "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.model_zoo import get_config_file, get_checkpoint_url\n",
    "import torch\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Load base configuration file from Detectron2 model zoo\n",
    "cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# Register the custom training and validation datasets\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)  # Replace with the name used during dataset registration\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)     # Replace with the name used during dataset registration\n",
    "\n",
    "# Number of data loading workers (increase for better performance if you have more CPU cores)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "# Use pre-trained COCO weights to fine-tune the model\n",
    "cfg.MODEL.WEIGHTS = get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "# Number of images per batch across all GPUs (adjust based on GPU memory; higher = faster)\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "\n",
    "# Base learning rate for the optimizer\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "\n",
    "# Maximum number of training iterations (not epochs); adjust based on dataset size\n",
    "cfg.SOLVER.MAX_ITER = 8900\n",
    "\n",
    "# Learning rate decay steps (iteration numbers where learning rate will be reduced)\n",
    "cfg.SOLVER.STEPS = (6100, 7900)\n",
    "\n",
    "# Number of RoI (Region of Interest) samples per image used for training\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "\n",
    "# Number of object classes (excluding background); set to 1 for a single-class segmentation task\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "\n",
    "# Evaluate model every 500 iterations using the validation set\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "\n",
    "# Directory where output files (models, logs) will be saved\n",
    "cfg.OUTPUT_DIR = output_dir  # Make sure this directory exists or create it using os.makedirs\n",
    "\n",
    "# Specify whether to use GPU ('cuda') or CPU based on availability\n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "# cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "# cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "# cfg.DATALOADER.NUM_WORKERS = 2  # Reduce for Colab\n",
    "# cfg.MODEL.WEIGHTS = get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 2  # Reduce for Colab\n",
    "# cfg.SOLVER.BASE_LR = 0.00025\n",
    "# cfg.SOLVER.MAX_ITER = 2500  # Total iterations for 50 epochs\n",
    "# cfg.SOLVER.STEPS = (1750, 2250)  # Learning rate decay steps at 60% and 80% of the total iterations\n",
    "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "# cfg.TEST.EVAL_PERIOD = 500\n",
    "# cfg.OUTPUT_DIR = output_dir\n",
    "# cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740392500695,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "j5t-4PduVFcx"
   },
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740392500695,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "bWARjDFzVJ8p"
   },
   "outputs": [],
   "source": [
    "# Early Stopping & Model Saving Hook\n",
    "class EarlyStoppingHook(HookBase):\n",
    "    def __init__(self, patience=3):  # Stop if no improvement for 3 evals\n",
    "        self.patience = patience\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def after_step(self):\n",
    "        if self.trainer.iter % cfg.TEST.EVAL_PERIOD == 0:\n",
    "            eval_results = self.trainer.storage.latest()\n",
    "            val_loss = eval_results.get(\"total_loss\", None)\n",
    "\n",
    "            print(\"val_loss\", val_loss)\n",
    "\n",
    "            # Check if val_loss is not None and is a tuple, then access the first element\n",
    "            if val_loss is not None:\n",
    "                val_loss_value = val_loss[0]  # Access the actual validation loss value\n",
    "\n",
    "                # Print the validation loss correctly\n",
    "                print(f\"Iteration {self.trainer.iter}: Validation Loss = {val_loss_value:.4f}\")\n",
    "\n",
    "                model_path = os.path.join(cfg.OUTPUT_DIR, f\"model_iter_{self.trainer.iter}.pth\")\n",
    "                torch.save(self.trainer.model.state_dict(), model_path)\n",
    "                print(f\"Model saved at: {model_path}\")\n",
    "\n",
    "                # Compare and save the best model based on the loss\n",
    "                if val_loss_value < self.best_loss:\n",
    "                    self.best_loss = val_loss_value\n",
    "                    self.counter = 0\n",
    "                    # Save the best model\n",
    "                    torch.save(self.trainer.model.state_dict(), os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\"))\n",
    "                else:\n",
    "                    self.counter += 1\n",
    "                    if self.counter >= self.patience:\n",
    "                        print(\"Early stopping triggered. Stopping training.\")\n",
    "                        self.trainer.iter = cfg.SOLVER.MAX_ITER  # Force training to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740392500695,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "GUMS3bRVVNED"
   },
   "outputs": [],
   "source": [
    "# Custom Trainer\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"eval\")\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.append(EarlyStoppingHook(patience=3))  # Add early stopping & model saving\n",
    "        return hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693937,
     "status": "ok",
     "timestamp": 1740394194626,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "akEXGjMiVQZL",
    "outputId": "0f614dcd-bdae-428a-dfdb-c59ebaf4a43f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/23 12:51:34 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[06/23 12:51:34 d2.data.datasets.coco]: \u001b[0mLoaded 848 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/train.json\n",
      "\u001b[32m[06/23 12:51:34 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 848 images left.\n",
      "\u001b[32m[06/23 12:51:34 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  wrinkle   | 4975         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[06/23 12:51:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[06/23 12:51:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[06/23 12:51:34 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 12:51:34 d2.data.common]: \u001b[0mSerializing 848 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 12:51:34 d2.data.common]: \u001b[0mSerialized dataset takes 22.35 MiB\n",
      "\u001b[32m[06/23 12:51:34 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[06/23 12:51:34 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/23 12:51:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai_train/anaconda3/envs/yolov8/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss (2.468878650572151, 0)\n",
      "Iteration 0: Validation Loss = 2.4689\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_0.pth\n",
      "\u001b[32m[06/23 12:51:41 d2.utils.events]: \u001b[0m eta: 0:42:35  iter: 19  total_loss: 2.524  loss_cls: 0.5866  loss_box_reg: 0.007786  loss_mask: 0.6911  loss_rpn_cls: 1.16  loss_rpn_loc: 0.09155    time: 0.2930  last_time: 0.2857  data_time: 0.0138  last_data_time: 0.0037   lr: 4.9953e-06  max_mem: 2255M\n",
      "\u001b[32m[06/23 12:51:47 d2.utils.events]: \u001b[0m eta: 0:43:43  iter: 39  total_loss: 1.881  loss_cls: 0.4994  loss_box_reg: 0.003791  loss_mask: 0.6893  loss_rpn_cls: 0.6464  loss_rpn_loc: 0.05156    time: 0.2942  last_time: 0.3237  data_time: 0.0036  last_data_time: 0.0036   lr: 9.9903e-06  max_mem: 2333M\n",
      "\u001b[32m[06/23 12:51:53 d2.utils.events]: \u001b[0m eta: 0:43:46  iter: 59  total_loss: 2.068  loss_cls: 0.366  loss_box_reg: 0.01259  loss_mask: 0.6868  loss_rpn_cls: 0.8279  loss_rpn_loc: 0.07914    time: 0.2952  last_time: 0.3153  data_time: 0.0037  last_data_time: 0.0040   lr: 1.4985e-05  max_mem: 2333M\n",
      "\u001b[32m[06/23 12:51:59 d2.utils.events]: \u001b[0m eta: 0:43:46  iter: 79  total_loss: 1.642  loss_cls: 0.2669  loss_box_reg: 0.01185  loss_mask: 0.6788  loss_rpn_cls: 0.5906  loss_rpn_loc: 0.06569    time: 0.2965  last_time: 0.3185  data_time: 0.0035  last_data_time: 0.0034   lr: 1.998e-05  max_mem: 2333M\n",
      "\u001b[32m[06/23 12:52:05 d2.utils.events]: \u001b[0m eta: 0:43:43  iter: 99  total_loss: 1.371  loss_cls: 0.1887  loss_box_reg: 0.01629  loss_mask: 0.6729  loss_rpn_cls: 0.4353  loss_rpn_loc: 0.04504    time: 0.2970  last_time: 0.3317  data_time: 0.0035  last_data_time: 0.0032   lr: 2.4975e-05  max_mem: 2333M\n",
      "\u001b[32m[06/23 12:52:12 d2.utils.events]: \u001b[0m eta: 0:43:52  iter: 119  total_loss: 1.495  loss_cls: 0.1588  loss_box_reg: 0.0331  loss_mask: 0.6661  loss_rpn_cls: 0.5083  loss_rpn_loc: 0.07035    time: 0.2991  last_time: 0.3166  data_time: 0.0032  last_data_time: 0.0030   lr: 2.997e-05  max_mem: 2333M\n",
      "\u001b[32m[06/23 12:52:17 d2.utils.events]: \u001b[0m eta: 0:43:50  iter: 139  total_loss: 1.164  loss_cls: 0.1284  loss_box_reg: 0.03333  loss_mask: 0.6639  loss_rpn_cls: 0.2371  loss_rpn_loc: 0.0389    time: 0.2976  last_time: 0.3216  data_time: 0.0034  last_data_time: 0.0033   lr: 3.4965e-05  max_mem: 2333M\n",
      "\u001b[32m[06/23 12:52:23 d2.utils.events]: \u001b[0m eta: 0:43:29  iter: 159  total_loss: 1.244  loss_cls: 0.1329  loss_box_reg: 0.05639  loss_mask: 0.6589  loss_rpn_cls: 0.3197  loss_rpn_loc: 0.05725    time: 0.2961  last_time: 0.3211  data_time: 0.0033  last_data_time: 0.0030   lr: 3.996e-05  max_mem: 2333M\n",
      "\u001b[32m[06/23 12:52:29 d2.utils.events]: \u001b[0m eta: 0:43:23  iter: 179  total_loss: 1.199  loss_cls: 0.1538  loss_box_reg: 0.08923  loss_mask: 0.647  loss_rpn_cls: 0.2504  loss_rpn_loc: 0.05084    time: 0.2964  last_time: 0.3123  data_time: 0.0035  last_data_time: 0.0038   lr: 4.4955e-05  max_mem: 2334M\n",
      "\u001b[32m[06/23 12:52:35 d2.utils.events]: \u001b[0m eta: 0:43:13  iter: 199  total_loss: 1.152  loss_cls: 0.1512  loss_box_reg: 0.09174  loss_mask: 0.638  loss_rpn_cls: 0.2233  loss_rpn_loc: 0.06194    time: 0.2961  last_time: 0.3034  data_time: 0.0034  last_data_time: 0.0035   lr: 4.995e-05  max_mem: 2334M\n",
      "\u001b[32m[06/23 12:52:41 d2.utils.events]: \u001b[0m eta: 0:43:06  iter: 219  total_loss: 1.168  loss_cls: 0.1308  loss_box_reg: 0.06911  loss_mask: 0.6371  loss_rpn_cls: 0.2552  loss_rpn_loc: 0.06805    time: 0.2957  last_time: 0.3302  data_time: 0.0035  last_data_time: 0.0039   lr: 5.4945e-05  max_mem: 2334M\n",
      "\u001b[32m[06/23 12:52:47 d2.utils.events]: \u001b[0m eta: 0:43:04  iter: 239  total_loss: 1.233  loss_cls: 0.1829  loss_box_reg: 0.1273  loss_mask: 0.6233  loss_rpn_cls: 0.1828  loss_rpn_loc: 0.05823    time: 0.2964  last_time: 0.2778  data_time: 0.0037  last_data_time: 0.0031   lr: 5.994e-05  max_mem: 2334M\n",
      "\u001b[32m[06/23 12:52:53 d2.utils.events]: \u001b[0m eta: 0:43:04  iter: 259  total_loss: 1.121  loss_cls: 0.1588  loss_box_reg: 0.1177  loss_mask: 0.6085  loss_rpn_cls: 0.1419  loss_rpn_loc: 0.06341    time: 0.2977  last_time: 0.2757  data_time: 0.0034  last_data_time: 0.0034   lr: 6.4935e-05  max_mem: 2334M\n",
      "\u001b[32m[06/23 12:53:00 d2.utils.events]: \u001b[0m eta: 0:43:05  iter: 279  total_loss: 1.192  loss_cls: 0.186  loss_box_reg: 0.1672  loss_mask: 0.5826  loss_rpn_cls: 0.1722  loss_rpn_loc: 0.06271    time: 0.2997  last_time: 0.3338  data_time: 0.0035  last_data_time: 0.0033   lr: 6.993e-05  max_mem: 2334M\n",
      "\u001b[32m[06/23 12:53:06 d2.utils.events]: \u001b[0m eta: 0:43:02  iter: 299  total_loss: 1.145  loss_cls: 0.1902  loss_box_reg: 0.1516  loss_mask: 0.5737  loss_rpn_cls: 0.1443  loss_rpn_loc: 0.04895    time: 0.3008  last_time: 0.3485  data_time: 0.0034  last_data_time: 0.0035   lr: 7.4925e-05  max_mem: 2342M\n",
      "\u001b[32m[06/23 12:53:12 d2.utils.events]: \u001b[0m eta: 0:43:10  iter: 319  total_loss: 1.136  loss_cls: 0.1558  loss_box_reg: 0.1084  loss_mask: 0.5779  loss_rpn_cls: 0.1566  loss_rpn_loc: 0.06278    time: 0.3018  last_time: 0.3125  data_time: 0.0034  last_data_time: 0.0029   lr: 7.992e-05  max_mem: 2342M\n",
      "\u001b[32m[06/23 12:53:19 d2.utils.events]: \u001b[0m eta: 0:43:11  iter: 339  total_loss: 1.184  loss_cls: 0.1894  loss_box_reg: 0.1574  loss_mask: 0.562  loss_rpn_cls: 0.1814  loss_rpn_loc: 0.05546    time: 0.3035  last_time: 0.2984  data_time: 0.0036  last_data_time: 0.0035   lr: 8.4915e-05  max_mem: 2342M\n",
      "\u001b[32m[06/23 12:53:26 d2.utils.events]: \u001b[0m eta: 0:43:38  iter: 359  total_loss: 1.155  loss_cls: 0.2101  loss_box_reg: 0.1788  loss_mask: 0.5571  loss_rpn_cls: 0.1355  loss_rpn_loc: 0.05724    time: 0.3048  last_time: 0.3549  data_time: 0.0034  last_data_time: 0.0039   lr: 8.991e-05  max_mem: 2342M\n",
      "\u001b[32m[06/23 12:53:32 d2.utils.events]: \u001b[0m eta: 0:43:37  iter: 379  total_loss: 1.07  loss_cls: 0.1816  loss_box_reg: 0.1548  loss_mask: 0.5484  loss_rpn_cls: 0.1544  loss_rpn_loc: 0.06054    time: 0.3049  last_time: 0.2982  data_time: 0.0034  last_data_time: 0.0028   lr: 9.4905e-05  max_mem: 2342M\n",
      "\u001b[32m[06/23 12:53:38 d2.utils.events]: \u001b[0m eta: 0:43:37  iter: 399  total_loss: 1.097  loss_cls: 0.2055  loss_box_reg: 0.1884  loss_mask: 0.5406  loss_rpn_cls: 0.1368  loss_rpn_loc: 0.04913    time: 0.3057  last_time: 0.3206  data_time: 0.0035  last_data_time: 0.0029   lr: 9.99e-05  max_mem: 2342M\n",
      "\u001b[32m[06/23 12:53:44 d2.utils.events]: \u001b[0m eta: 0:43:33  iter: 419  total_loss: 1.127  loss_cls: 0.1966  loss_box_reg: 0.1789  loss_mask: 0.504  loss_rpn_cls: 0.149  loss_rpn_loc: 0.05008    time: 0.3057  last_time: 0.3164  data_time: 0.0034  last_data_time: 0.0034   lr: 0.0001049  max_mem: 2342M\n",
      "\u001b[32m[06/23 12:53:51 d2.utils.events]: \u001b[0m eta: 0:43:32  iter: 439  total_loss: 1.151  loss_cls: 0.2031  loss_box_reg: 0.2  loss_mask: 0.4894  loss_rpn_cls: 0.129  loss_rpn_loc: 0.04745    time: 0.3065  last_time: 0.2896  data_time: 0.0034  last_data_time: 0.0036   lr: 0.00010989  max_mem: 2342M\n",
      "\u001b[32m[06/23 12:53:57 d2.utils.events]: \u001b[0m eta: 0:43:33  iter: 459  total_loss: 1.136  loss_cls: 0.2161  loss_box_reg: 0.2333  loss_mask: 0.5013  loss_rpn_cls: 0.1455  loss_rpn_loc: 0.04596    time: 0.3074  last_time: 0.3085  data_time: 0.0035  last_data_time: 0.0034   lr: 0.00011489  max_mem: 2351M\n",
      "\u001b[32m[06/23 12:54:04 d2.utils.events]: \u001b[0m eta: 0:43:33  iter: 479  total_loss: 1.113  loss_cls: 0.209  loss_box_reg: 0.197  loss_mask: 0.5139  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.04669    time: 0.3084  last_time: 0.3183  data_time: 0.0035  last_data_time: 0.0034   lr: 0.00011988  max_mem: 2351M\n",
      "\u001b[32m[06/23 12:54:11 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 12:54:11 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  wrinkle   | 1094         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[06/23 12:54:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 12:54:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 12:54:11 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 12:54:11 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 12:54:11 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 12:54:11 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 12:54:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 12:54:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.1419 s/iter. Eval: 0.5434 s/iter. Total: 0.6864 s/iter. ETA=0:02:18\n",
      "\u001b[32m[06/23 12:54:23 d2.evaluation.evaluator]: \u001b[0mInference done 17/213. Dataloading: 0.0012 s/iter. Inference: 0.1628 s/iter. Eval: 0.6027 s/iter. Total: 0.7669 s/iter. ETA=0:02:30\n",
      "\u001b[32m[06/23 12:54:28 d2.evaluation.evaluator]: \u001b[0mInference done 23/213. Dataloading: 0.0013 s/iter. Inference: 0.1570 s/iter. Eval: 0.6313 s/iter. Total: 0.7898 s/iter. ETA=0:02:30\n",
      "\u001b[32m[06/23 12:54:33 d2.evaluation.evaluator]: \u001b[0mInference done 31/213. Dataloading: 0.0013 s/iter. Inference: 0.1464 s/iter. Eval: 0.6092 s/iter. Total: 0.7570 s/iter. ETA=0:02:17\n",
      "\u001b[32m[06/23 12:54:39 d2.evaluation.evaluator]: \u001b[0mInference done 41/213. Dataloading: 0.0013 s/iter. Inference: 0.1357 s/iter. Eval: 0.5525 s/iter. Total: 0.6897 s/iter. ETA=0:01:58\n",
      "\u001b[32m[06/23 12:54:45 d2.evaluation.evaluator]: \u001b[0mInference done 49/213. Dataloading: 0.0013 s/iter. Inference: 0.1337 s/iter. Eval: 0.5653 s/iter. Total: 0.7004 s/iter. ETA=0:01:54\n",
      "\u001b[32m[06/23 12:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 57/213. Dataloading: 0.0013 s/iter. Inference: 0.1312 s/iter. Eval: 0.5583 s/iter. Total: 0.6909 s/iter. ETA=0:01:47\n",
      "\u001b[32m[06/23 12:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 63/213. Dataloading: 0.0013 s/iter. Inference: 0.1320 s/iter. Eval: 0.5804 s/iter. Total: 0.7138 s/iter. ETA=0:01:47\n",
      "\u001b[32m[06/23 12:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 72/213. Dataloading: 0.0013 s/iter. Inference: 0.1298 s/iter. Eval: 0.5667 s/iter. Total: 0.6980 s/iter. ETA=0:01:38\n",
      "\u001b[32m[06/23 12:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 81/213. Dataloading: 0.0013 s/iter. Inference: 0.1273 s/iter. Eval: 0.5583 s/iter. Total: 0.6871 s/iter. ETA=0:01:30\n",
      "\u001b[32m[06/23 12:55:11 d2.evaluation.evaluator]: \u001b[0mInference done 89/213. Dataloading: 0.0013 s/iter. Inference: 0.1268 s/iter. Eval: 0.5558 s/iter. Total: 0.6841 s/iter. ETA=0:01:24\n",
      "\u001b[32m[06/23 12:55:16 d2.evaluation.evaluator]: \u001b[0mInference done 99/213. Dataloading: 0.0013 s/iter. Inference: 0.1249 s/iter. Eval: 0.5400 s/iter. Total: 0.6663 s/iter. ETA=0:01:15\n",
      "\u001b[32m[06/23 12:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 104/213. Dataloading: 0.0013 s/iter. Inference: 0.1263 s/iter. Eval: 0.5636 s/iter. Total: 0.6914 s/iter. ETA=0:01:15\n",
      "\u001b[32m[06/23 12:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 110/213. Dataloading: 0.0013 s/iter. Inference: 0.1266 s/iter. Eval: 0.5762 s/iter. Total: 0.7043 s/iter. ETA=0:01:12\n",
      "\u001b[32m[06/23 12:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 119/213. Dataloading: 0.0013 s/iter. Inference: 0.1260 s/iter. Eval: 0.5696 s/iter. Total: 0.6971 s/iter. ETA=0:01:05\n",
      "\u001b[32m[06/23 12:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 127/213. Dataloading: 0.0013 s/iter. Inference: 0.1253 s/iter. Eval: 0.5672 s/iter. Total: 0.6939 s/iter. ETA=0:00:59\n",
      "\u001b[32m[06/23 12:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 134/213. Dataloading: 0.0013 s/iter. Inference: 0.1254 s/iter. Eval: 0.5745 s/iter. Total: 0.7013 s/iter. ETA=0:00:55\n",
      "\u001b[32m[06/23 12:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 142/213. Dataloading: 0.0013 s/iter. Inference: 0.1250 s/iter. Eval: 0.5708 s/iter. Total: 0.6972 s/iter. ETA=0:00:49\n",
      "\u001b[32m[06/23 12:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 152/213. Dataloading: 0.0013 s/iter. Inference: 0.1240 s/iter. Eval: 0.5606 s/iter. Total: 0.6861 s/iter. ETA=0:00:41\n",
      "\u001b[32m[06/23 12:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 161/213. Dataloading: 0.0013 s/iter. Inference: 0.1231 s/iter. Eval: 0.5543 s/iter. Total: 0.6788 s/iter. ETA=0:00:35\n",
      "\u001b[32m[06/23 12:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 168/213. Dataloading: 0.0013 s/iter. Inference: 0.1232 s/iter. Eval: 0.5566 s/iter. Total: 0.6812 s/iter. ETA=0:00:30\n",
      "\u001b[32m[06/23 12:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 175/213. Dataloading: 0.0013 s/iter. Inference: 0.1234 s/iter. Eval: 0.5623 s/iter. Total: 0.6871 s/iter. ETA=0:00:26\n",
      "\u001b[32m[06/23 12:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 186/213. Dataloading: 0.0013 s/iter. Inference: 0.1221 s/iter. Eval: 0.5506 s/iter. Total: 0.6741 s/iter. ETA=0:00:18\n",
      "\u001b[32m[06/23 12:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 195/213. Dataloading: 0.0013 s/iter. Inference: 0.1216 s/iter. Eval: 0.5466 s/iter. Total: 0.6696 s/iter. ETA=0:00:12\n",
      "\u001b[32m[06/23 12:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 200/213. Dataloading: 0.0013 s/iter. Inference: 0.1220 s/iter. Eval: 0.5560 s/iter. Total: 0.6795 s/iter. ETA=0:00:08\n",
      "\u001b[32m[06/23 12:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 206/213. Dataloading: 0.0013 s/iter. Inference: 0.1223 s/iter. Eval: 0.5663 s/iter. Total: 0.6900 s/iter. ETA=0:00:04\n",
      "\u001b[32m[06/23 12:56:38 d2.evaluation.evaluator]: \u001b[0mInference done 211/213. Dataloading: 0.0013 s/iter. Inference: 0.1227 s/iter. Eval: 0.5751 s/iter. Total: 0.6993 s/iter. ETA=0:00:01\n",
      "\u001b[32m[06/23 12:56:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:26.095241 (0.702381 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 12:56:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:25 (0.122509 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 12:56:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 12:56:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 12:56:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.25s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
      "\u001b[32m[06/23 12:56:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.157 | 5.022  | 0.091  | 0.020 | 0.639 | 1.447 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=1.39s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.045\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.114\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
      "\u001b[32m[06/23 12:56:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.016 | 4.434  | 0.071  | 0.028 | 0.399 | 1.385 |\n",
      "\u001b[32m[06/23 12:56:44 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 12:56:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 12:56:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 12:56:44 d2.evaluation.testing]: \u001b[0mcopypaste: 1.1574,5.0225,0.0912,0.0196,0.6393,1.4469\n",
      "\u001b[32m[06/23 12:56:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 12:56:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 12:56:44 d2.evaluation.testing]: \u001b[0mcopypaste: 1.0157,4.4341,0.0713,0.0276,0.3986,1.3853\n",
      "\u001b[32m[06/23 12:56:44 d2.utils.events]: \u001b[0m eta: 0:43:45  iter: 499  total_loss: 1.155  loss_cls: 0.2122  loss_box_reg: 0.2449  loss_mask: 0.5094  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.04672    time: 0.3097  last_time: 0.3471  data_time: 0.0033  last_data_time: 0.0035   lr: 0.00012488  max_mem: 5355M\n",
      "val_loss (0.9484617970883846, 500)\n",
      "Iteration 500: Validation Loss = 0.9485\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_500.pth\n",
      "\u001b[32m[06/23 12:56:50 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 519  total_loss: 0.9356  loss_cls: 0.1545  loss_box_reg: 0.1349  loss_mask: 0.4869  loss_rpn_cls: 0.09041  loss_rpn_loc: 0.02503    time: 0.3097  last_time: 0.3157  data_time: 0.0033  last_data_time: 0.0031   lr: 0.00012987  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:56:57 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 539  total_loss: 1.06  loss_cls: 0.1962  loss_box_reg: 0.2067  loss_mask: 0.4964  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.04109    time: 0.3101  last_time: 0.3420  data_time: 0.0035  last_data_time: 0.0038   lr: 0.00013487  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:57:03 d2.utils.events]: \u001b[0m eta: 0:43:38  iter: 559  total_loss: 1.188  loss_cls: 0.2236  loss_box_reg: 0.2592  loss_mask: 0.4567  loss_rpn_cls: 0.1262  loss_rpn_loc: 0.04923    time: 0.3110  last_time: 0.3033  data_time: 0.0035  last_data_time: 0.0030   lr: 0.00013986  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:57:10 d2.utils.events]: \u001b[0m eta: 0:43:38  iter: 579  total_loss: 1.179  loss_cls: 0.2241  loss_box_reg: 0.2514  loss_mask: 0.4917  loss_rpn_cls: 0.08586  loss_rpn_loc: 0.04166    time: 0.3114  last_time: 0.2990  data_time: 0.0034  last_data_time: 0.0032   lr: 0.00014486  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:57:16 d2.utils.events]: \u001b[0m eta: 0:43:35  iter: 599  total_loss: 1.087  loss_cls: 0.2361  loss_box_reg: 0.2516  loss_mask: 0.4964  loss_rpn_cls: 0.08571  loss_rpn_loc: 0.0417    time: 0.3118  last_time: 0.2797  data_time: 0.0034  last_data_time: 0.0033   lr: 0.00014985  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:57:23 d2.utils.events]: \u001b[0m eta: 0:43:35  iter: 619  total_loss: 1.332  loss_cls: 0.2769  loss_box_reg: 0.3027  loss_mask: 0.4761  loss_rpn_cls: 0.09827  loss_rpn_loc: 0.05329    time: 0.3125  last_time: 0.3752  data_time: 0.0035  last_data_time: 0.0036   lr: 0.00015485  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:57:30 d2.utils.events]: \u001b[0m eta: 0:43:34  iter: 639  total_loss: 1.305  loss_cls: 0.3028  loss_box_reg: 0.3869  loss_mask: 0.4585  loss_rpn_cls: 0.08824  loss_rpn_loc: 0.05626    time: 0.3133  last_time: 0.3699  data_time: 0.0034  last_data_time: 0.0032   lr: 0.00015984  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:57:37 d2.utils.events]: \u001b[0m eta: 0:43:31  iter: 659  total_loss: 1.188  loss_cls: 0.2543  loss_box_reg: 0.3189  loss_mask: 0.4716  loss_rpn_cls: 0.08999  loss_rpn_loc: 0.04274    time: 0.3139  last_time: 0.3417  data_time: 0.0033  last_data_time: 0.0034   lr: 0.00016484  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:57:43 d2.utils.events]: \u001b[0m eta: 0:43:29  iter: 679  total_loss: 1.087  loss_cls: 0.2202  loss_box_reg: 0.1982  loss_mask: 0.4774  loss_rpn_cls: 0.07174  loss_rpn_loc: 0.03636    time: 0.3144  last_time: 0.3481  data_time: 0.0034  last_data_time: 0.0035   lr: 0.00016983  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:57:50 d2.utils.events]: \u001b[0m eta: 0:43:27  iter: 699  total_loss: 1.083  loss_cls: 0.2309  loss_box_reg: 0.2961  loss_mask: 0.4744  loss_rpn_cls: 0.08196  loss_rpn_loc: 0.04098    time: 0.3150  last_time: 0.3297  data_time: 0.0035  last_data_time: 0.0035   lr: 0.00017483  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:57:57 d2.utils.events]: \u001b[0m eta: 0:43:23  iter: 719  total_loss: 1.079  loss_cls: 0.2349  loss_box_reg: 0.268  loss_mask: 0.4405  loss_rpn_cls: 0.06404  loss_rpn_loc: 0.02857    time: 0.3157  last_time: 0.3099  data_time: 0.0033  last_data_time: 0.0035   lr: 0.00017982  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:58:03 d2.utils.events]: \u001b[0m eta: 0:43:18  iter: 739  total_loss: 1.293  loss_cls: 0.2709  loss_box_reg: 0.3899  loss_mask: 0.4548  loss_rpn_cls: 0.07845  loss_rpn_loc: 0.04172    time: 0.3159  last_time: 0.2735  data_time: 0.0033  last_data_time: 0.0034   lr: 0.00018482  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:58:10 d2.utils.events]: \u001b[0m eta: 0:43:12  iter: 759  total_loss: 1.252  loss_cls: 0.1761  loss_box_reg: 0.2353  loss_mask: 0.4589  loss_rpn_cls: 0.1084  loss_rpn_loc: 0.06333    time: 0.3161  last_time: 0.3952  data_time: 0.0034  last_data_time: 0.0036   lr: 0.00018981  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:58:16 d2.utils.events]: \u001b[0m eta: 0:43:08  iter: 779  total_loss: 1.116  loss_cls: 0.1891  loss_box_reg: 0.2645  loss_mask: 0.4365  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.04717    time: 0.3164  last_time: 0.3446  data_time: 0.0034  last_data_time: 0.0036   lr: 0.00019481  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:58:23 d2.utils.events]: \u001b[0m eta: 0:43:06  iter: 799  total_loss: 1.17  loss_cls: 0.2185  loss_box_reg: 0.2999  loss_mask: 0.4771  loss_rpn_cls: 0.07793  loss_rpn_loc: 0.05709    time: 0.3169  last_time: 0.3591  data_time: 0.0034  last_data_time: 0.0032   lr: 0.0001998  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:58:29 d2.utils.events]: \u001b[0m eta: 0:42:59  iter: 819  total_loss: 1.047  loss_cls: 0.2079  loss_box_reg: 0.2736  loss_mask: 0.4284  loss_rpn_cls: 0.0698  loss_rpn_loc: 0.03743    time: 0.3171  last_time: 0.4093  data_time: 0.0032  last_data_time: 0.0037   lr: 0.0002048  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:58:36 d2.utils.events]: \u001b[0m eta: 0:42:58  iter: 839  total_loss: 1.12  loss_cls: 0.2315  loss_box_reg: 0.3423  loss_mask: 0.4278  loss_rpn_cls: 0.07952  loss_rpn_loc: 0.04237    time: 0.3179  last_time: 0.3612  data_time: 0.0034  last_data_time: 0.0036   lr: 0.00020979  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:58:43 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 859  total_loss: 1.128  loss_cls: 0.2434  loss_box_reg: 0.2868  loss_mask: 0.4284  loss_rpn_cls: 0.06399  loss_rpn_loc: 0.05907    time: 0.3184  last_time: 0.4096  data_time: 0.0035  last_data_time: 0.0042   lr: 0.00021479  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:58:50 d2.utils.events]: \u001b[0m eta: 0:42:48  iter: 879  total_loss: 1.106  loss_cls: 0.2257  loss_box_reg: 0.3045  loss_mask: 0.4506  loss_rpn_cls: 0.07286  loss_rpn_loc: 0.02813    time: 0.3188  last_time: 0.3887  data_time: 0.0034  last_data_time: 0.0038   lr: 0.00021978  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:58:57 d2.utils.events]: \u001b[0m eta: 0:42:42  iter: 899  total_loss: 1.214  loss_cls: 0.2612  loss_box_reg: 0.3465  loss_mask: 0.4572  loss_rpn_cls: 0.07739  loss_rpn_loc: 0.03962    time: 0.3191  last_time: 0.3543  data_time: 0.0034  last_data_time: 0.0041   lr: 0.00022478  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:59:03 d2.utils.events]: \u001b[0m eta: 0:42:38  iter: 919  total_loss: 1.23  loss_cls: 0.2526  loss_box_reg: 0.3681  loss_mask: 0.4526  loss_rpn_cls: 0.0746  loss_rpn_loc: 0.04475    time: 0.3194  last_time: 0.3551  data_time: 0.0035  last_data_time: 0.0038   lr: 0.00022977  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:59:10 d2.utils.events]: \u001b[0m eta: 0:42:35  iter: 939  total_loss: 1.3  loss_cls: 0.3089  loss_box_reg: 0.4606  loss_mask: 0.4208  loss_rpn_cls: 0.06882  loss_rpn_loc: 0.05056    time: 0.3197  last_time: 0.3563  data_time: 0.0034  last_data_time: 0.0034   lr: 0.00023477  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:59:17 d2.utils.events]: \u001b[0m eta: 0:42:31  iter: 959  total_loss: 1.085  loss_cls: 0.2381  loss_box_reg: 0.3383  loss_mask: 0.4172  loss_rpn_cls: 0.08081  loss_rpn_loc: 0.04313    time: 0.3200  last_time: 0.3511  data_time: 0.0034  last_data_time: 0.0033   lr: 0.00023976  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:59:23 d2.utils.events]: \u001b[0m eta: 0:42:34  iter: 979  total_loss: 1.124  loss_cls: 0.2282  loss_box_reg: 0.323  loss_mask: 0.423  loss_rpn_cls: 0.06466  loss_rpn_loc: 0.04218    time: 0.3204  last_time: 0.3542  data_time: 0.0034  last_data_time: 0.0032   lr: 0.00024476  max_mem: 5355M\n",
      "\u001b[32m[06/23 12:59:30 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 12:59:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 12:59:31 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 12:59:31 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 12:59:31 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 12:59:31 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 12:59:31 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 12:59:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 12:59:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0974 s/iter. Eval: 0.3584 s/iter. Total: 0.4569 s/iter. ETA=0:01:32\n",
      "\u001b[32m[06/23 12:59:40 d2.evaluation.evaluator]: \u001b[0mInference done 19/213. Dataloading: 0.0012 s/iter. Inference: 0.1062 s/iter. Eval: 0.4518 s/iter. Total: 0.5595 s/iter. ETA=0:01:48\n",
      "\u001b[32m[06/23 12:59:46 d2.evaluation.evaluator]: \u001b[0mInference done 27/213. Dataloading: 0.0013 s/iter. Inference: 0.1094 s/iter. Eval: 0.4906 s/iter. Total: 0.6014 s/iter. ETA=0:01:51\n",
      "\u001b[32m[06/23 12:59:51 d2.evaluation.evaluator]: \u001b[0mInference done 40/213. Dataloading: 0.0013 s/iter. Inference: 0.1024 s/iter. Eval: 0.4186 s/iter. Total: 0.5225 s/iter. ETA=0:01:30\n",
      "\u001b[32m[06/23 12:59:57 d2.evaluation.evaluator]: \u001b[0mInference done 49/213. Dataloading: 0.0013 s/iter. Inference: 0.1048 s/iter. Eval: 0.4472 s/iter. Total: 0.5534 s/iter. ETA=0:01:30\n",
      "\u001b[32m[06/23 13:00:03 d2.evaluation.evaluator]: \u001b[0mInference done 61/213. Dataloading: 0.0013 s/iter. Inference: 0.1045 s/iter. Eval: 0.4433 s/iter. Total: 0.5492 s/iter. ETA=0:01:23\n",
      "\u001b[32m[06/23 13:00:08 d2.evaluation.evaluator]: \u001b[0mInference done 72/213. Dataloading: 0.0013 s/iter. Inference: 0.1041 s/iter. Eval: 0.4287 s/iter. Total: 0.5343 s/iter. ETA=0:01:15\n",
      "\u001b[32m[06/23 13:00:14 d2.evaluation.evaluator]: \u001b[0mInference done 84/213. Dataloading: 0.0013 s/iter. Inference: 0.1021 s/iter. Eval: 0.4174 s/iter. Total: 0.5209 s/iter. ETA=0:01:07\n",
      "\u001b[32m[06/23 13:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 98/213. Dataloading: 0.0013 s/iter. Inference: 0.1000 s/iter. Eval: 0.3953 s/iter. Total: 0.4967 s/iter. ETA=0:00:57\n",
      "\u001b[32m[06/23 13:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 104/213. Dataloading: 0.0013 s/iter. Inference: 0.1042 s/iter. Eval: 0.4199 s/iter. Total: 0.5256 s/iter. ETA=0:00:57\n",
      "\u001b[32m[06/23 13:00:30 d2.evaluation.evaluator]: \u001b[0mInference done 111/213. Dataloading: 0.0013 s/iter. Inference: 0.1061 s/iter. Eval: 0.4337 s/iter. Total: 0.5412 s/iter. ETA=0:00:55\n",
      "\u001b[32m[06/23 13:00:35 d2.evaluation.evaluator]: \u001b[0mInference done 121/213. Dataloading: 0.0013 s/iter. Inference: 0.1069 s/iter. Eval: 0.4312 s/iter. Total: 0.5395 s/iter. ETA=0:00:49\n",
      "\u001b[32m[06/23 13:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 130/213. Dataloading: 0.0013 s/iter. Inference: 0.1067 s/iter. Eval: 0.4336 s/iter. Total: 0.5418 s/iter. ETA=0:00:44\n",
      "\u001b[32m[06/23 13:00:45 d2.evaluation.evaluator]: \u001b[0mInference done 139/213. Dataloading: 0.0013 s/iter. Inference: 0.1066 s/iter. Eval: 0.4357 s/iter. Total: 0.5438 s/iter. ETA=0:00:40\n",
      "\u001b[32m[06/23 13:00:50 d2.evaluation.evaluator]: \u001b[0mInference done 152/213. Dataloading: 0.0013 s/iter. Inference: 0.1051 s/iter. Eval: 0.4231 s/iter. Total: 0.5297 s/iter. ETA=0:00:32\n",
      "\u001b[32m[06/23 13:00:56 d2.evaluation.evaluator]: \u001b[0mInference done 163/213. Dataloading: 0.0013 s/iter. Inference: 0.1050 s/iter. Eval: 0.4219 s/iter. Total: 0.5283 s/iter. ETA=0:00:26\n",
      "\u001b[32m[06/23 13:01:01 d2.evaluation.evaluator]: \u001b[0mInference done 172/213. Dataloading: 0.0013 s/iter. Inference: 0.1049 s/iter. Eval: 0.4262 s/iter. Total: 0.5326 s/iter. ETA=0:00:21\n",
      "\u001b[32m[06/23 13:01:07 d2.evaluation.evaluator]: \u001b[0mInference done 185/213. Dataloading: 0.0013 s/iter. Inference: 0.1038 s/iter. Eval: 0.4171 s/iter. Total: 0.5223 s/iter. ETA=0:00:14\n",
      "\u001b[32m[06/23 13:01:12 d2.evaluation.evaluator]: \u001b[0mInference done 197/213. Dataloading: 0.0013 s/iter. Inference: 0.1034 s/iter. Eval: 0.4150 s/iter. Total: 0.5199 s/iter. ETA=0:00:08\n",
      "\u001b[32m[06/23 13:01:17 d2.evaluation.evaluator]: \u001b[0mInference done 208/213. Dataloading: 0.0013 s/iter. Inference: 0.1022 s/iter. Eval: 0.4133 s/iter. Total: 0.5170 s/iter. ETA=0:00:02\n",
      "\u001b[32m[06/23 13:01:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:47.965479 (0.519065 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:01:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.101912 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:01:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:01:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:01:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.94s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
      "\u001b[32m[06/23 13:01:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 8.835 | 28.283 | 3.200  | 1.861 | 8.802 | 9.501 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=1.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\n",
      "\u001b[32m[06/23 13:01:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 8.743 | 27.024 | 2.941  | 2.334 | 5.796 | 10.343 |\n",
      "\u001b[32m[06/23 13:01:23 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:01:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:01:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:01:23 d2.evaluation.testing]: \u001b[0mcopypaste: 8.8353,28.2827,3.1996,1.8614,8.8024,9.5009\n",
      "\u001b[32m[06/23 13:01:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:01:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:01:23 d2.evaluation.testing]: \u001b[0mcopypaste: 8.7431,27.0241,2.9409,2.3338,5.7960,10.3434\n",
      "\u001b[32m[06/23 13:01:23 d2.utils.events]: \u001b[0m eta: 0:42:31  iter: 999  total_loss: 1.316  loss_cls: 0.2991  loss_box_reg: 0.4563  loss_mask: 0.4253  loss_rpn_cls: 0.05941  loss_rpn_loc: 0.05161    time: 0.3209  last_time: 0.3488  data_time: 0.0035  last_data_time: 0.0030   lr: 0.00024975  max_mem: 5355M\n",
      "val_loss (1.3821540847420692, 1000)\n",
      "Iteration 1000: Validation Loss = 1.3822\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_1000.pth\n",
      "\u001b[32m[06/23 13:01:30 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 1019  total_loss: 1.276  loss_cls: 0.2888  loss_box_reg: 0.4195  loss_mask: 0.4098  loss_rpn_cls: 0.06859  loss_rpn_loc: 0.058    time: 0.3211  last_time: 0.3453  data_time: 0.0035  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:01:37 d2.utils.events]: \u001b[0m eta: 0:42:34  iter: 1039  total_loss: 1.13  loss_cls: 0.2457  loss_box_reg: 0.3643  loss_mask: 0.4204  loss_rpn_cls: 0.06572  loss_rpn_loc: 0.0371    time: 0.3216  last_time: 0.3273  data_time: 0.0033  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:01:44 d2.utils.events]: \u001b[0m eta: 0:42:38  iter: 1059  total_loss: 1.08  loss_cls: 0.2228  loss_box_reg: 0.2841  loss_mask: 0.4149  loss_rpn_cls: 0.06658  loss_rpn_loc: 0.04181    time: 0.3218  last_time: 0.4106  data_time: 0.0034  last_data_time: 0.0030   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:01:50 d2.utils.events]: \u001b[0m eta: 0:42:34  iter: 1079  total_loss: 1.122  loss_cls: 0.2388  loss_box_reg: 0.3036  loss_mask: 0.4321  loss_rpn_cls: 0.05826  loss_rpn_loc: 0.04701    time: 0.3219  last_time: 0.2982  data_time: 0.0035  last_data_time: 0.0030   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:01:57 d2.utils.events]: \u001b[0m eta: 0:42:31  iter: 1099  total_loss: 1.153  loss_cls: 0.254  loss_box_reg: 0.3905  loss_mask: 0.4062  loss_rpn_cls: 0.05927  loss_rpn_loc: 0.04214    time: 0.3222  last_time: 0.3441  data_time: 0.0034  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:02:04 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 1119  total_loss: 0.9476  loss_cls: 0.2046  loss_box_reg: 0.268  loss_mask: 0.4221  loss_rpn_cls: 0.05547  loss_rpn_loc: 0.03544    time: 0.3223  last_time: 0.3000  data_time: 0.0035  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:02:10 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 1139  total_loss: 1.172  loss_cls: 0.2662  loss_box_reg: 0.3519  loss_mask: 0.416  loss_rpn_cls: 0.06902  loss_rpn_loc: 0.04181    time: 0.3226  last_time: 0.3697  data_time: 0.0035  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:02:17 d2.utils.events]: \u001b[0m eta: 0:42:27  iter: 1159  total_loss: 1.092  loss_cls: 0.2462  loss_box_reg: 0.3792  loss_mask: 0.3926  loss_rpn_cls: 0.06867  loss_rpn_loc: 0.06363    time: 0.3229  last_time: 0.3073  data_time: 0.0035  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:02:24 d2.utils.events]: \u001b[0m eta: 0:42:24  iter: 1179  total_loss: 1.145  loss_cls: 0.2287  loss_box_reg: 0.3206  loss_mask: 0.4373  loss_rpn_cls: 0.06231  loss_rpn_loc: 0.04859    time: 0.3233  last_time: 0.3353  data_time: 0.0035  last_data_time: 0.0027   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:02:31 d2.utils.events]: \u001b[0m eta: 0:42:21  iter: 1199  total_loss: 1.041  loss_cls: 0.197  loss_box_reg: 0.2637  loss_mask: 0.4151  loss_rpn_cls: 0.05327  loss_rpn_loc: 0.03204    time: 0.3233  last_time: 0.3142  data_time: 0.0034  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:02:37 d2.utils.events]: \u001b[0m eta: 0:42:19  iter: 1219  total_loss: 1.066  loss_cls: 0.2187  loss_box_reg: 0.3058  loss_mask: 0.3911  loss_rpn_cls: 0.05949  loss_rpn_loc: 0.04627    time: 0.3235  last_time: 0.3460  data_time: 0.0036  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:02:44 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 1239  total_loss: 0.995  loss_cls: 0.1932  loss_box_reg: 0.2664  loss_mask: 0.4086  loss_rpn_cls: 0.0544  loss_rpn_loc: 0.03398    time: 0.3237  last_time: 0.4112  data_time: 0.0034  last_data_time: 0.0040   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:02:51 d2.utils.events]: \u001b[0m eta: 0:42:15  iter: 1259  total_loss: 1.181  loss_cls: 0.2428  loss_box_reg: 0.4043  loss_mask: 0.4015  loss_rpn_cls: 0.06147  loss_rpn_loc: 0.04014    time: 0.3242  last_time: 0.3679  data_time: 0.0036  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:02:58 d2.utils.events]: \u001b[0m eta: 0:42:12  iter: 1279  total_loss: 1.043  loss_cls: 0.2345  loss_box_reg: 0.2972  loss_mask: 0.3887  loss_rpn_cls: 0.04346  loss_rpn_loc: 0.03541    time: 0.3244  last_time: 0.3365  data_time: 0.0034  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:03:05 d2.utils.events]: \u001b[0m eta: 0:42:09  iter: 1299  total_loss: 1.189  loss_cls: 0.2491  loss_box_reg: 0.3558  loss_mask: 0.3822  loss_rpn_cls: 0.06151  loss_rpn_loc: 0.04664    time: 0.3247  last_time: 0.3119  data_time: 0.0034  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:03:12 d2.utils.events]: \u001b[0m eta: 0:42:08  iter: 1319  total_loss: 1.273  loss_cls: 0.2802  loss_box_reg: 0.3923  loss_mask: 0.4082  loss_rpn_cls: 0.06105  loss_rpn_loc: 0.05022    time: 0.3251  last_time: 0.3587  data_time: 0.0034  last_data_time: 0.0030   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:03:19 d2.utils.events]: \u001b[0m eta: 0:42:03  iter: 1339  total_loss: 1.056  loss_cls: 0.2316  loss_box_reg: 0.2839  loss_mask: 0.4003  loss_rpn_cls: 0.06313  loss_rpn_loc: 0.03897    time: 0.3254  last_time: 0.3636  data_time: 0.0034  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:03:25 d2.utils.events]: \u001b[0m eta: 0:42:01  iter: 1359  total_loss: 1.125  loss_cls: 0.2364  loss_box_reg: 0.3841  loss_mask: 0.3873  loss_rpn_cls: 0.04188  loss_rpn_loc: 0.04324    time: 0.3255  last_time: 0.3402  data_time: 0.0033  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:03:32 d2.utils.events]: \u001b[0m eta: 0:42:02  iter: 1379  total_loss: 1.163  loss_cls: 0.2681  loss_box_reg: 0.399  loss_mask: 0.3858  loss_rpn_cls: 0.05706  loss_rpn_loc: 0.04463    time: 0.3258  last_time: 0.3587  data_time: 0.0035  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:03:39 d2.utils.events]: \u001b[0m eta: 0:41:56  iter: 1399  total_loss: 1.193  loss_cls: 0.2571  loss_box_reg: 0.3402  loss_mask: 0.395  loss_rpn_cls: 0.07031  loss_rpn_loc: 0.03455    time: 0.3259  last_time: 0.2900  data_time: 0.0037  last_data_time: 0.0030   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:03:46 d2.utils.events]: \u001b[0m eta: 0:41:54  iter: 1419  total_loss: 1.081  loss_cls: 0.2383  loss_box_reg: 0.3658  loss_mask: 0.411  loss_rpn_cls: 0.05837  loss_rpn_loc: 0.04342    time: 0.3262  last_time: 0.3503  data_time: 0.0034  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:03:53 d2.utils.events]: \u001b[0m eta: 0:41:50  iter: 1439  total_loss: 1.004  loss_cls: 0.1997  loss_box_reg: 0.286  loss_mask: 0.4026  loss_rpn_cls: 0.04634  loss_rpn_loc: 0.03361    time: 0.3263  last_time: 0.3340  data_time: 0.0034  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:04:00 d2.utils.events]: \u001b[0m eta: 0:41:47  iter: 1459  total_loss: 1.099  loss_cls: 0.2295  loss_box_reg: 0.2975  loss_mask: 0.4087  loss_rpn_cls: 0.05135  loss_rpn_loc: 0.04244    time: 0.3266  last_time: 0.3434  data_time: 0.0034  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:04:07 d2.utils.events]: \u001b[0m eta: 0:41:44  iter: 1479  total_loss: 1.055  loss_cls: 0.2162  loss_box_reg: 0.3067  loss_mask: 0.396  loss_rpn_cls: 0.05358  loss_rpn_loc: 0.04644    time: 0.3268  last_time: 0.3186  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:04:13 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:04:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:04:13 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:04:13 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:04:13 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:04:13 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:04:13 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:04:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0890 s/iter. Eval: 0.2839 s/iter. Total: 0.3741 s/iter. ETA=0:01:15\n",
      "\u001b[32m[06/23 13:04:22 d2.evaluation.evaluator]: \u001b[0mInference done 21/213. Dataloading: 0.0013 s/iter. Inference: 0.0965 s/iter. Eval: 0.3623 s/iter. Total: 0.4603 s/iter. ETA=0:01:28\n",
      "\u001b[32m[06/23 13:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 36/213. Dataloading: 0.0013 s/iter. Inference: 0.0909 s/iter. Eval: 0.3078 s/iter. Total: 0.4001 s/iter. ETA=0:01:10\n",
      "\u001b[32m[06/23 13:04:33 d2.evaluation.evaluator]: \u001b[0mInference done 46/213. Dataloading: 0.0013 s/iter. Inference: 0.0938 s/iter. Eval: 0.3339 s/iter. Total: 0.4291 s/iter. ETA=0:01:11\n",
      "\u001b[32m[06/23 13:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 61/213. Dataloading: 0.0013 s/iter. Inference: 0.0932 s/iter. Eval: 0.3342 s/iter. Total: 0.4288 s/iter. ETA=0:01:05\n",
      "\u001b[32m[06/23 13:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 77/213. Dataloading: 0.0013 s/iter. Inference: 0.0916 s/iter. Eval: 0.3113 s/iter. Total: 0.4043 s/iter. ETA=0:00:54\n",
      "\u001b[32m[06/23 13:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 93/213. Dataloading: 0.0013 s/iter. Inference: 0.0900 s/iter. Eval: 0.2997 s/iter. Total: 0.3911 s/iter. ETA=0:00:46\n",
      "\u001b[32m[06/23 13:04:55 d2.evaluation.evaluator]: \u001b[0mInference done 105/213. Dataloading: 0.0013 s/iter. Inference: 0.0901 s/iter. Eval: 0.3033 s/iter. Total: 0.3948 s/iter. ETA=0:00:42\n",
      "\u001b[32m[06/23 13:05:00 d2.evaluation.evaluator]: \u001b[0mInference done 114/213. Dataloading: 0.0013 s/iter. Inference: 0.0915 s/iter. Eval: 0.3191 s/iter. Total: 0.4120 s/iter. ETA=0:00:40\n",
      "\u001b[32m[06/23 13:05:05 d2.evaluation.evaluator]: \u001b[0mInference done 128/213. Dataloading: 0.0013 s/iter. Inference: 0.0917 s/iter. Eval: 0.3169 s/iter. Total: 0.4100 s/iter. ETA=0:00:34\n",
      "\u001b[32m[06/23 13:05:11 d2.evaluation.evaluator]: \u001b[0mInference done 139/213. Dataloading: 0.0013 s/iter. Inference: 0.0923 s/iter. Eval: 0.3217 s/iter. Total: 0.4153 s/iter. ETA=0:00:30\n",
      "\u001b[32m[06/23 13:05:16 d2.evaluation.evaluator]: \u001b[0mInference done 157/213. Dataloading: 0.0013 s/iter. Inference: 0.0907 s/iter. Eval: 0.3071 s/iter. Total: 0.3992 s/iter. ETA=0:00:22\n",
      "\u001b[32m[06/23 13:05:21 d2.evaluation.evaluator]: \u001b[0mInference done 167/213. Dataloading: 0.0013 s/iter. Inference: 0.0913 s/iter. Eval: 0.3145 s/iter. Total: 0.4072 s/iter. ETA=0:00:18\n",
      "\u001b[32m[06/23 13:05:26 d2.evaluation.evaluator]: \u001b[0mInference done 178/213. Dataloading: 0.0013 s/iter. Inference: 0.0917 s/iter. Eval: 0.3189 s/iter. Total: 0.4120 s/iter. ETA=0:00:14\n",
      "\u001b[32m[06/23 13:05:31 d2.evaluation.evaluator]: \u001b[0mInference done 194/213. Dataloading: 0.0013 s/iter. Inference: 0.0912 s/iter. Eval: 0.3113 s/iter. Total: 0.4040 s/iter. ETA=0:00:07\n",
      "\u001b[32m[06/23 13:05:36 d2.evaluation.evaluator]: \u001b[0mInference done 211/213. Dataloading: 0.0013 s/iter. Inference: 0.0894 s/iter. Eval: 0.3042 s/iter. Total: 0.3950 s/iter. ETA=0:00:00\n",
      "\u001b[32m[06/23 13:05:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:21.969639 (0.394085 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:05:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.089097 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:05:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:05:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:05:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.73s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.436\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379\n",
      "\u001b[32m[06/23 13:05:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.092 | 43.641 | 5.302  | 3.762 | 14.589 | 16.850 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.84s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.135\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.399\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n",
      "\u001b[32m[06/23 13:05:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 13.526 | 39.911 | 4.644  | 3.564 | 8.196 | 16.435 |\n",
      "\u001b[32m[06/23 13:05:39 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:05:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:05:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:05:39 d2.evaluation.testing]: \u001b[0mcopypaste: 15.0919,43.6415,5.3024,3.7624,14.5893,16.8498\n",
      "\u001b[32m[06/23 13:05:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:05:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:05:39 d2.evaluation.testing]: \u001b[0mcopypaste: 13.5265,39.9108,4.6444,3.5644,8.1963,16.4351\n",
      "\u001b[32m[06/23 13:05:39 d2.utils.events]: \u001b[0m eta: 0:41:38  iter: 1499  total_loss: 0.9985  loss_cls: 0.2373  loss_box_reg: 0.3102  loss_mask: 0.3997  loss_rpn_cls: 0.06099  loss_rpn_loc: 0.03283    time: 0.3270  last_time: 0.3048  data_time: 0.0036  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "val_loss (0.853463813662529, 1500)\n",
      "Iteration 1500: Validation Loss = 0.8535\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_1500.pth\n",
      "\u001b[32m[06/23 13:05:47 d2.utils.events]: \u001b[0m eta: 0:41:34  iter: 1519  total_loss: 1.127  loss_cls: 0.2279  loss_box_reg: 0.3345  loss_mask: 0.4028  loss_rpn_cls: 0.0593  loss_rpn_loc: 0.03779    time: 0.3272  last_time: 0.3363  data_time: 0.0036  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:05:54 d2.utils.events]: \u001b[0m eta: 0:41:32  iter: 1539  total_loss: 1.072  loss_cls: 0.2324  loss_box_reg: 0.3211  loss_mask: 0.4037  loss_rpn_cls: 0.0431  loss_rpn_loc: 0.04216    time: 0.3275  last_time: 0.3752  data_time: 0.0034  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:06:00 d2.utils.events]: \u001b[0m eta: 0:41:26  iter: 1559  total_loss: 1.072  loss_cls: 0.2304  loss_box_reg: 0.3423  loss_mask: 0.4116  loss_rpn_cls: 0.05829  loss_rpn_loc: 0.03952    time: 0.3276  last_time: 0.3319  data_time: 0.0034  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:06:07 d2.utils.events]: \u001b[0m eta: 0:41:19  iter: 1579  total_loss: 1.066  loss_cls: 0.2184  loss_box_reg: 0.3162  loss_mask: 0.3926  loss_rpn_cls: 0.07107  loss_rpn_loc: 0.04216    time: 0.3277  last_time: 0.3501  data_time: 0.0034  last_data_time: 0.0040   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:06:14 d2.utils.events]: \u001b[0m eta: 0:41:18  iter: 1599  total_loss: 1.004  loss_cls: 0.2124  loss_box_reg: 0.3006  loss_mask: 0.4123  loss_rpn_cls: 0.05325  loss_rpn_loc: 0.0424    time: 0.3279  last_time: 0.3724  data_time: 0.0035  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:06:21 d2.utils.events]: \u001b[0m eta: 0:41:13  iter: 1619  total_loss: 1.155  loss_cls: 0.2511  loss_box_reg: 0.3629  loss_mask: 0.3875  loss_rpn_cls: 0.05376  loss_rpn_loc: 0.05037    time: 0.3281  last_time: 0.3188  data_time: 0.0035  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:06:28 d2.utils.events]: \u001b[0m eta: 0:41:08  iter: 1639  total_loss: 1.002  loss_cls: 0.2245  loss_box_reg: 0.3315  loss_mask: 0.3891  loss_rpn_cls: 0.05444  loss_rpn_loc: 0.04057    time: 0.3283  last_time: 0.3218  data_time: 0.0034  last_data_time: 0.0026   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:06:34 d2.utils.events]: \u001b[0m eta: 0:41:02  iter: 1659  total_loss: 1.183  loss_cls: 0.264  loss_box_reg: 0.3905  loss_mask: 0.3931  loss_rpn_cls: 0.06198  loss_rpn_loc: 0.05377    time: 0.3283  last_time: 0.3173  data_time: 0.0033  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:06:41 d2.utils.events]: \u001b[0m eta: 0:40:53  iter: 1679  total_loss: 1.043  loss_cls: 0.22  loss_box_reg: 0.3256  loss_mask: 0.3869  loss_rpn_cls: 0.05361  loss_rpn_loc: 0.03258    time: 0.3283  last_time: 0.3298  data_time: 0.0034  last_data_time: 0.0029   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:06:48 d2.utils.events]: \u001b[0m eta: 0:40:46  iter: 1699  total_loss: 1.004  loss_cls: 0.2235  loss_box_reg: 0.3054  loss_mask: 0.3977  loss_rpn_cls: 0.03679  loss_rpn_loc: 0.03006    time: 0.3285  last_time: 0.3193  data_time: 0.0034  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:06:54 d2.utils.events]: \u001b[0m eta: 0:40:41  iter: 1719  total_loss: 1.13  loss_cls: 0.2708  loss_box_reg: 0.3625  loss_mask: 0.3823  loss_rpn_cls: 0.05229  loss_rpn_loc: 0.05043    time: 0.3286  last_time: 0.2881  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:07:01 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 1739  total_loss: 0.9449  loss_cls: 0.1868  loss_box_reg: 0.2565  loss_mask: 0.4205  loss_rpn_cls: 0.05632  loss_rpn_loc: 0.02987    time: 0.3285  last_time: 0.3770  data_time: 0.0036  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:07:08 d2.utils.events]: \u001b[0m eta: 0:40:30  iter: 1759  total_loss: 1.105  loss_cls: 0.2524  loss_box_reg: 0.3691  loss_mask: 0.3718  loss_rpn_cls: 0.04802  loss_rpn_loc: 0.0379    time: 0.3287  last_time: 0.3045  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:07:14 d2.utils.events]: \u001b[0m eta: 0:40:24  iter: 1779  total_loss: 1.12  loss_cls: 0.2269  loss_box_reg: 0.332  loss_mask: 0.3794  loss_rpn_cls: 0.0438  loss_rpn_loc: 0.04038    time: 0.3287  last_time: 0.3449  data_time: 0.0036  last_data_time: 0.0029   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:07:21 d2.utils.events]: \u001b[0m eta: 0:40:15  iter: 1799  total_loss: 1.054  loss_cls: 0.211  loss_box_reg: 0.2933  loss_mask: 0.4021  loss_rpn_cls: 0.04971  loss_rpn_loc: 0.04161    time: 0.3287  last_time: 0.3528  data_time: 0.0035  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:07:28 d2.utils.events]: \u001b[0m eta: 0:40:08  iter: 1819  total_loss: 1.051  loss_cls: 0.2077  loss_box_reg: 0.2899  loss_mask: 0.3661  loss_rpn_cls: 0.04554  loss_rpn_loc: 0.03826    time: 0.3288  last_time: 0.2943  data_time: 0.0037  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:07:35 d2.utils.events]: \u001b[0m eta: 0:40:01  iter: 1839  total_loss: 1.088  loss_cls: 0.1855  loss_box_reg: 0.3229  loss_mask: 0.3898  loss_rpn_cls: 0.0467  loss_rpn_loc: 0.04129    time: 0.3290  last_time: 0.3455  data_time: 0.0034  last_data_time: 0.0040   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:07:42 d2.utils.events]: \u001b[0m eta: 0:39:58  iter: 1859  total_loss: 1.186  loss_cls: 0.2931  loss_box_reg: 0.3782  loss_mask: 0.3827  loss_rpn_cls: 0.05372  loss_rpn_loc: 0.05108    time: 0.3293  last_time: 0.3153  data_time: 0.0034  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:07:49 d2.utils.events]: \u001b[0m eta: 0:39:51  iter: 1879  total_loss: 1.055  loss_cls: 0.2122  loss_box_reg: 0.3289  loss_mask: 0.3991  loss_rpn_cls: 0.05838  loss_rpn_loc: 0.02623    time: 0.3293  last_time: 0.4170  data_time: 0.0034  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:07:56 d2.utils.events]: \u001b[0m eta: 0:39:46  iter: 1899  total_loss: 1.17  loss_cls: 0.2576  loss_box_reg: 0.4144  loss_mask: 0.3892  loss_rpn_cls: 0.03855  loss_rpn_loc: 0.05282    time: 0.3296  last_time: 0.3734  data_time: 0.0033  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:08:02 d2.utils.events]: \u001b[0m eta: 0:39:39  iter: 1919  total_loss: 1.083  loss_cls: 0.2471  loss_box_reg: 0.3418  loss_mask: 0.3882  loss_rpn_cls: 0.05246  loss_rpn_loc: 0.04095    time: 0.3296  last_time: 0.3850  data_time: 0.0034  last_data_time: 0.0029   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:08:09 d2.utils.events]: \u001b[0m eta: 0:39:32  iter: 1939  total_loss: 1.038  loss_cls: 0.2327  loss_box_reg: 0.3197  loss_mask: 0.4024  loss_rpn_cls: 0.05483  loss_rpn_loc: 0.04637    time: 0.3297  last_time: 0.3341  data_time: 0.0035  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:08:16 d2.utils.events]: \u001b[0m eta: 0:39:27  iter: 1959  total_loss: 0.9426  loss_cls: 0.188  loss_box_reg: 0.3067  loss_mask: 0.3739  loss_rpn_cls: 0.03346  loss_rpn_loc: 0.03241    time: 0.3297  last_time: 0.3932  data_time: 0.0036  last_data_time: 0.0042   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:08:22 d2.utils.events]: \u001b[0m eta: 0:39:18  iter: 1979  total_loss: 0.936  loss_cls: 0.1977  loss_box_reg: 0.2961  loss_mask: 0.3895  loss_rpn_cls: 0.03958  loss_rpn_loc: 0.03198    time: 0.3298  last_time: 0.4167  data_time: 0.0034  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:08:29 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:08:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:08:29 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:08:29 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:08:29 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:08:29 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:08:29 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:08:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0765 s/iter. Eval: 0.1633 s/iter. Total: 0.2409 s/iter. ETA=0:00:48\n",
      "\u001b[32m[06/23 13:08:38 d2.evaluation.evaluator]: \u001b[0mInference done 27/213. Dataloading: 0.0013 s/iter. Inference: 0.0842 s/iter. Eval: 0.2384 s/iter. Total: 0.3240 s/iter. ETA=0:01:00\n",
      "\u001b[32m[06/23 13:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 47/213. Dataloading: 0.0013 s/iter. Inference: 0.0814 s/iter. Eval: 0.2091 s/iter. Total: 0.2919 s/iter. ETA=0:00:48\n",
      "\u001b[32m[06/23 13:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 63/213. Dataloading: 0.0013 s/iter. Inference: 0.0817 s/iter. Eval: 0.2194 s/iter. Total: 0.3025 s/iter. ETA=0:00:45\n",
      "\u001b[32m[06/23 13:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 90/213. Dataloading: 0.0020 s/iter. Inference: 0.0786 s/iter. Eval: 0.1854 s/iter. Total: 0.2661 s/iter. ETA=0:00:32\n",
      "\u001b[32m[06/23 13:08:59 d2.evaluation.evaluator]: \u001b[0mInference done 109/213. Dataloading: 0.0020 s/iter. Inference: 0.0779 s/iter. Eval: 0.1906 s/iter. Total: 0.2706 s/iter. ETA=0:00:28\n",
      "\u001b[32m[06/23 13:09:04 d2.evaluation.evaluator]: \u001b[0mInference done 128/213. Dataloading: 0.0019 s/iter. Inference: 0.0780 s/iter. Eval: 0.1937 s/iter. Total: 0.2736 s/iter. ETA=0:00:23\n",
      "\u001b[32m[06/23 13:09:09 d2.evaluation.evaluator]: \u001b[0mInference done 145/213. Dataloading: 0.0018 s/iter. Inference: 0.0780 s/iter. Eval: 0.1963 s/iter. Total: 0.2763 s/iter. ETA=0:00:18\n",
      "\u001b[32m[06/23 13:09:14 d2.evaluation.evaluator]: \u001b[0mInference done 167/213. Dataloading: 0.0017 s/iter. Inference: 0.0774 s/iter. Eval: 0.1910 s/iter. Total: 0.2703 s/iter. ETA=0:00:12\n",
      "\u001b[32m[06/23 13:09:19 d2.evaluation.evaluator]: \u001b[0mInference done 184/213. Dataloading: 0.0017 s/iter. Inference: 0.0777 s/iter. Eval: 0.1938 s/iter. Total: 0.2732 s/iter. ETA=0:00:07\n",
      "\u001b[32m[06/23 13:09:25 d2.evaluation.evaluator]: \u001b[0mInference done 211/213. Dataloading: 0.0016 s/iter. Inference: 0.0759 s/iter. Eval: 0.1847 s/iter. Total: 0.2624 s/iter. ETA=0:00:00\n",
      "\u001b[32m[06/23 13:09:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:54.390530 (0.261493 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:09:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.075647 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:09:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:09:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:09:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.49s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.468\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.161\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.383\n",
      "\u001b[32m[06/23 13:09:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.928 | 46.795 | 6.692  | 4.782 | 16.085 | 18.646 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.58s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.452\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.353\n",
      "\u001b[32m[06/23 13:09:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.523 | 45.217 | 5.257  | 3.683 | 10.825 | 18.171 |\n",
      "\u001b[32m[06/23 13:09:26 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:09:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:09:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:09:26 d2.evaluation.testing]: \u001b[0mcopypaste: 16.9281,46.7953,6.6919,4.7822,16.0845,18.6463\n",
      "\u001b[32m[06/23 13:09:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:09:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:09:26 d2.evaluation.testing]: \u001b[0mcopypaste: 15.5229,45.2169,5.2574,3.6832,10.8245,18.1709\n",
      "\u001b[32m[06/23 13:09:26 d2.utils.events]: \u001b[0m eta: 0:39:10  iter: 1999  total_loss: 0.9265  loss_cls: 0.2058  loss_box_reg: 0.2662  loss_mask: 0.3809  loss_rpn_cls: 0.03874  loss_rpn_loc: 0.02572    time: 0.3299  last_time: 0.3648  data_time: 0.0035  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "val_loss (1.234253078699112, 2000)\n",
      "Iteration 2000: Validation Loss = 1.2343\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_2000.pth\n",
      "\u001b[32m[06/23 13:09:33 d2.utils.events]: \u001b[0m eta: 0:39:01  iter: 2019  total_loss: 1.111  loss_cls: 0.22  loss_box_reg: 0.3329  loss_mask: 0.4021  loss_rpn_cls: 0.04881  loss_rpn_loc: 0.044    time: 0.3300  last_time: 0.3872  data_time: 0.0035  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:09:41 d2.utils.events]: \u001b[0m eta: 0:38:57  iter: 2039  total_loss: 1.093  loss_cls: 0.248  loss_box_reg: 0.3755  loss_mask: 0.3841  loss_rpn_cls: 0.04963  loss_rpn_loc: 0.05179    time: 0.3302  last_time: 0.3925  data_time: 0.0037  last_data_time: 0.0043   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:09:47 d2.utils.events]: \u001b[0m eta: 0:38:50  iter: 2059  total_loss: 1.013  loss_cls: 0.2358  loss_box_reg: 0.3215  loss_mask: 0.3822  loss_rpn_cls: 0.04498  loss_rpn_loc: 0.03671    time: 0.3304  last_time: 0.3196  data_time: 0.0035  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:09:54 d2.utils.events]: \u001b[0m eta: 0:38:46  iter: 2079  total_loss: 1.134  loss_cls: 0.2633  loss_box_reg: 0.3877  loss_mask: 0.3715  loss_rpn_cls: 0.04931  loss_rpn_loc: 0.03933    time: 0.3305  last_time: 0.3599  data_time: 0.0034  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:10:01 d2.utils.events]: \u001b[0m eta: 0:38:39  iter: 2099  total_loss: 0.9947  loss_cls: 0.2157  loss_box_reg: 0.2977  loss_mask: 0.3842  loss_rpn_cls: 0.04421  loss_rpn_loc: 0.0496    time: 0.3305  last_time: 0.3769  data_time: 0.0035  last_data_time: 0.0041   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:10:08 d2.utils.events]: \u001b[0m eta: 0:38:36  iter: 2119  total_loss: 1.101  loss_cls: 0.2532  loss_box_reg: 0.387  loss_mask: 0.3925  loss_rpn_cls: 0.04974  loss_rpn_loc: 0.0502    time: 0.3308  last_time: 0.3961  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:10:15 d2.utils.events]: \u001b[0m eta: 0:38:31  iter: 2139  total_loss: 0.9599  loss_cls: 0.2061  loss_box_reg: 0.3109  loss_mask: 0.3816  loss_rpn_cls: 0.0405  loss_rpn_loc: 0.03385    time: 0.3309  last_time: 0.3589  data_time: 0.0036  last_data_time: 0.0039   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:10:22 d2.utils.events]: \u001b[0m eta: 0:38:19  iter: 2159  total_loss: 1.093  loss_cls: 0.2478  loss_box_reg: 0.3713  loss_mask: 0.3857  loss_rpn_cls: 0.04495  loss_rpn_loc: 0.0429    time: 0.3310  last_time: 0.3216  data_time: 0.0036  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:10:29 d2.utils.events]: \u001b[0m eta: 0:38:14  iter: 2179  total_loss: 1.126  loss_cls: 0.2544  loss_box_reg: 0.3946  loss_mask: 0.3901  loss_rpn_cls: 0.05672  loss_rpn_loc: 0.04894    time: 0.3311  last_time: 0.3377  data_time: 0.0036  last_data_time: 0.0041   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:10:36 d2.utils.events]: \u001b[0m eta: 0:38:10  iter: 2199  total_loss: 0.9903  loss_cls: 0.2135  loss_box_reg: 0.2918  loss_mask: 0.4026  loss_rpn_cls: 0.0289  loss_rpn_loc: 0.03    time: 0.3312  last_time: 0.3143  data_time: 0.0037  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:10:42 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 2219  total_loss: 1.134  loss_cls: 0.2377  loss_box_reg: 0.3351  loss_mask: 0.3787  loss_rpn_cls: 0.0478  loss_rpn_loc: 0.04765    time: 0.3313  last_time: 0.3732  data_time: 0.0037  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:10:49 d2.utils.events]: \u001b[0m eta: 0:37:53  iter: 2239  total_loss: 1.069  loss_cls: 0.224  loss_box_reg: 0.3553  loss_mask: 0.3844  loss_rpn_cls: 0.04192  loss_rpn_loc: 0.04343    time: 0.3313  last_time: 0.2883  data_time: 0.0039  last_data_time: 0.0027   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:10:56 d2.utils.events]: \u001b[0m eta: 0:37:44  iter: 2259  total_loss: 1.003  loss_cls: 0.2143  loss_box_reg: 0.3449  loss_mask: 0.3843  loss_rpn_cls: 0.05368  loss_rpn_loc: 0.04743    time: 0.3313  last_time: 0.3012  data_time: 0.0035  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:11:02 d2.utils.events]: \u001b[0m eta: 0:37:34  iter: 2279  total_loss: 0.9225  loss_cls: 0.1785  loss_box_reg: 0.2771  loss_mask: 0.3883  loss_rpn_cls: 0.05637  loss_rpn_loc: 0.02527    time: 0.3312  last_time: 0.2579  data_time: 0.0036  last_data_time: 0.0041   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:11:09 d2.utils.events]: \u001b[0m eta: 0:37:25  iter: 2299  total_loss: 0.9507  loss_cls: 0.196  loss_box_reg: 0.2579  loss_mask: 0.3894  loss_rpn_cls: 0.04506  loss_rpn_loc: 0.03749    time: 0.3312  last_time: 0.3267  data_time: 0.0035  last_data_time: 0.0040   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:11:16 d2.utils.events]: \u001b[0m eta: 0:37:18  iter: 2319  total_loss: 1.134  loss_cls: 0.2265  loss_box_reg: 0.396  loss_mask: 0.3584  loss_rpn_cls: 0.05264  loss_rpn_loc: 0.03819    time: 0.3313  last_time: 0.4304  data_time: 0.0036  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:11:23 d2.utils.events]: \u001b[0m eta: 0:37:11  iter: 2339  total_loss: 0.9592  loss_cls: 0.2186  loss_box_reg: 0.3092  loss_mask: 0.363  loss_rpn_cls: 0.03941  loss_rpn_loc: 0.028    time: 0.3314  last_time: 0.3093  data_time: 0.0038  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:11:29 d2.utils.events]: \u001b[0m eta: 0:37:04  iter: 2359  total_loss: 1.112  loss_cls: 0.2497  loss_box_reg: 0.3986  loss_mask: 0.3686  loss_rpn_cls: 0.03814  loss_rpn_loc: 0.05287    time: 0.3315  last_time: 0.3560  data_time: 0.0036  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:11:36 d2.utils.events]: \u001b[0m eta: 0:36:57  iter: 2379  total_loss: 1.108  loss_cls: 0.2154  loss_box_reg: 0.3587  loss_mask: 0.3732  loss_rpn_cls: 0.03964  loss_rpn_loc: 0.0411    time: 0.3316  last_time: 0.3117  data_time: 0.0037  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:11:43 d2.utils.events]: \u001b[0m eta: 0:36:49  iter: 2399  total_loss: 0.9217  loss_cls: 0.2031  loss_box_reg: 0.2637  loss_mask: 0.386  loss_rpn_cls: 0.04997  loss_rpn_loc: 0.03205    time: 0.3317  last_time: 0.3357  data_time: 0.0035  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:11:50 d2.utils.events]: \u001b[0m eta: 0:36:39  iter: 2419  total_loss: 1.061  loss_cls: 0.2169  loss_box_reg: 0.3233  loss_mask: 0.3832  loss_rpn_cls: 0.0395  loss_rpn_loc: 0.02544    time: 0.3317  last_time: 0.3371  data_time: 0.0035  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:11:57 d2.utils.events]: \u001b[0m eta: 0:36:33  iter: 2439  total_loss: 1.116  loss_cls: 0.2519  loss_box_reg: 0.3838  loss_mask: 0.3728  loss_rpn_cls: 0.04961  loss_rpn_loc: 0.0352    time: 0.3318  last_time: 0.3762  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:12:04 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 2459  total_loss: 1.115  loss_cls: 0.2461  loss_box_reg: 0.3455  loss_mask: 0.3818  loss_rpn_cls: 0.04759  loss_rpn_loc: 0.04241    time: 0.3319  last_time: 0.4022  data_time: 0.0037  last_data_time: 0.0041   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:12:11 d2.utils.events]: \u001b[0m eta: 0:36:19  iter: 2479  total_loss: 1.065  loss_cls: 0.214  loss_box_reg: 0.3615  loss_mask: 0.3711  loss_rpn_cls: 0.03679  loss_rpn_loc: 0.04504    time: 0.3321  last_time: 0.3322  data_time: 0.0037  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:12:18 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:12:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:12:18 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:12:18 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:12:18 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:12:18 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:12:18 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:12:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:12:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0871 s/iter. Eval: 0.2803 s/iter. Total: 0.3685 s/iter. ETA=0:01:14\n",
      "\u001b[32m[06/23 13:12:27 d2.evaluation.evaluator]: \u001b[0mInference done 21/213. Dataloading: 0.0013 s/iter. Inference: 0.0958 s/iter. Eval: 0.3587 s/iter. Total: 0.4559 s/iter. ETA=0:01:27\n",
      "\u001b[32m[06/23 13:12:32 d2.evaluation.evaluator]: \u001b[0mInference done 37/213. Dataloading: 0.0013 s/iter. Inference: 0.0905 s/iter. Eval: 0.3034 s/iter. Total: 0.3953 s/iter. ETA=0:01:09\n",
      "\u001b[32m[06/23 13:12:37 d2.evaluation.evaluator]: \u001b[0mInference done 48/213. Dataloading: 0.0013 s/iter. Inference: 0.0909 s/iter. Eval: 0.3191 s/iter. Total: 0.4114 s/iter. ETA=0:01:07\n",
      "\u001b[32m[06/23 13:12:43 d2.evaluation.evaluator]: \u001b[0mInference done 61/213. Dataloading: 0.0013 s/iter. Inference: 0.0920 s/iter. Eval: 0.3305 s/iter. Total: 0.4239 s/iter. ETA=0:01:04\n",
      "\u001b[32m[06/23 13:12:48 d2.evaluation.evaluator]: \u001b[0mInference done 78/213. Dataloading: 0.0013 s/iter. Inference: 0.0906 s/iter. Eval: 0.3030 s/iter. Total: 0.3951 s/iter. ETA=0:00:53\n",
      "\u001b[32m[06/23 13:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 96/213. Dataloading: 0.0014 s/iter. Inference: 0.0884 s/iter. Eval: 0.2836 s/iter. Total: 0.3735 s/iter. ETA=0:00:43\n",
      "\u001b[32m[06/23 13:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 109/213. Dataloading: 0.0014 s/iter. Inference: 0.0889 s/iter. Eval: 0.2920 s/iter. Total: 0.3823 s/iter. ETA=0:00:39\n",
      "\u001b[32m[06/23 13:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 122/213. Dataloading: 0.0014 s/iter. Inference: 0.0894 s/iter. Eval: 0.2936 s/iter. Total: 0.3844 s/iter. ETA=0:00:34\n",
      "\u001b[32m[06/23 13:13:09 d2.evaluation.evaluator]: \u001b[0mInference done 134/213. Dataloading: 0.0014 s/iter. Inference: 0.0896 s/iter. Eval: 0.2974 s/iter. Total: 0.3884 s/iter. ETA=0:00:30\n",
      "\u001b[32m[06/23 13:13:15 d2.evaluation.evaluator]: \u001b[0mInference done 147/213. Dataloading: 0.0014 s/iter. Inference: 0.0898 s/iter. Eval: 0.2982 s/iter. Total: 0.3894 s/iter. ETA=0:00:25\n",
      "\u001b[32m[06/23 13:13:20 d2.evaluation.evaluator]: \u001b[0mInference done 163/213. Dataloading: 0.0013 s/iter. Inference: 0.0895 s/iter. Eval: 0.2949 s/iter. Total: 0.3858 s/iter. ETA=0:00:19\n",
      "\u001b[32m[06/23 13:13:26 d2.evaluation.evaluator]: \u001b[0mInference done 176/213. Dataloading: 0.0013 s/iter. Inference: 0.0895 s/iter. Eval: 0.2967 s/iter. Total: 0.3877 s/iter. ETA=0:00:14\n",
      "\u001b[32m[06/23 13:13:31 d2.evaluation.evaluator]: \u001b[0mInference done 192/213. Dataloading: 0.0013 s/iter. Inference: 0.0892 s/iter. Eval: 0.2907 s/iter. Total: 0.3813 s/iter. ETA=0:00:08\n",
      "\u001b[32m[06/23 13:13:36 d2.evaluation.evaluator]: \u001b[0mInference done 208/213. Dataloading: 0.0013 s/iter. Inference: 0.0880 s/iter. Eval: 0.2872 s/iter. Total: 0.3767 s/iter. ETA=0:00:01\n",
      "\u001b[32m[06/23 13:13:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:18.367349 (0.376766 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:13:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.087629 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:13:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:13:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:13:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.71s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.473\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.392\n",
      "\u001b[32m[06/23 13:13:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.337 | 47.321 | 5.934  | 3.735 | 15.380 | 17.837 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.80s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.458\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.369\n",
      "\u001b[32m[06/23 13:13:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.585 | 45.836 | 5.265  | 3.633 | 11.194 | 18.173 |\n",
      "\u001b[32m[06/23 13:13:40 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:13:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:13:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:13:40 d2.evaluation.testing]: \u001b[0mcopypaste: 16.3370,47.3213,5.9343,3.7349,15.3805,17.8370\n",
      "\u001b[32m[06/23 13:13:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:13:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:13:40 d2.evaluation.testing]: \u001b[0mcopypaste: 15.5852,45.8358,5.2648,3.6330,11.1940,18.1725\n",
      "\u001b[32m[06/23 13:13:40 d2.utils.events]: \u001b[0m eta: 0:36:13  iter: 2499  total_loss: 1.155  loss_cls: 0.2443  loss_box_reg: 0.375  loss_mask: 0.3782  loss_rpn_cls: 0.03817  loss_rpn_loc: 0.04757    time: 0.3322  last_time: 0.3185  data_time: 0.0036  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "val_loss (0.630391439422965, 2500)\n",
      "Iteration 2500: Validation Loss = 0.6304\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_2500.pth\n",
      "\u001b[32m[06/23 13:13:47 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 2519  total_loss: 0.9345  loss_cls: 0.1906  loss_box_reg: 0.2716  loss_mask: 0.3697  loss_rpn_cls: 0.03958  loss_rpn_loc: 0.03122    time: 0.3322  last_time: 0.3672  data_time: 0.0033  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:13:54 d2.utils.events]: \u001b[0m eta: 0:35:58  iter: 2539  total_loss: 1.093  loss_cls: 0.2559  loss_box_reg: 0.3681  loss_mask: 0.3911  loss_rpn_cls: 0.03925  loss_rpn_loc: 0.03066    time: 0.3323  last_time: 0.3177  data_time: 0.0035  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:14:01 d2.utils.events]: \u001b[0m eta: 0:35:51  iter: 2559  total_loss: 1.014  loss_cls: 0.2352  loss_box_reg: 0.3766  loss_mask: 0.3496  loss_rpn_cls: 0.0349  loss_rpn_loc: 0.03752    time: 0.3324  last_time: 0.4132  data_time: 0.0034  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:14:08 d2.utils.events]: \u001b[0m eta: 0:35:46  iter: 2579  total_loss: 0.9859  loss_cls: 0.2197  loss_box_reg: 0.3392  loss_mask: 0.3537  loss_rpn_cls: 0.03843  loss_rpn_loc: 0.03852    time: 0.3325  last_time: 0.3371  data_time: 0.0033  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:14:15 d2.utils.events]: \u001b[0m eta: 0:35:39  iter: 2599  total_loss: 0.9893  loss_cls: 0.2105  loss_box_reg: 0.3153  loss_mask: 0.3806  loss_rpn_cls: 0.04881  loss_rpn_loc: 0.02961    time: 0.3326  last_time: 0.3047  data_time: 0.0034  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:14:22 d2.utils.events]: \u001b[0m eta: 0:35:32  iter: 2619  total_loss: 1.19  loss_cls: 0.264  loss_box_reg: 0.4131  loss_mask: 0.3737  loss_rpn_cls: 0.04405  loss_rpn_loc: 0.03914    time: 0.3327  last_time: 0.3044  data_time: 0.0035  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:14:29 d2.utils.events]: \u001b[0m eta: 0:35:25  iter: 2639  total_loss: 0.98  loss_cls: 0.2174  loss_box_reg: 0.3233  loss_mask: 0.3566  loss_rpn_cls: 0.03366  loss_rpn_loc: 0.02587    time: 0.3328  last_time: 0.3560  data_time: 0.0035  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:14:36 d2.utils.events]: \u001b[0m eta: 0:35:18  iter: 2659  total_loss: 1.118  loss_cls: 0.2468  loss_box_reg: 0.3893  loss_mask: 0.3763  loss_rpn_cls: 0.0448  loss_rpn_loc: 0.03554    time: 0.3329  last_time: 0.3771  data_time: 0.0034  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:14:42 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 2679  total_loss: 1.071  loss_cls: 0.2344  loss_box_reg: 0.3636  loss_mask: 0.3686  loss_rpn_cls: 0.04698  loss_rpn_loc: 0.03771    time: 0.3330  last_time: 0.3529  data_time: 0.0034  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:14:49 d2.utils.events]: \u001b[0m eta: 0:35:09  iter: 2699  total_loss: 1.152  loss_cls: 0.2439  loss_box_reg: 0.4209  loss_mask: 0.3927  loss_rpn_cls: 0.04447  loss_rpn_loc: 0.05077    time: 0.3331  last_time: 0.3325  data_time: 0.0034  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:14:56 d2.utils.events]: \u001b[0m eta: 0:35:03  iter: 2719  total_loss: 0.8691  loss_cls: 0.1775  loss_box_reg: 0.2492  loss_mask: 0.3985  loss_rpn_cls: 0.04127  loss_rpn_loc: 0.02526    time: 0.3332  last_time: 0.3446  data_time: 0.0035  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:15:03 d2.utils.events]: \u001b[0m eta: 0:35:00  iter: 2739  total_loss: 1.056  loss_cls: 0.2261  loss_box_reg: 0.3384  loss_mask: 0.3804  loss_rpn_cls: 0.0319  loss_rpn_loc: 0.03145    time: 0.3333  last_time: 0.3425  data_time: 0.0034  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:15:10 d2.utils.events]: \u001b[0m eta: 0:34:56  iter: 2759  total_loss: 1.14  loss_cls: 0.2592  loss_box_reg: 0.3733  loss_mask: 0.3852  loss_rpn_cls: 0.03709  loss_rpn_loc: 0.05076    time: 0.3335  last_time: 0.3499  data_time: 0.0035  last_data_time: 0.0039   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:15:18 d2.utils.events]: \u001b[0m eta: 0:34:53  iter: 2779  total_loss: 1.133  loss_cls: 0.2552  loss_box_reg: 0.3754  loss_mask: 0.3792  loss_rpn_cls: 0.04519  loss_rpn_loc: 0.04881    time: 0.3337  last_time: 0.3588  data_time: 0.0035  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:15:25 d2.utils.events]: \u001b[0m eta: 0:34:47  iter: 2799  total_loss: 1.012  loss_cls: 0.2369  loss_box_reg: 0.3079  loss_mask: 0.383  loss_rpn_cls: 0.03921  loss_rpn_loc: 0.04166    time: 0.3338  last_time: 0.4167  data_time: 0.0035  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:15:32 d2.utils.events]: \u001b[0m eta: 0:34:43  iter: 2819  total_loss: 0.9785  loss_cls: 0.2038  loss_box_reg: 0.2825  loss_mask: 0.3797  loss_rpn_cls: 0.03646  loss_rpn_loc: 0.03835    time: 0.3339  last_time: 0.3273  data_time: 0.0036  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:15:39 d2.utils.events]: \u001b[0m eta: 0:34:36  iter: 2839  total_loss: 1.13  loss_cls: 0.2743  loss_box_reg: 0.4284  loss_mask: 0.3711  loss_rpn_cls: 0.03876  loss_rpn_loc: 0.03956    time: 0.3341  last_time: 0.3145  data_time: 0.0036  last_data_time: 0.0042   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:15:45 d2.utils.events]: \u001b[0m eta: 0:34:27  iter: 2859  total_loss: 1.009  loss_cls: 0.224  loss_box_reg: 0.3016  loss_mask: 0.3828  loss_rpn_cls: 0.03892  loss_rpn_loc: 0.03509    time: 0.3340  last_time: 0.3445  data_time: 0.0037  last_data_time: 0.0040   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:15:52 d2.utils.events]: \u001b[0m eta: 0:34:19  iter: 2879  total_loss: 1.033  loss_cls: 0.2178  loss_box_reg: 0.3199  loss_mask: 0.383  loss_rpn_cls: 0.03849  loss_rpn_loc: 0.04002    time: 0.3340  last_time: 0.3153  data_time: 0.0035  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:15:58 d2.utils.events]: \u001b[0m eta: 0:34:10  iter: 2899  total_loss: 1.072  loss_cls: 0.2481  loss_box_reg: 0.3685  loss_mask: 0.396  loss_rpn_cls: 0.03878  loss_rpn_loc: 0.04062    time: 0.3339  last_time: 0.3701  data_time: 0.0036  last_data_time: 0.0039   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:16:05 d2.utils.events]: \u001b[0m eta: 0:34:02  iter: 2919  total_loss: 0.9829  loss_cls: 0.2304  loss_box_reg: 0.331  loss_mask: 0.3471  loss_rpn_cls: 0.03451  loss_rpn_loc: 0.02757    time: 0.3338  last_time: 0.3049  data_time: 0.0034  last_data_time: 0.0022   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:16:12 d2.utils.events]: \u001b[0m eta: 0:33:55  iter: 2939  total_loss: 1.076  loss_cls: 0.2363  loss_box_reg: 0.3429  loss_mask: 0.4008  loss_rpn_cls: 0.06196  loss_rpn_loc: 0.05715    time: 0.3339  last_time: 0.3262  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:16:18 d2.utils.events]: \u001b[0m eta: 0:33:47  iter: 2959  total_loss: 1.018  loss_cls: 0.2147  loss_box_reg: 0.3326  loss_mask: 0.3745  loss_rpn_cls: 0.03922  loss_rpn_loc: 0.03228    time: 0.3339  last_time: 0.3134  data_time: 0.0035  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:16:25 d2.utils.events]: \u001b[0m eta: 0:33:38  iter: 2979  total_loss: 1.054  loss_cls: 0.2365  loss_box_reg: 0.3103  loss_mask: 0.3749  loss_rpn_cls: 0.046  loss_rpn_loc: 0.0367    time: 0.3338  last_time: 0.2846  data_time: 0.0036  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:16:32 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:16:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:16:32 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:16:32 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:16:32 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:16:32 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:16:32 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:16:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:16:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0773 s/iter. Eval: 0.2043 s/iter. Total: 0.2827 s/iter. ETA=0:00:57\n",
      "\u001b[32m[06/23 13:16:40 d2.evaluation.evaluator]: \u001b[0mInference done 25/213. Dataloading: 0.0013 s/iter. Inference: 0.0831 s/iter. Eval: 0.2528 s/iter. Total: 0.3373 s/iter. ETA=0:01:03\n",
      "\u001b[32m[06/23 13:16:45 d2.evaluation.evaluator]: \u001b[0mInference done 42/213. Dataloading: 0.0014 s/iter. Inference: 0.0826 s/iter. Eval: 0.2489 s/iter. Total: 0.3330 s/iter. ETA=0:00:56\n",
      "\u001b[32m[06/23 13:16:50 d2.evaluation.evaluator]: \u001b[0mInference done 59/213. Dataloading: 0.0014 s/iter. Inference: 0.0824 s/iter. Eval: 0.2415 s/iter. Total: 0.3253 s/iter. ETA=0:00:50\n",
      "\u001b[32m[06/23 13:16:56 d2.evaluation.evaluator]: \u001b[0mInference done 77/213. Dataloading: 0.0014 s/iter. Inference: 0.0821 s/iter. Eval: 0.2312 s/iter. Total: 0.3148 s/iter. ETA=0:00:42\n",
      "\u001b[32m[06/23 13:17:01 d2.evaluation.evaluator]: \u001b[0mInference done 100/213. Dataloading: 0.0014 s/iter. Inference: 0.0799 s/iter. Eval: 0.2134 s/iter. Total: 0.2948 s/iter. ETA=0:00:33\n",
      "\u001b[32m[06/23 13:17:06 d2.evaluation.evaluator]: \u001b[0mInference done 111/213. Dataloading: 0.0014 s/iter. Inference: 0.0810 s/iter. Eval: 0.2299 s/iter. Total: 0.3123 s/iter. ETA=0:00:31\n",
      "\u001b[32m[06/23 13:17:11 d2.evaluation.evaluator]: \u001b[0mInference done 128/213. Dataloading: 0.0014 s/iter. Inference: 0.0811 s/iter. Eval: 0.2281 s/iter. Total: 0.3106 s/iter. ETA=0:00:26\n",
      "\u001b[32m[06/23 13:17:17 d2.evaluation.evaluator]: \u001b[0mInference done 145/213. Dataloading: 0.0014 s/iter. Inference: 0.0812 s/iter. Eval: 0.2299 s/iter. Total: 0.3125 s/iter. ETA=0:00:21\n",
      "\u001b[32m[06/23 13:17:22 d2.evaluation.evaluator]: \u001b[0mInference done 163/213. Dataloading: 0.0014 s/iter. Inference: 0.0810 s/iter. Eval: 0.2272 s/iter. Total: 0.3097 s/iter. ETA=0:00:15\n",
      "\u001b[32m[06/23 13:17:27 d2.evaluation.evaluator]: \u001b[0mInference done 178/213. Dataloading: 0.0014 s/iter. Inference: 0.0809 s/iter. Eval: 0.2294 s/iter. Total: 0.3118 s/iter. ETA=0:00:10\n",
      "\u001b[32m[06/23 13:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 198/213. Dataloading: 0.0014 s/iter. Inference: 0.0806 s/iter. Eval: 0.2252 s/iter. Total: 0.3072 s/iter. ETA=0:00:04\n",
      "\u001b[32m[06/23 13:17:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:02.752200 (0.301693 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:17:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.079095 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:17:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:17:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:17:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.57s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.508\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
      "\u001b[32m[06/23 13:17:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.027 | 50.827 | 7.629  | 4.734 | 17.047 | 21.082 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.80s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.488\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.370\n",
      "\u001b[32m[06/23 13:17:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.805 | 48.755 | 6.683  | 3.921 | 11.246 | 19.742 |\n",
      "\u001b[32m[06/23 13:17:37 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:17:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:17:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:17:37 d2.evaluation.testing]: \u001b[0mcopypaste: 19.0270,50.8272,7.6287,4.7340,17.0467,21.0825\n",
      "\u001b[32m[06/23 13:17:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:17:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:17:37 d2.evaluation.testing]: \u001b[0mcopypaste: 16.8046,48.7548,6.6827,3.9212,11.2456,19.7424\n",
      "\u001b[32m[06/23 13:17:37 d2.utils.events]: \u001b[0m eta: 0:33:31  iter: 2999  total_loss: 1.012  loss_cls: 0.212  loss_box_reg: 0.3412  loss_mask: 0.3824  loss_rpn_cls: 0.04178  loss_rpn_loc: 0.04483    time: 0.3338  last_time: 0.2976  data_time: 0.0036  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "val_loss (1.1893046200275421, 3000)\n",
      "Iteration 3000: Validation Loss = 1.1893\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_3000.pth\n",
      "\u001b[32m[06/23 13:17:44 d2.utils.events]: \u001b[0m eta: 0:33:25  iter: 3019  total_loss: 1.099  loss_cls: 0.2447  loss_box_reg: 0.3413  loss_mask: 0.3658  loss_rpn_cls: 0.02912  loss_rpn_loc: 0.0428    time: 0.3338  last_time: 0.3185  data_time: 0.0037  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:17:51 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 3039  total_loss: 0.9122  loss_cls: 0.1861  loss_box_reg: 0.2955  loss_mask: 0.3842  loss_rpn_cls: 0.03607  loss_rpn_loc: 0.02713    time: 0.3337  last_time: 0.3082  data_time: 0.0036  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:17:57 d2.utils.events]: \u001b[0m eta: 0:33:07  iter: 3059  total_loss: 1.034  loss_cls: 0.2284  loss_box_reg: 0.3267  loss_mask: 0.349  loss_rpn_cls: 0.03086  loss_rpn_loc: 0.03562    time: 0.3336  last_time: 0.3030  data_time: 0.0036  last_data_time: 0.0040   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:18:04 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 3079  total_loss: 1.107  loss_cls: 0.2441  loss_box_reg: 0.379  loss_mask: 0.3553  loss_rpn_cls: 0.04893  loss_rpn_loc: 0.046    time: 0.3336  last_time: 0.3594  data_time: 0.0037  last_data_time: 0.0045   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:18:11 d2.utils.events]: \u001b[0m eta: 0:32:53  iter: 3099  total_loss: 1.012  loss_cls: 0.195  loss_box_reg: 0.3563  loss_mask: 0.3655  loss_rpn_cls: 0.0344  loss_rpn_loc: 0.03704    time: 0.3336  last_time: 0.3232  data_time: 0.0037  last_data_time: 0.0039   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:18:17 d2.utils.events]: \u001b[0m eta: 0:32:43  iter: 3119  total_loss: 1.079  loss_cls: 0.1988  loss_box_reg: 0.3731  loss_mask: 0.3912  loss_rpn_cls: 0.03875  loss_rpn_loc: 0.03468    time: 0.3335  last_time: 0.3713  data_time: 0.0036  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:18:24 d2.utils.events]: \u001b[0m eta: 0:32:35  iter: 3139  total_loss: 1.024  loss_cls: 0.2253  loss_box_reg: 0.335  loss_mask: 0.3615  loss_rpn_cls: 0.03712  loss_rpn_loc: 0.03325    time: 0.3336  last_time: 0.3518  data_time: 0.0038  last_data_time: 0.0047   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:18:30 d2.utils.events]: \u001b[0m eta: 0:32:26  iter: 3159  total_loss: 0.8604  loss_cls: 0.2024  loss_box_reg: 0.2335  loss_mask: 0.364  loss_rpn_cls: 0.0426  loss_rpn_loc: 0.02242    time: 0.3335  last_time: 0.3104  data_time: 0.0035  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:18:37 d2.utils.events]: \u001b[0m eta: 0:32:19  iter: 3179  total_loss: 0.9237  loss_cls: 0.1998  loss_box_reg: 0.2995  loss_mask: 0.3672  loss_rpn_cls: 0.02337  loss_rpn_loc: 0.03038    time: 0.3334  last_time: 0.3823  data_time: 0.0035  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:18:43 d2.utils.events]: \u001b[0m eta: 0:32:12  iter: 3199  total_loss: 1.01  loss_cls: 0.2093  loss_box_reg: 0.347  loss_mask: 0.3729  loss_rpn_cls: 0.02701  loss_rpn_loc: 0.03382    time: 0.3334  last_time: 0.3488  data_time: 0.0035  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:18:50 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 3219  total_loss: 1.214  loss_cls: 0.2941  loss_box_reg: 0.4098  loss_mask: 0.3862  loss_rpn_cls: 0.05417  loss_rpn_loc: 0.05247    time: 0.3335  last_time: 0.3212  data_time: 0.0037  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:18:57 d2.utils.events]: \u001b[0m eta: 0:32:00  iter: 3239  total_loss: 1.066  loss_cls: 0.2288  loss_box_reg: 0.3994  loss_mask: 0.3799  loss_rpn_cls: 0.02777  loss_rpn_loc: 0.03126    time: 0.3335  last_time: 0.3300  data_time: 0.0037  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:19:03 d2.utils.events]: \u001b[0m eta: 0:31:54  iter: 3259  total_loss: 1.029  loss_cls: 0.2094  loss_box_reg: 0.3472  loss_mask: 0.3624  loss_rpn_cls: 0.05091  loss_rpn_loc: 0.05162    time: 0.3335  last_time: 0.1966  data_time: 0.0035  last_data_time: 0.0029   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:19:10 d2.utils.events]: \u001b[0m eta: 0:31:49  iter: 3279  total_loss: 0.9864  loss_cls: 0.2295  loss_box_reg: 0.351  loss_mask: 0.3751  loss_rpn_cls: 0.03642  loss_rpn_loc: 0.02881    time: 0.3334  last_time: 0.3816  data_time: 0.0036  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:19:17 d2.utils.events]: \u001b[0m eta: 0:31:41  iter: 3299  total_loss: 0.9526  loss_cls: 0.1909  loss_box_reg: 0.2945  loss_mask: 0.3678  loss_rpn_cls: 0.03168  loss_rpn_loc: 0.02379    time: 0.3334  last_time: 0.3240  data_time: 0.0038  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:19:24 d2.utils.events]: \u001b[0m eta: 0:31:37  iter: 3319  total_loss: 1.102  loss_cls: 0.2579  loss_box_reg: 0.3766  loss_mask: 0.3496  loss_rpn_cls: 0.03285  loss_rpn_loc: 0.03949    time: 0.3335  last_time: 0.3602  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:19:30 d2.utils.events]: \u001b[0m eta: 0:31:25  iter: 3339  total_loss: 1.108  loss_cls: 0.2612  loss_box_reg: 0.3855  loss_mask: 0.3898  loss_rpn_cls: 0.05499  loss_rpn_loc: 0.05205    time: 0.3335  last_time: 0.2961  data_time: 0.0036  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:19:37 d2.utils.events]: \u001b[0m eta: 0:31:19  iter: 3359  total_loss: 1.105  loss_cls: 0.2582  loss_box_reg: 0.4255  loss_mask: 0.38  loss_rpn_cls: 0.04224  loss_rpn_loc: 0.04716    time: 0.3335  last_time: 0.2907  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:19:44 d2.utils.events]: \u001b[0m eta: 0:31:11  iter: 3379  total_loss: 1.046  loss_cls: 0.2604  loss_box_reg: 0.3435  loss_mask: 0.3582  loss_rpn_cls: 0.03395  loss_rpn_loc: 0.03237    time: 0.3335  last_time: 0.3572  data_time: 0.0036  last_data_time: 0.0039   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:19:51 d2.utils.events]: \u001b[0m eta: 0:31:07  iter: 3399  total_loss: 1.139  loss_cls: 0.2849  loss_box_reg: 0.4077  loss_mask: 0.3695  loss_rpn_cls: 0.03631  loss_rpn_loc: 0.04283    time: 0.3336  last_time: 0.3534  data_time: 0.0036  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:19:58 d2.utils.events]: \u001b[0m eta: 0:31:04  iter: 3419  total_loss: 1.051  loss_cls: 0.2466  loss_box_reg: 0.3769  loss_mask: 0.3582  loss_rpn_cls: 0.03776  loss_rpn_loc: 0.03635    time: 0.3336  last_time: 0.3402  data_time: 0.0035  last_data_time: 0.0028   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:20:04 d2.utils.events]: \u001b[0m eta: 0:30:58  iter: 3439  total_loss: 1.121  loss_cls: 0.2585  loss_box_reg: 0.3786  loss_mask: 0.3601  loss_rpn_cls: 0.03052  loss_rpn_loc: 0.04713    time: 0.3337  last_time: 0.3785  data_time: 0.0036  last_data_time: 0.0044   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:20:11 d2.utils.events]: \u001b[0m eta: 0:30:50  iter: 3459  total_loss: 0.9825  loss_cls: 0.2257  loss_box_reg: 0.3463  loss_mask: 0.3563  loss_rpn_cls: 0.03123  loss_rpn_loc: 0.03308    time: 0.3336  last_time: 0.4014  data_time: 0.0035  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:20:18 d2.utils.events]: \u001b[0m eta: 0:30:40  iter: 3479  total_loss: 0.865  loss_cls: 0.1655  loss_box_reg: 0.2697  loss_mask: 0.3988  loss_rpn_cls: 0.03441  loss_rpn_loc: 0.02394    time: 0.3336  last_time: 0.3815  data_time: 0.0037  last_data_time: 0.0041   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:20:24 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:20:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:20:24 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:20:24 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:20:24 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:20:24 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:20:24 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:20:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:20:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0787 s/iter. Eval: 0.2056 s/iter. Total: 0.2855 s/iter. ETA=0:00:57\n",
      "\u001b[32m[06/23 13:20:33 d2.evaluation.evaluator]: \u001b[0mInference done 25/213. Dataloading: 0.0013 s/iter. Inference: 0.0847 s/iter. Eval: 0.2549 s/iter. Total: 0.3411 s/iter. ETA=0:01:04\n",
      "\u001b[32m[06/23 13:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 42/213. Dataloading: 0.0013 s/iter. Inference: 0.0827 s/iter. Eval: 0.2405 s/iter. Total: 0.3246 s/iter. ETA=0:00:55\n",
      "\u001b[32m[06/23 13:20:43 d2.evaluation.evaluator]: \u001b[0mInference done 59/213. Dataloading: 0.0013 s/iter. Inference: 0.0823 s/iter. Eval: 0.2340 s/iter. Total: 0.3177 s/iter. ETA=0:00:48\n",
      "\u001b[32m[06/23 13:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 76/213. Dataloading: 0.0013 s/iter. Inference: 0.0826 s/iter. Eval: 0.2336 s/iter. Total: 0.3177 s/iter. ETA=0:00:43\n",
      "\u001b[32m[06/23 13:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 100/213. Dataloading: 0.0014 s/iter. Inference: 0.0798 s/iter. Eval: 0.2116 s/iter. Total: 0.2930 s/iter. ETA=0:00:33\n",
      "\u001b[32m[06/23 13:20:59 d2.evaluation.evaluator]: \u001b[0mInference done 111/213. Dataloading: 0.0014 s/iter. Inference: 0.0809 s/iter. Eval: 0.2274 s/iter. Total: 0.3097 s/iter. ETA=0:00:31\n",
      "\u001b[32m[06/23 13:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 128/213. Dataloading: 0.0014 s/iter. Inference: 0.0811 s/iter. Eval: 0.2261 s/iter. Total: 0.3087 s/iter. ETA=0:00:26\n",
      "\u001b[32m[06/23 13:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 145/213. Dataloading: 0.0014 s/iter. Inference: 0.0812 s/iter. Eval: 0.2265 s/iter. Total: 0.3091 s/iter. ETA=0:00:21\n",
      "\u001b[32m[06/23 13:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 165/213. Dataloading: 0.0014 s/iter. Inference: 0.0804 s/iter. Eval: 0.2209 s/iter. Total: 0.3028 s/iter. ETA=0:00:14\n",
      "\u001b[32m[06/23 13:21:20 d2.evaluation.evaluator]: \u001b[0mInference done 181/213. Dataloading: 0.0014 s/iter. Inference: 0.0807 s/iter. Eval: 0.2235 s/iter. Total: 0.3056 s/iter. ETA=0:00:09\n",
      "\u001b[32m[06/23 13:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 206/213. Dataloading: 0.0014 s/iter. Inference: 0.0792 s/iter. Eval: 0.2157 s/iter. Total: 0.2964 s/iter. ETA=0:00:02\n",
      "\u001b[32m[06/23 13:21:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:01.800674 (0.297119 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:21:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.078885 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:21:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:21:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:21:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.56s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.519\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
      "\u001b[32m[06/23 13:21:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.313 | 51.892 | 9.168  | 5.635 | 17.536 | 21.375 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.64s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.492\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
      "\u001b[32m[06/23 13:21:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.128 | 49.156 | 8.664  | 4.421 | 12.366 | 21.259 |\n",
      "\u001b[32m[06/23 13:21:29 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:21:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:21:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:21:29 d2.evaluation.testing]: \u001b[0mcopypaste: 19.3127,51.8919,9.1681,5.6347,17.5361,21.3751\n",
      "\u001b[32m[06/23 13:21:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:21:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:21:29 d2.evaluation.testing]: \u001b[0mcopypaste: 18.1282,49.1561,8.6639,4.4213,12.3661,21.2590\n",
      "\u001b[32m[06/23 13:21:29 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 3499  total_loss: 0.8919  loss_cls: 0.2051  loss_box_reg: 0.2857  loss_mask: 0.3456  loss_rpn_cls: 0.03007  loss_rpn_loc: 0.04181    time: 0.3336  last_time: 0.3748  data_time: 0.0036  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "val_loss (1.2844120264053345, 3500)\n",
      "Iteration 3500: Validation Loss = 1.2844\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_3500.pth\n",
      "\u001b[32m[06/23 13:21:36 d2.utils.events]: \u001b[0m eta: 0:30:25  iter: 3519  total_loss: 1.019  loss_cls: 0.2189  loss_box_reg: 0.3327  loss_mask: 0.3655  loss_rpn_cls: 0.03244  loss_rpn_loc: 0.04246    time: 0.3337  last_time: 0.3073  data_time: 0.0036  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:21:43 d2.utils.events]: \u001b[0m eta: 0:30:17  iter: 3539  total_loss: 0.9714  loss_cls: 0.2432  loss_box_reg: 0.3401  loss_mask: 0.3358  loss_rpn_cls: 0.02918  loss_rpn_loc: 0.03117    time: 0.3337  last_time: 0.3457  data_time: 0.0035  last_data_time: 0.0029   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:21:50 d2.utils.events]: \u001b[0m eta: 0:30:11  iter: 3559  total_loss: 1.066  loss_cls: 0.2323  loss_box_reg: 0.3817  loss_mask: 0.3858  loss_rpn_cls: 0.04501  loss_rpn_loc: 0.03085    time: 0.3337  last_time: 0.2832  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:21:57 d2.utils.events]: \u001b[0m eta: 0:30:01  iter: 3579  total_loss: 1.061  loss_cls: 0.2484  loss_box_reg: 0.3867  loss_mask: 0.3681  loss_rpn_cls: 0.0315  loss_rpn_loc: 0.03518    time: 0.3337  last_time: 0.3576  data_time: 0.0037  last_data_time: 0.0042   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:22:04 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 3599  total_loss: 1.208  loss_cls: 0.2658  loss_box_reg: 0.4477  loss_mask: 0.3828  loss_rpn_cls: 0.03233  loss_rpn_loc: 0.04574    time: 0.3338  last_time: 0.3876  data_time: 0.0038  last_data_time: 0.0042   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:22:10 d2.utils.events]: \u001b[0m eta: 0:29:47  iter: 3619  total_loss: 0.9581  loss_cls: 0.2215  loss_box_reg: 0.315  loss_mask: 0.3725  loss_rpn_cls: 0.03507  loss_rpn_loc: 0.02496    time: 0.3338  last_time: 0.2848  data_time: 0.0037  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:22:17 d2.utils.events]: \u001b[0m eta: 0:29:39  iter: 3639  total_loss: 1.018  loss_cls: 0.2176  loss_box_reg: 0.3322  loss_mask: 0.3708  loss_rpn_cls: 0.03215  loss_rpn_loc: 0.03445    time: 0.3338  last_time: 0.3422  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:22:23 d2.utils.events]: \u001b[0m eta: 0:29:28  iter: 3659  total_loss: 0.9856  loss_cls: 0.2061  loss_box_reg: 0.3334  loss_mask: 0.3585  loss_rpn_cls: 0.02964  loss_rpn_loc: 0.03867    time: 0.3337  last_time: 0.3058  data_time: 0.0035  last_data_time: 0.0043   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:22:30 d2.utils.events]: \u001b[0m eta: 0:29:19  iter: 3679  total_loss: 1.004  loss_cls: 0.2224  loss_box_reg: 0.3138  loss_mask: 0.3573  loss_rpn_cls: 0.04021  loss_rpn_loc: 0.04026    time: 0.3338  last_time: 0.3555  data_time: 0.0041  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:22:37 d2.utils.events]: \u001b[0m eta: 0:29:12  iter: 3699  total_loss: 1.078  loss_cls: 0.2655  loss_box_reg: 0.4287  loss_mask: 0.3637  loss_rpn_cls: 0.0361  loss_rpn_loc: 0.03454    time: 0.3338  last_time: 0.2992  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:22:44 d2.utils.events]: \u001b[0m eta: 0:29:05  iter: 3719  total_loss: 0.9867  loss_cls: 0.2191  loss_box_reg: 0.3532  loss_mask: 0.3801  loss_rpn_cls: 0.03374  loss_rpn_loc: 0.03676    time: 0.3338  last_time: 0.3495  data_time: 0.0036  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:22:51 d2.utils.events]: \u001b[0m eta: 0:28:55  iter: 3739  total_loss: 1.16  loss_cls: 0.2549  loss_box_reg: 0.3945  loss_mask: 0.3806  loss_rpn_cls: 0.03947  loss_rpn_loc: 0.04916    time: 0.3339  last_time: 0.2756  data_time: 0.0038  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:22:57 d2.utils.events]: \u001b[0m eta: 0:28:48  iter: 3759  total_loss: 0.9707  loss_cls: 0.2187  loss_box_reg: 0.324  loss_mask: 0.3252  loss_rpn_cls: 0.03014  loss_rpn_loc: 0.03395    time: 0.3339  last_time: 0.4055  data_time: 0.0034  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:23:04 d2.utils.events]: \u001b[0m eta: 0:28:40  iter: 3779  total_loss: 0.9729  loss_cls: 0.2169  loss_box_reg: 0.3231  loss_mask: 0.3628  loss_rpn_cls: 0.02557  loss_rpn_loc: 0.02951    time: 0.3339  last_time: 0.3383  data_time: 0.0035  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:23:11 d2.utils.events]: \u001b[0m eta: 0:28:32  iter: 3799  total_loss: 0.9234  loss_cls: 0.1799  loss_box_reg: 0.2787  loss_mask: 0.3783  loss_rpn_cls: 0.02824  loss_rpn_loc: 0.02426    time: 0.3339  last_time: 0.3606  data_time: 0.0037  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:23:18 d2.utils.events]: \u001b[0m eta: 0:28:25  iter: 3819  total_loss: 1.001  loss_cls: 0.2277  loss_box_reg: 0.3522  loss_mask: 0.3471  loss_rpn_cls: 0.0348  loss_rpn_loc: 0.04262    time: 0.3340  last_time: 0.3210  data_time: 0.0037  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:23:25 d2.utils.events]: \u001b[0m eta: 0:28:18  iter: 3839  total_loss: 1.04  loss_cls: 0.2384  loss_box_reg: 0.3431  loss_mask: 0.3646  loss_rpn_cls: 0.02802  loss_rpn_loc: 0.03175    time: 0.3340  last_time: 0.3409  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:23:31 d2.utils.events]: \u001b[0m eta: 0:28:12  iter: 3859  total_loss: 1.157  loss_cls: 0.2827  loss_box_reg: 0.4017  loss_mask: 0.3559  loss_rpn_cls: 0.03828  loss_rpn_loc: 0.03317    time: 0.3340  last_time: 0.2885  data_time: 0.0035  last_data_time: 0.0039   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:23:38 d2.utils.events]: \u001b[0m eta: 0:28:06  iter: 3879  total_loss: 1.099  loss_cls: 0.2355  loss_box_reg: 0.3827  loss_mask: 0.3615  loss_rpn_cls: 0.03132  loss_rpn_loc: 0.02981    time: 0.3340  last_time: 0.3270  data_time: 0.0036  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:23:44 d2.utils.events]: \u001b[0m eta: 0:27:59  iter: 3899  total_loss: 0.8732  loss_cls: 0.1892  loss_box_reg: 0.2824  loss_mask: 0.3358  loss_rpn_cls: 0.02553  loss_rpn_loc: 0.02657    time: 0.3340  last_time: 0.2826  data_time: 0.0036  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:23:51 d2.utils.events]: \u001b[0m eta: 0:27:52  iter: 3919  total_loss: 1.058  loss_cls: 0.2207  loss_box_reg: 0.3114  loss_mask: 0.3407  loss_rpn_cls: 0.02393  loss_rpn_loc: 0.04011    time: 0.3339  last_time: 0.3007  data_time: 0.0036  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:23:58 d2.utils.events]: \u001b[0m eta: 0:27:46  iter: 3939  total_loss: 0.9213  loss_cls: 0.1868  loss_box_reg: 0.2537  loss_mask: 0.3564  loss_rpn_cls: 0.03178  loss_rpn_loc: 0.03197    time: 0.3339  last_time: 0.3799  data_time: 0.0036  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:24:04 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 3959  total_loss: 1.007  loss_cls: 0.1738  loss_box_reg: 0.294  loss_mask: 0.3648  loss_rpn_cls: 0.03425  loss_rpn_loc: 0.03655    time: 0.3339  last_time: 0.2684  data_time: 0.0036  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:24:11 d2.utils.events]: \u001b[0m eta: 0:27:31  iter: 3979  total_loss: 0.9856  loss_cls: 0.2254  loss_box_reg: 0.3075  loss_mask: 0.3499  loss_rpn_cls: 0.03482  loss_rpn_loc: 0.04059    time: 0.3338  last_time: 0.2942  data_time: 0.0036  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:24:17 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:24:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:24:17 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:24:17 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:24:17 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:24:17 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:24:17 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:24:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0013 s/iter. Inference: 0.0845 s/iter. Eval: 0.2709 s/iter. Total: 0.3567 s/iter. ETA=0:01:12\n",
      "\u001b[32m[06/23 13:24:26 d2.evaluation.evaluator]: \u001b[0mInference done 24/213. Dataloading: 0.0013 s/iter. Inference: 0.0890 s/iter. Eval: 0.2986 s/iter. Total: 0.3891 s/iter. ETA=0:01:13\n",
      "\u001b[32m[06/23 13:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 41/213. Dataloading: 0.0013 s/iter. Inference: 0.0855 s/iter. Eval: 0.2621 s/iter. Total: 0.3491 s/iter. ETA=0:01:00\n",
      "\u001b[32m[06/23 13:24:37 d2.evaluation.evaluator]: \u001b[0mInference done 51/213. Dataloading: 0.0013 s/iter. Inference: 0.0914 s/iter. Eval: 0.2912 s/iter. Total: 0.3840 s/iter. ETA=0:01:02\n",
      "\u001b[32m[06/23 13:24:42 d2.evaluation.evaluator]: \u001b[0mInference done 66/213. Dataloading: 0.0013 s/iter. Inference: 0.0900 s/iter. Eval: 0.2822 s/iter. Total: 0.3736 s/iter. ETA=0:00:54\n",
      "\u001b[32m[06/23 13:24:47 d2.evaluation.evaluator]: \u001b[0mInference done 86/213. Dataloading: 0.0013 s/iter. Inference: 0.0864 s/iter. Eval: 0.2558 s/iter. Total: 0.3436 s/iter. ETA=0:00:43\n",
      "\u001b[32m[06/23 13:24:52 d2.evaluation.evaluator]: \u001b[0mInference done 104/213. Dataloading: 0.0013 s/iter. Inference: 0.0851 s/iter. Eval: 0.2502 s/iter. Total: 0.3368 s/iter. ETA=0:00:36\n",
      "\u001b[32m[06/23 13:24:57 d2.evaluation.evaluator]: \u001b[0mInference done 115/213. Dataloading: 0.0014 s/iter. Inference: 0.0861 s/iter. Eval: 0.2624 s/iter. Total: 0.3499 s/iter. ETA=0:00:34\n",
      "\u001b[32m[06/23 13:25:02 d2.evaluation.evaluator]: \u001b[0mInference done 131/213. Dataloading: 0.0014 s/iter. Inference: 0.0856 s/iter. Eval: 0.2586 s/iter. Total: 0.3456 s/iter. ETA=0:00:28\n",
      "\u001b[32m[06/23 13:25:07 d2.evaluation.evaluator]: \u001b[0mInference done 145/213. Dataloading: 0.0014 s/iter. Inference: 0.0858 s/iter. Eval: 0.2599 s/iter. Total: 0.3471 s/iter. ETA=0:00:23\n",
      "\u001b[32m[06/23 13:25:13 d2.evaluation.evaluator]: \u001b[0mInference done 163/213. Dataloading: 0.0014 s/iter. Inference: 0.0853 s/iter. Eval: 0.2571 s/iter. Total: 0.3439 s/iter. ETA=0:00:17\n",
      "\u001b[32m[06/23 13:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 178/213. Dataloading: 0.0014 s/iter. Inference: 0.0850 s/iter. Eval: 0.2582 s/iter. Total: 0.3447 s/iter. ETA=0:00:12\n",
      "\u001b[32m[06/23 13:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 196/213. Dataloading: 0.0014 s/iter. Inference: 0.0846 s/iter. Eval: 0.2533 s/iter. Total: 0.3393 s/iter. ETA=0:00:05\n",
      "\u001b[32m[06/23 13:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 211/213. Dataloading: 0.0014 s/iter. Inference: 0.0838 s/iter. Eval: 0.2554 s/iter. Total: 0.3407 s/iter. ETA=0:00:00\n",
      "\u001b[32m[06/23 13:25:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:10.852022 (0.340635 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:25:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.083589 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:25:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:25:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:25:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.66s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.510\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389\n",
      "\u001b[32m[06/23 13:25:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.434 | 51.040 | 5.754  | 4.669 | 16.879 | 18.841 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.74s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.481\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.360\n",
      "\u001b[32m[06/23 13:25:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.703 | 48.060 | 4.786  | 3.373 | 11.756 | 18.037 |\n",
      "\u001b[32m[06/23 13:25:32 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:25:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:25:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:25:32 d2.evaluation.testing]: \u001b[0mcopypaste: 17.4340,51.0399,5.7540,4.6695,16.8792,18.8409\n",
      "\u001b[32m[06/23 13:25:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:25:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:25:32 d2.evaluation.testing]: \u001b[0mcopypaste: 15.7029,48.0603,4.7862,3.3730,11.7563,18.0369\n",
      "\u001b[32m[06/23 13:25:32 d2.utils.events]: \u001b[0m eta: 0:27:22  iter: 3999  total_loss: 1.084  loss_cls: 0.2274  loss_box_reg: 0.3556  loss_mask: 0.3621  loss_rpn_cls: 0.03845  loss_rpn_loc: 0.03681    time: 0.3338  last_time: 0.3406  data_time: 0.0034  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "val_loss (1.2771081142127514, 4000)\n",
      "Iteration 4000: Validation Loss = 1.2771\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_4000.pth\n",
      "Early stopping triggered. Stopping training.\n",
      "\u001b[32m[06/23 13:25:39 d2.utils.events]: \u001b[0m eta: 0:27:19  iter: 4019  total_loss: 0.9607  loss_cls: 0.2159  loss_box_reg: 0.3417  loss_mask: 0.3449  loss_rpn_cls: 0.0291  loss_rpn_loc: 0.02817    time: 0.3338  last_time: 0.3615  data_time: 0.0036  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:25:45 d2.utils.events]: \u001b[0m eta: 0:27:14  iter: 4039  total_loss: 1.034  loss_cls: 0.2107  loss_box_reg: 0.3458  loss_mask: 0.362  loss_rpn_cls: 0.03005  loss_rpn_loc: 0.04055    time: 0.3338  last_time: 0.2600  data_time: 0.0036  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:25:52 d2.utils.events]: \u001b[0m eta: 0:27:07  iter: 4059  total_loss: 0.978  loss_cls: 0.216  loss_box_reg: 0.3222  loss_mask: 0.3459  loss_rpn_cls: 0.0328  loss_rpn_loc: 0.04343    time: 0.3338  last_time: 0.3057  data_time: 0.0035  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:25:59 d2.utils.events]: \u001b[0m eta: 0:27:00  iter: 4079  total_loss: 1.025  loss_cls: 0.2353  loss_box_reg: 0.3677  loss_mask: 0.3549  loss_rpn_cls: 0.03921  loss_rpn_loc: 0.0281    time: 0.3338  last_time: 0.3141  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:26:05 d2.utils.events]: \u001b[0m eta: 0:26:53  iter: 4099  total_loss: 0.96  loss_cls: 0.2101  loss_box_reg: 0.3197  loss_mask: 0.3487  loss_rpn_cls: 0.02612  loss_rpn_loc: 0.02951    time: 0.3338  last_time: 0.3381  data_time: 0.0035  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:26:12 d2.utils.events]: \u001b[0m eta: 0:26:47  iter: 4119  total_loss: 1.086  loss_cls: 0.2464  loss_box_reg: 0.392  loss_mask: 0.3697  loss_rpn_cls: 0.03036  loss_rpn_loc: 0.04028    time: 0.3338  last_time: 0.2958  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:26:19 d2.utils.events]: \u001b[0m eta: 0:26:40  iter: 4139  total_loss: 0.9465  loss_cls: 0.2252  loss_box_reg: 0.3087  loss_mask: 0.361  loss_rpn_cls: 0.02673  loss_rpn_loc: 0.02453    time: 0.3338  last_time: 0.2905  data_time: 0.0037  last_data_time: 0.0055   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:26:25 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 4159  total_loss: 1.089  loss_cls: 0.2476  loss_box_reg: 0.3552  loss_mask: 0.3876  loss_rpn_cls: 0.03319  loss_rpn_loc: 0.03872    time: 0.3338  last_time: 0.3128  data_time: 0.0038  last_data_time: 0.0040   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:26:32 d2.utils.events]: \u001b[0m eta: 0:26:29  iter: 4179  total_loss: 0.9537  loss_cls: 0.2034  loss_box_reg: 0.3302  loss_mask: 0.3443  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.02943    time: 0.3337  last_time: 0.1902  data_time: 0.0035  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:26:38 d2.utils.events]: \u001b[0m eta: 0:26:21  iter: 4199  total_loss: 0.9496  loss_cls: 0.2014  loss_box_reg: 0.3152  loss_mask: 0.3492  loss_rpn_cls: 0.03083  loss_rpn_loc: 0.03297    time: 0.3337  last_time: 0.3021  data_time: 0.0038  last_data_time: 0.0041   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:26:45 d2.utils.events]: \u001b[0m eta: 0:26:13  iter: 4219  total_loss: 1.083  loss_cls: 0.2514  loss_box_reg: 0.3834  loss_mask: 0.3504  loss_rpn_cls: 0.03818  loss_rpn_loc: 0.0368    time: 0.3338  last_time: 0.3986  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:26:52 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 4239  total_loss: 1.121  loss_cls: 0.2683  loss_box_reg: 0.3938  loss_mask: 0.3688  loss_rpn_cls: 0.03743  loss_rpn_loc: 0.04465    time: 0.3338  last_time: 0.3908  data_time: 0.0037  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:26:59 d2.utils.events]: \u001b[0m eta: 0:26:00  iter: 4259  total_loss: 1.058  loss_cls: 0.2199  loss_box_reg: 0.3571  loss_mask: 0.3708  loss_rpn_cls: 0.02879  loss_rpn_loc: 0.0298    time: 0.3338  last_time: 0.3080  data_time: 0.0037  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:27:06 d2.utils.events]: \u001b[0m eta: 0:25:54  iter: 4279  total_loss: 1.006  loss_cls: 0.2123  loss_box_reg: 0.3016  loss_mask: 0.3668  loss_rpn_cls: 0.02348  loss_rpn_loc: 0.03028    time: 0.3338  last_time: 0.3337  data_time: 0.0036  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:27:12 d2.utils.events]: \u001b[0m eta: 0:25:47  iter: 4299  total_loss: 1.025  loss_cls: 0.2124  loss_box_reg: 0.3497  loss_mask: 0.3693  loss_rpn_cls: 0.04028  loss_rpn_loc: 0.0417    time: 0.3338  last_time: 0.3352  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:27:19 d2.utils.events]: \u001b[0m eta: 0:25:39  iter: 4319  total_loss: 1.055  loss_cls: 0.2305  loss_box_reg: 0.4049  loss_mask: 0.3364  loss_rpn_cls: 0.03123  loss_rpn_loc: 0.03728    time: 0.3338  last_time: 0.3358  data_time: 0.0035  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:27:26 d2.utils.events]: \u001b[0m eta: 0:25:34  iter: 4339  total_loss: 0.9661  loss_cls: 0.2073  loss_box_reg: 0.3215  loss_mask: 0.371  loss_rpn_cls: 0.02767  loss_rpn_loc: 0.03498    time: 0.3338  last_time: 0.2419  data_time: 0.0037  last_data_time: 0.0042   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:27:32 d2.utils.events]: \u001b[0m eta: 0:25:26  iter: 4359  total_loss: 0.9132  loss_cls: 0.2008  loss_box_reg: 0.3164  loss_mask: 0.3462  loss_rpn_cls: 0.03028  loss_rpn_loc: 0.029    time: 0.3339  last_time: 0.3831  data_time: 0.0036  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:27:39 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 4379  total_loss: 1.138  loss_cls: 0.2603  loss_box_reg: 0.3837  loss_mask: 0.3457  loss_rpn_cls: 0.03593  loss_rpn_loc: 0.03372    time: 0.3339  last_time: 0.3887  data_time: 0.0036  last_data_time: 0.0046   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:27:46 d2.utils.events]: \u001b[0m eta: 0:25:13  iter: 4399  total_loss: 0.9581  loss_cls: 0.2108  loss_box_reg: 0.3136  loss_mask: 0.3686  loss_rpn_cls: 0.03556  loss_rpn_loc: 0.03333    time: 0.3339  last_time: 0.3340  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:27:53 d2.utils.events]: \u001b[0m eta: 0:25:06  iter: 4419  total_loss: 1.055  loss_cls: 0.2362  loss_box_reg: 0.3742  loss_mask: 0.3529  loss_rpn_cls: 0.03075  loss_rpn_loc: 0.04464    time: 0.3340  last_time: 0.3434  data_time: 0.0035  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:28:00 d2.utils.events]: \u001b[0m eta: 0:24:59  iter: 4439  total_loss: 1.101  loss_cls: 0.2418  loss_box_reg: 0.3538  loss_mask: 0.3684  loss_rpn_cls: 0.03098  loss_rpn_loc: 0.03808    time: 0.3340  last_time: 0.3125  data_time: 0.0037  last_data_time: 0.0045   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:28:07 d2.utils.events]: \u001b[0m eta: 0:24:52  iter: 4459  total_loss: 1.047  loss_cls: 0.2308  loss_box_reg: 0.3076  loss_mask: 0.358  loss_rpn_cls: 0.03546  loss_rpn_loc: 0.03051    time: 0.3340  last_time: 0.4081  data_time: 0.0038  last_data_time: 0.0039   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:28:13 d2.utils.events]: \u001b[0m eta: 0:24:47  iter: 4479  total_loss: 1.009  loss_cls: 0.223  loss_box_reg: 0.3468  loss_mask: 0.3636  loss_rpn_cls: 0.02934  loss_rpn_loc: 0.03367    time: 0.3340  last_time: 0.3500  data_time: 0.0035  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:28:20 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:28:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:28:20 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:28:20 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:28:20 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:28:20 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:28:20 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:28:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0810 s/iter. Eval: 0.2253 s/iter. Total: 0.3074 s/iter. ETA=0:01:02\n",
      "\u001b[32m[06/23 13:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 25/213. Dataloading: 0.0013 s/iter. Inference: 0.0859 s/iter. Eval: 0.2659 s/iter. Total: 0.3532 s/iter. ETA=0:01:06\n",
      "\u001b[32m[06/23 13:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 42/213. Dataloading: 0.0013 s/iter. Inference: 0.0853 s/iter. Eval: 0.2648 s/iter. Total: 0.3515 s/iter. ETA=0:01:00\n",
      "\u001b[32m[06/23 13:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 56/213. Dataloading: 0.0013 s/iter. Inference: 0.0852 s/iter. Eval: 0.2678 s/iter. Total: 0.3544 s/iter. ETA=0:00:55\n",
      "\u001b[32m[06/23 13:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 72/213. Dataloading: 0.0013 s/iter. Inference: 0.0854 s/iter. Eval: 0.2635 s/iter. Total: 0.3504 s/iter. ETA=0:00:49\n",
      "\u001b[32m[06/23 13:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 91/213. Dataloading: 0.0013 s/iter. Inference: 0.0834 s/iter. Eval: 0.2484 s/iter. Total: 0.3332 s/iter. ETA=0:00:40\n",
      "\u001b[32m[06/23 13:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 108/213. Dataloading: 0.0013 s/iter. Inference: 0.0825 s/iter. Eval: 0.2450 s/iter. Total: 0.3289 s/iter. ETA=0:00:34\n",
      "\u001b[32m[06/23 13:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 122/213. Dataloading: 0.0013 s/iter. Inference: 0.0833 s/iter. Eval: 0.2503 s/iter. Total: 0.3351 s/iter. ETA=0:00:30\n",
      "\u001b[32m[06/23 13:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 136/213. Dataloading: 0.0013 s/iter. Inference: 0.0834 s/iter. Eval: 0.2532 s/iter. Total: 0.3380 s/iter. ETA=0:00:26\n",
      "\u001b[32m[06/23 13:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 153/213. Dataloading: 0.0013 s/iter. Inference: 0.0834 s/iter. Eval: 0.2497 s/iter. Total: 0.3345 s/iter. ETA=0:00:20\n",
      "\u001b[32m[06/23 13:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 168/213. Dataloading: 0.0013 s/iter. Inference: 0.0834 s/iter. Eval: 0.2521 s/iter. Total: 0.3369 s/iter. ETA=0:00:15\n",
      "\u001b[32m[06/23 13:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 181/213. Dataloading: 0.0013 s/iter. Inference: 0.0839 s/iter. Eval: 0.2573 s/iter. Total: 0.3426 s/iter. ETA=0:00:10\n",
      "\u001b[32m[06/23 13:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 203/213. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.2466 s/iter. Total: 0.3304 s/iter. ETA=0:00:03\n",
      "\u001b[32m[06/23 13:29:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:08.751115 (0.330534 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:29:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.081887 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:29:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:29:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:29:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.64s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.540\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415\n",
      "\u001b[32m[06/23 13:29:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.335 | 54.023 | 7.313  | 4.335 | 18.376 | 20.986 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.73s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.513\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.391\n",
      "\u001b[32m[06/23 13:29:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.251 | 51.332 | 7.474  | 3.507 | 13.361 | 21.015 |\n",
      "\u001b[32m[06/23 13:29:32 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:29:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:29:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:29:32 d2.evaluation.testing]: \u001b[0mcopypaste: 19.3347,54.0234,7.3133,4.3353,18.3759,20.9856\n",
      "\u001b[32m[06/23 13:29:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:29:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:29:32 d2.evaluation.testing]: \u001b[0mcopypaste: 18.2514,51.3318,7.4739,3.5072,13.3611,21.0151\n",
      "\u001b[32m[06/23 13:29:33 d2.utils.events]: \u001b[0m eta: 0:24:41  iter: 4499  total_loss: 0.983  loss_cls: 0.2264  loss_box_reg: 0.3062  loss_mask: 0.3651  loss_rpn_cls: 0.03621  loss_rpn_loc: 0.03847    time: 0.3341  last_time: 0.3213  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "val_loss (1.1007043048739433, 4500)\n",
      "Iteration 4500: Validation Loss = 1.1007\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_4500.pth\n",
      "Early stopping triggered. Stopping training.\n",
      "\u001b[32m[06/23 13:29:39 d2.utils.events]: \u001b[0m eta: 0:24:34  iter: 4519  total_loss: 0.9654  loss_cls: 0.2171  loss_box_reg: 0.331  loss_mask: 0.3645  loss_rpn_cls: 0.01965  loss_rpn_loc: 0.02962    time: 0.3341  last_time: 0.3127  data_time: 0.0036  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:29:46 d2.utils.events]: \u001b[0m eta: 0:24:27  iter: 4539  total_loss: 1.004  loss_cls: 0.236  loss_box_reg: 0.3632  loss_mask: 0.3574  loss_rpn_cls: 0.02998  loss_rpn_loc: 0.03138    time: 0.3341  last_time: 0.3279  data_time: 0.0036  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:29:53 d2.utils.events]: \u001b[0m eta: 0:24:20  iter: 4559  total_loss: 1.083  loss_cls: 0.2584  loss_box_reg: 0.3686  loss_mask: 0.373  loss_rpn_cls: 0.03057  loss_rpn_loc: 0.03611    time: 0.3341  last_time: 0.3512  data_time: 0.0037  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:29:59 d2.utils.events]: \u001b[0m eta: 0:24:15  iter: 4579  total_loss: 0.7975  loss_cls: 0.1641  loss_box_reg: 0.2576  loss_mask: 0.3422  loss_rpn_cls: 0.02753  loss_rpn_loc: 0.02405    time: 0.3341  last_time: 0.3006  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:30:06 d2.utils.events]: \u001b[0m eta: 0:24:07  iter: 4599  total_loss: 1.089  loss_cls: 0.2257  loss_box_reg: 0.392  loss_mask: 0.3505  loss_rpn_cls: 0.03159  loss_rpn_loc: 0.03092    time: 0.3341  last_time: 0.4164  data_time: 0.0037  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:30:13 d2.utils.events]: \u001b[0m eta: 0:24:01  iter: 4619  total_loss: 1.091  loss_cls: 0.2472  loss_box_reg: 0.3916  loss_mask: 0.3461  loss_rpn_cls: 0.03439  loss_rpn_loc: 0.03259    time: 0.3341  last_time: 0.2667  data_time: 0.0038  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:30:20 d2.utils.events]: \u001b[0m eta: 0:23:55  iter: 4639  total_loss: 1.012  loss_cls: 0.2099  loss_box_reg: 0.3407  loss_mask: 0.3413  loss_rpn_cls: 0.03003  loss_rpn_loc: 0.03924    time: 0.3341  last_time: 0.3434  data_time: 0.0035  last_data_time: 0.0040   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:30:27 d2.utils.events]: \u001b[0m eta: 0:23:51  iter: 4659  total_loss: 1.013  loss_cls: 0.2472  loss_box_reg: 0.3756  loss_mask: 0.3555  loss_rpn_cls: 0.0382  loss_rpn_loc: 0.03472    time: 0.3342  last_time: 0.3178  data_time: 0.0037  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:30:33 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 4679  total_loss: 1.017  loss_cls: 0.2322  loss_box_reg: 0.3578  loss_mask: 0.3437  loss_rpn_cls: 0.02756  loss_rpn_loc: 0.03149    time: 0.3342  last_time: 0.3577  data_time: 0.0038  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:30:40 d2.utils.events]: \u001b[0m eta: 0:23:37  iter: 4699  total_loss: 1.007  loss_cls: 0.2187  loss_box_reg: 0.3588  loss_mask: 0.3508  loss_rpn_cls: 0.03066  loss_rpn_loc: 0.03582    time: 0.3342  last_time: 0.3409  data_time: 0.0035  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:30:47 d2.utils.events]: \u001b[0m eta: 0:23:29  iter: 4719  total_loss: 0.9707  loss_cls: 0.2223  loss_box_reg: 0.3154  loss_mask: 0.3614  loss_rpn_cls: 0.02498  loss_rpn_loc: 0.02868    time: 0.3342  last_time: 0.2877  data_time: 0.0038  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:30:54 d2.utils.events]: \u001b[0m eta: 0:23:24  iter: 4739  total_loss: 0.9256  loss_cls: 0.2182  loss_box_reg: 0.3434  loss_mask: 0.339  loss_rpn_cls: 0.0222  loss_rpn_loc: 0.03343    time: 0.3342  last_time: 0.2430  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:31:00 d2.utils.events]: \u001b[0m eta: 0:23:17  iter: 4759  total_loss: 1.005  loss_cls: 0.2307  loss_box_reg: 0.3425  loss_mask: 0.3435  loss_rpn_cls: 0.0294  loss_rpn_loc: 0.02385    time: 0.3342  last_time: 0.3126  data_time: 0.0036  last_data_time: 0.0043   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:31:07 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 4779  total_loss: 0.9013  loss_cls: 0.1802  loss_box_reg: 0.2851  loss_mask: 0.3595  loss_rpn_cls: 0.01928  loss_rpn_loc: 0.03077    time: 0.3342  last_time: 0.3486  data_time: 0.0034  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:31:14 d2.utils.events]: \u001b[0m eta: 0:23:01  iter: 4799  total_loss: 1.026  loss_cls: 0.2193  loss_box_reg: 0.3851  loss_mask: 0.3745  loss_rpn_cls: 0.02804  loss_rpn_loc: 0.03522    time: 0.3342  last_time: 0.3313  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:31:20 d2.utils.events]: \u001b[0m eta: 0:22:53  iter: 4819  total_loss: 0.9515  loss_cls: 0.2129  loss_box_reg: 0.2589  loss_mask: 0.3641  loss_rpn_cls: 0.02404  loss_rpn_loc: 0.02865    time: 0.3342  last_time: 0.3491  data_time: 0.0036  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:31:27 d2.utils.events]: \u001b[0m eta: 0:22:45  iter: 4839  total_loss: 0.9203  loss_cls: 0.1839  loss_box_reg: 0.3293  loss_mask: 0.3584  loss_rpn_cls: 0.03251  loss_rpn_loc: 0.03127    time: 0.3341  last_time: 0.2911  data_time: 0.0037  last_data_time: 0.0041   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:31:34 d2.utils.events]: \u001b[0m eta: 0:22:38  iter: 4859  total_loss: 1.005  loss_cls: 0.2269  loss_box_reg: 0.3456  loss_mask: 0.359  loss_rpn_cls: 0.0324  loss_rpn_loc: 0.03575    time: 0.3342  last_time: 0.3700  data_time: 0.0037  last_data_time: 0.0039   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:31:40 d2.utils.events]: \u001b[0m eta: 0:22:31  iter: 4879  total_loss: 1.016  loss_cls: 0.2503  loss_box_reg: 0.3638  loss_mask: 0.3342  loss_rpn_cls: 0.02672  loss_rpn_loc: 0.03505    time: 0.3342  last_time: 0.3050  data_time: 0.0036  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:31:47 d2.utils.events]: \u001b[0m eta: 0:22:24  iter: 4899  total_loss: 0.965  loss_cls: 0.2034  loss_box_reg: 0.3117  loss_mask: 0.3566  loss_rpn_cls: 0.0252  loss_rpn_loc: 0.03522    time: 0.3341  last_time: 0.3400  data_time: 0.0035  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:31:53 d2.utils.events]: \u001b[0m eta: 0:22:18  iter: 4919  total_loss: 0.9915  loss_cls: 0.2057  loss_box_reg: 0.3702  loss_mask: 0.3508  loss_rpn_cls: 0.02639  loss_rpn_loc: 0.03481    time: 0.3341  last_time: 0.2984  data_time: 0.0036  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:32:00 d2.utils.events]: \u001b[0m eta: 0:22:12  iter: 4939  total_loss: 0.9227  loss_cls: 0.1925  loss_box_reg: 0.3107  loss_mask: 0.3461  loss_rpn_cls: 0.01938  loss_rpn_loc: 0.02481    time: 0.3341  last_time: 0.3489  data_time: 0.0036  last_data_time: 0.0043   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:32:07 d2.utils.events]: \u001b[0m eta: 0:22:06  iter: 4959  total_loss: 0.9093  loss_cls: 0.2212  loss_box_reg: 0.3078  loss_mask: 0.3557  loss_rpn_cls: 0.03217  loss_rpn_loc: 0.02969    time: 0.3341  last_time: 0.3747  data_time: 0.0035  last_data_time: 0.0029   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:32:14 d2.utils.events]: \u001b[0m eta: 0:22:02  iter: 4979  total_loss: 1.163  loss_cls: 0.2664  loss_box_reg: 0.4114  loss_mask: 0.3735  loss_rpn_cls: 0.03377  loss_rpn_loc: 0.04462    time: 0.3342  last_time: 0.3374  data_time: 0.0036  last_data_time: 0.0030   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:32:22 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:32:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:32:22 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:32:22 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:32:22 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:32:22 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:32:22 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:32:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:32:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0012 s/iter. Inference: 0.0777 s/iter. Eval: 0.1955 s/iter. Total: 0.2743 s/iter. ETA=0:00:55\n",
      "\u001b[32m[06/23 13:32:30 d2.evaluation.evaluator]: \u001b[0mInference done 25/213. Dataloading: 0.0014 s/iter. Inference: 0.0837 s/iter. Eval: 0.2497 s/iter. Total: 0.3348 s/iter. ETA=0:01:02\n",
      "\u001b[32m[06/23 13:32:35 d2.evaluation.evaluator]: \u001b[0mInference done 42/213. Dataloading: 0.0013 s/iter. Inference: 0.0822 s/iter. Eval: 0.2390 s/iter. Total: 0.3226 s/iter. ETA=0:00:55\n",
      "\u001b[32m[06/23 13:32:40 d2.evaluation.evaluator]: \u001b[0mInference done 59/213. Dataloading: 0.0013 s/iter. Inference: 0.0818 s/iter. Eval: 0.2309 s/iter. Total: 0.3141 s/iter. ETA=0:00:48\n",
      "\u001b[32m[06/23 13:32:46 d2.evaluation.evaluator]: \u001b[0mInference done 76/213. Dataloading: 0.0013 s/iter. Inference: 0.0825 s/iter. Eval: 0.2329 s/iter. Total: 0.3169 s/iter. ETA=0:00:43\n",
      "\u001b[32m[06/23 13:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 100/213. Dataloading: 0.0013 s/iter. Inference: 0.0796 s/iter. Eval: 0.2116 s/iter. Total: 0.2927 s/iter. ETA=0:00:33\n",
      "\u001b[32m[06/23 13:32:56 d2.evaluation.evaluator]: \u001b[0mInference done 111/213. Dataloading: 0.0013 s/iter. Inference: 0.0807 s/iter. Eval: 0.2300 s/iter. Total: 0.3122 s/iter. ETA=0:00:31\n",
      "\u001b[32m[06/23 13:33:02 d2.evaluation.evaluator]: \u001b[0mInference done 129/213. Dataloading: 0.0013 s/iter. Inference: 0.0808 s/iter. Eval: 0.2284 s/iter. Total: 0.3106 s/iter. ETA=0:00:26\n",
      "\u001b[32m[06/23 13:33:07 d2.evaluation.evaluator]: \u001b[0mInference done 150/213. Dataloading: 0.0013 s/iter. Inference: 0.0801 s/iter. Eval: 0.2195 s/iter. Total: 0.3010 s/iter. ETA=0:00:18\n",
      "\u001b[32m[06/23 13:33:12 d2.evaluation.evaluator]: \u001b[0mInference done 168/213. Dataloading: 0.0013 s/iter. Inference: 0.0799 s/iter. Eval: 0.2186 s/iter. Total: 0.2998 s/iter. ETA=0:00:13\n",
      "\u001b[32m[06/23 13:33:17 d2.evaluation.evaluator]: \u001b[0mInference done 183/213. Dataloading: 0.0013 s/iter. Inference: 0.0801 s/iter. Eval: 0.2215 s/iter. Total: 0.3030 s/iter. ETA=0:00:09\n",
      "\u001b[32m[06/23 13:33:22 d2.evaluation.evaluator]: \u001b[0mInference done 206/213. Dataloading: 0.0013 s/iter. Inference: 0.0788 s/iter. Eval: 0.2153 s/iter. Total: 0.2956 s/iter. ETA=0:00:02\n",
      "\u001b[32m[06/23 13:33:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:01.661358 (0.296449 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:33:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.078498 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:33:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:33:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:33:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.55s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.530\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "\u001b[32m[06/23 13:33:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.840 | 53.030 | 8.432  | 4.571 | 16.998 | 20.635 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.64s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.504\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.066\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      "\u001b[32m[06/23 13:33:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.571 | 50.368 | 6.587  | 4.269 | 12.760 | 20.373 |\n",
      "\u001b[32m[06/23 13:33:26 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:33:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:33:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:33:26 d2.evaluation.testing]: \u001b[0mcopypaste: 18.8396,53.0305,8.4321,4.5710,16.9984,20.6348\n",
      "\u001b[32m[06/23 13:33:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:33:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:33:26 d2.evaluation.testing]: \u001b[0mcopypaste: 17.5709,50.3681,6.5873,4.2693,12.7603,20.3732\n",
      "\u001b[32m[06/23 13:33:26 d2.utils.events]: \u001b[0m eta: 0:21:56  iter: 4999  total_loss: 1.088  loss_cls: 0.2568  loss_box_reg: 0.3894  loss_mask: 0.3575  loss_rpn_cls: 0.03339  loss_rpn_loc: 0.03778    time: 0.3343  last_time: 0.2861  data_time: 0.0034  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "val_loss (1.283508311957121, 5000)\n",
      "Iteration 5000: Validation Loss = 1.2835\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_5000.pth\n",
      "Early stopping triggered. Stopping training.\n",
      "\u001b[32m[06/23 13:33:33 d2.utils.events]: \u001b[0m eta: 0:21:49  iter: 5019  total_loss: 1.101  loss_cls: 0.2433  loss_box_reg: 0.3902  loss_mask: 0.3591  loss_rpn_cls: 0.03986  loss_rpn_loc: 0.04118    time: 0.3343  last_time: 0.3630  data_time: 0.0037  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:33:40 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 5039  total_loss: 1.08  loss_cls: 0.2445  loss_box_reg: 0.3465  loss_mask: 0.3596  loss_rpn_cls: 0.03445  loss_rpn_loc: 0.03757    time: 0.3343  last_time: 0.3313  data_time: 0.0038  last_data_time: 0.0043   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:33:47 d2.utils.events]: \u001b[0m eta: 0:21:35  iter: 5059  total_loss: 0.9314  loss_cls: 0.1972  loss_box_reg: 0.3413  loss_mask: 0.3427  loss_rpn_cls: 0.0305  loss_rpn_loc: 0.02994    time: 0.3343  last_time: 0.3309  data_time: 0.0038  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:33:53 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 5079  total_loss: 0.9354  loss_cls: 0.1794  loss_box_reg: 0.3076  loss_mask: 0.3604  loss_rpn_cls: 0.02502  loss_rpn_loc: 0.02816    time: 0.3343  last_time: 0.3592  data_time: 0.0037  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:34:00 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 5099  total_loss: 0.9299  loss_cls: 0.2097  loss_box_reg: 0.3448  loss_mask: 0.336  loss_rpn_cls: 0.02716  loss_rpn_loc: 0.0288    time: 0.3343  last_time: 0.3119  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:34:07 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 5119  total_loss: 1.204  loss_cls: 0.2621  loss_box_reg: 0.4224  loss_mask: 0.3639  loss_rpn_cls: 0.0391  loss_rpn_loc: 0.04679    time: 0.3343  last_time: 0.3665  data_time: 0.0042  last_data_time: 0.0041   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:34:14 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 5139  total_loss: 1.023  loss_cls: 0.2174  loss_box_reg: 0.3695  loss_mask: 0.334  loss_rpn_cls: 0.02601  loss_rpn_loc: 0.04765    time: 0.3344  last_time: 0.3496  data_time: 0.0036  last_data_time: 0.0041   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:34:21 d2.utils.events]: \u001b[0m eta: 0:21:02  iter: 5159  total_loss: 0.9466  loss_cls: 0.22  loss_box_reg: 0.326  loss_mask: 0.3423  loss_rpn_cls: 0.01768  loss_rpn_loc: 0.0263    time: 0.3344  last_time: 0.3156  data_time: 0.0037  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:34:28 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 5179  total_loss: 1.152  loss_cls: 0.2766  loss_box_reg: 0.4046  loss_mask: 0.3421  loss_rpn_cls: 0.02597  loss_rpn_loc: 0.03567    time: 0.3345  last_time: 0.3162  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:34:34 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 5199  total_loss: 0.9635  loss_cls: 0.2155  loss_box_reg: 0.3598  loss_mask: 0.3601  loss_rpn_cls: 0.02627  loss_rpn_loc: 0.03824    time: 0.3345  last_time: 0.3250  data_time: 0.0036  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:34:41 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 5219  total_loss: 0.9771  loss_cls: 0.2236  loss_box_reg: 0.3359  loss_mask: 0.3289  loss_rpn_cls: 0.02559  loss_rpn_loc: 0.03458    time: 0.3345  last_time: 0.3624  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:34:48 d2.utils.events]: \u001b[0m eta: 0:20:36  iter: 5239  total_loss: 0.911  loss_cls: 0.1829  loss_box_reg: 0.3154  loss_mask: 0.3248  loss_rpn_cls: 0.0188  loss_rpn_loc: 0.0311    time: 0.3345  last_time: 0.3640  data_time: 0.0035  last_data_time: 0.0030   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:34:55 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 5259  total_loss: 0.9189  loss_cls: 0.1599  loss_box_reg: 0.2558  loss_mask: 0.3563  loss_rpn_cls: 0.03285  loss_rpn_loc: 0.0336    time: 0.3345  last_time: 0.3143  data_time: 0.0037  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:35:01 d2.utils.events]: \u001b[0m eta: 0:20:22  iter: 5279  total_loss: 0.9558  loss_cls: 0.2177  loss_box_reg: 0.3163  loss_mask: 0.3582  loss_rpn_cls: 0.02504  loss_rpn_loc: 0.03578    time: 0.3345  last_time: 0.3130  data_time: 0.0037  last_data_time: 0.0040   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:35:08 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 5299  total_loss: 1.009  loss_cls: 0.2336  loss_box_reg: 0.3591  loss_mask: 0.344  loss_rpn_cls: 0.02757  loss_rpn_loc: 0.03348    time: 0.3345  last_time: 0.3235  data_time: 0.0036  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:35:15 d2.utils.events]: \u001b[0m eta: 0:20:10  iter: 5319  total_loss: 0.9824  loss_cls: 0.2224  loss_box_reg: 0.2947  loss_mask: 0.3672  loss_rpn_cls: 0.0241  loss_rpn_loc: 0.0301    time: 0.3345  last_time: 0.3154  data_time: 0.0034  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:35:21 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 5339  total_loss: 1.022  loss_cls: 0.2251  loss_box_reg: 0.3217  loss_mask: 0.3428  loss_rpn_cls: 0.03396  loss_rpn_loc: 0.03125    time: 0.3344  last_time: 0.3450  data_time: 0.0035  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:35:28 d2.utils.events]: \u001b[0m eta: 0:19:58  iter: 5359  total_loss: 1.033  loss_cls: 0.2353  loss_box_reg: 0.3893  loss_mask: 0.3471  loss_rpn_cls: 0.03386  loss_rpn_loc: 0.03823    time: 0.3345  last_time: 0.3779  data_time: 0.0036  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:35:35 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 5379  total_loss: 1.005  loss_cls: 0.2279  loss_box_reg: 0.3603  loss_mask: 0.33  loss_rpn_cls: 0.02761  loss_rpn_loc: 0.0335    time: 0.3345  last_time: 0.3467  data_time: 0.0037  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:35:41 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 5399  total_loss: 0.8903  loss_cls: 0.2113  loss_box_reg: 0.2883  loss_mask: 0.3469  loss_rpn_cls: 0.03153  loss_rpn_loc: 0.0265    time: 0.3344  last_time: 0.3238  data_time: 0.0036  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:35:48 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 5419  total_loss: 1.032  loss_cls: 0.2398  loss_box_reg: 0.3379  loss_mask: 0.366  loss_rpn_cls: 0.02717  loss_rpn_loc: 0.05139    time: 0.3345  last_time: 0.3301  data_time: 0.0036  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:35:54 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 5439  total_loss: 0.8961  loss_cls: 0.1903  loss_box_reg: 0.2924  loss_mask: 0.3666  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.03085    time: 0.3344  last_time: 0.3259  data_time: 0.0036  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:36:01 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 5459  total_loss: 1.016  loss_cls: 0.2324  loss_box_reg: 0.368  loss_mask: 0.3372  loss_rpn_cls: 0.02552  loss_rpn_loc: 0.04578    time: 0.3344  last_time: 0.3630  data_time: 0.0037  last_data_time: 0.0036   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:36:08 d2.utils.events]: \u001b[0m eta: 0:19:13  iter: 5479  total_loss: 0.9547  loss_cls: 0.2017  loss_box_reg: 0.3267  loss_mask: 0.3548  loss_rpn_cls: 0.02114  loss_rpn_loc: 0.03644    time: 0.3344  last_time: 0.3495  data_time: 0.0036  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:36:15 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:36:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:36:15 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:36:15 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:36:15 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:36:15 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:36:15 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:36:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0742 s/iter. Eval: 0.1663 s/iter. Total: 0.2416 s/iter. ETA=0:00:48\n",
      "\u001b[32m[06/23 13:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 28/213. Dataloading: 0.0013 s/iter. Inference: 0.0791 s/iter. Eval: 0.2063 s/iter. Total: 0.2868 s/iter. ETA=0:00:53\n",
      "\u001b[32m[06/23 13:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 47/213. Dataloading: 0.0013 s/iter. Inference: 0.0786 s/iter. Eval: 0.1981 s/iter. Total: 0.2781 s/iter. ETA=0:00:46\n",
      "\u001b[32m[06/23 13:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 65/213. Dataloading: 0.0013 s/iter. Inference: 0.0783 s/iter. Eval: 0.1998 s/iter. Total: 0.2795 s/iter. ETA=0:00:41\n",
      "\u001b[32m[06/23 13:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 91/213. Dataloading: 0.0015 s/iter. Inference: 0.0765 s/iter. Eval: 0.1804 s/iter. Total: 0.2584 s/iter. ETA=0:00:31\n",
      "\u001b[32m[06/23 13:36:43 d2.evaluation.evaluator]: \u001b[0mInference done 110/213. Dataloading: 0.0014 s/iter. Inference: 0.0763 s/iter. Eval: 0.1854 s/iter. Total: 0.2632 s/iter. ETA=0:00:27\n",
      "\u001b[32m[06/23 13:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 131/213. Dataloading: 0.0014 s/iter. Inference: 0.0762 s/iter. Eval: 0.1826 s/iter. Total: 0.2603 s/iter. ETA=0:00:21\n",
      "\u001b[32m[06/23 13:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 153/213. Dataloading: 0.0014 s/iter. Inference: 0.0762 s/iter. Eval: 0.1781 s/iter. Total: 0.2558 s/iter. ETA=0:00:15\n",
      "\u001b[32m[06/23 13:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 170/213. Dataloading: 0.0014 s/iter. Inference: 0.0763 s/iter. Eval: 0.1823 s/iter. Total: 0.2601 s/iter. ETA=0:00:11\n",
      "\u001b[32m[06/23 13:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 193/213. Dataloading: 0.0014 s/iter. Inference: 0.0760 s/iter. Eval: 0.1779 s/iter. Total: 0.2554 s/iter. ETA=0:00:05\n",
      "\u001b[32m[06/23 13:37:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:52.509182 (0.252448 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:37:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.074670 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:37:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:37:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:37:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.48s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.522\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.398\n",
      "\u001b[32m[06/23 13:37:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.665 | 52.218 | 6.853  | 4.546 | 16.909 | 20.569 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.56s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.505\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.368\n",
      "\u001b[32m[06/23 13:37:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.432 | 50.459 | 6.887  | 3.665 | 11.747 | 20.436 |\n",
      "\u001b[32m[06/23 13:37:10 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:37:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:37:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:37:10 d2.evaluation.testing]: \u001b[0mcopypaste: 18.6646,52.2180,6.8527,4.5464,16.9090,20.5693\n",
      "\u001b[32m[06/23 13:37:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:37:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:37:10 d2.evaluation.testing]: \u001b[0mcopypaste: 17.4323,50.4593,6.8868,3.6653,11.7466,20.4358\n",
      "\u001b[32m[06/23 13:37:10 d2.utils.events]: \u001b[0m eta: 0:19:05  iter: 5499  total_loss: 0.9021  loss_cls: 0.194  loss_box_reg: 0.2716  loss_mask: 0.346  loss_rpn_cls: 0.02649  loss_rpn_loc: 0.03053    time: 0.3344  last_time: 0.3495  data_time: 0.0037  last_data_time: 0.0039   lr: 0.00025  max_mem: 5355M\n",
      "val_loss (1.1169455787166953, 5500)\n",
      "Iteration 5500: Validation Loss = 1.1169\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_5500.pth\n",
      "Early stopping triggered. Stopping training.\n",
      "\u001b[32m[06/23 13:37:16 d2.utils.events]: \u001b[0m eta: 0:18:57  iter: 5519  total_loss: 0.9622  loss_cls: 0.2279  loss_box_reg: 0.3359  loss_mask: 0.3336  loss_rpn_cls: 0.02552  loss_rpn_loc: 0.0277    time: 0.3344  last_time: 0.3055  data_time: 0.0036  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:37:24 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 5539  total_loss: 1.087  loss_cls: 0.2582  loss_box_reg: 0.4215  loss_mask: 0.3235  loss_rpn_cls: 0.02554  loss_rpn_loc: 0.03095    time: 0.3344  last_time: 0.3832  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:37:31 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 5559  total_loss: 0.9504  loss_cls: 0.2065  loss_box_reg: 0.312  loss_mask: 0.3322  loss_rpn_cls: 0.02446  loss_rpn_loc: 0.03118    time: 0.3345  last_time: 0.3464  data_time: 0.0036  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:37:37 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 5579  total_loss: 0.9455  loss_cls: 0.2086  loss_box_reg: 0.3248  loss_mask: 0.3513  loss_rpn_cls: 0.02252  loss_rpn_loc: 0.03395    time: 0.3345  last_time: 0.3302  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:37:44 d2.utils.events]: \u001b[0m eta: 0:18:32  iter: 5599  total_loss: 0.9126  loss_cls: 0.1937  loss_box_reg: 0.3031  loss_mask: 0.3594  loss_rpn_cls: 0.01954  loss_rpn_loc: 0.03414    time: 0.3345  last_time: 0.3550  data_time: 0.0037  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:37:51 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 5619  total_loss: 0.8901  loss_cls: 0.199  loss_box_reg: 0.3137  loss_mask: 0.324  loss_rpn_cls: 0.02488  loss_rpn_loc: 0.04138    time: 0.3345  last_time: 0.3402  data_time: 0.0036  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:37:58 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 5639  total_loss: 1.009  loss_cls: 0.1993  loss_box_reg: 0.3632  loss_mask: 0.341  loss_rpn_cls: 0.03247  loss_rpn_loc: 0.03111    time: 0.3346  last_time: 0.3445  data_time: 0.0036  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:38:04 d2.utils.events]: \u001b[0m eta: 0:18:12  iter: 5659  total_loss: 0.9435  loss_cls: 0.2036  loss_box_reg: 0.3531  loss_mask: 0.3573  loss_rpn_cls: 0.02757  loss_rpn_loc: 0.03472    time: 0.3345  last_time: 0.3866  data_time: 0.0035  last_data_time: 0.0033   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:38:11 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 5679  total_loss: 1.11  loss_cls: 0.2265  loss_box_reg: 0.3863  loss_mask: 0.3505  loss_rpn_cls: 0.03383  loss_rpn_loc: 0.04591    time: 0.3346  last_time: 0.4097  data_time: 0.0037  last_data_time: 0.0040   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:38:18 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 5699  total_loss: 0.9973  loss_cls: 0.2041  loss_box_reg: 0.3203  loss_mask: 0.3449  loss_rpn_cls: 0.02296  loss_rpn_loc: 0.02947    time: 0.3346  last_time: 0.3873  data_time: 0.0035  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:38:25 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 5719  total_loss: 1.1  loss_cls: 0.2438  loss_box_reg: 0.329  loss_mask: 0.3439  loss_rpn_cls: 0.03932  loss_rpn_loc: 0.04967    time: 0.3346  last_time: 0.3128  data_time: 0.0035  last_data_time: 0.0031   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:38:32 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 5739  total_loss: 1.034  loss_cls: 0.2418  loss_box_reg: 0.3586  loss_mask: 0.3595  loss_rpn_cls: 0.02663  loss_rpn_loc: 0.03088    time: 0.3346  last_time: 0.2887  data_time: 0.0037  last_data_time: 0.0041   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:38:38 d2.utils.events]: \u001b[0m eta: 0:17:39  iter: 5759  total_loss: 1.15  loss_cls: 0.2569  loss_box_reg: 0.4462  loss_mask: 0.3384  loss_rpn_cls: 0.03274  loss_rpn_loc: 0.04118    time: 0.3346  last_time: 0.3226  data_time: 0.0037  last_data_time: 0.0039   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:38:45 d2.utils.events]: \u001b[0m eta: 0:17:33  iter: 5779  total_loss: 1.152  loss_cls: 0.2461  loss_box_reg: 0.3981  loss_mask: 0.3576  loss_rpn_cls: 0.03718  loss_rpn_loc: 0.04026    time: 0.3346  last_time: 0.4197  data_time: 0.0037  last_data_time: 0.0038   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:38:52 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 5799  total_loss: 0.976  loss_cls: 0.2003  loss_box_reg: 0.3217  loss_mask: 0.3635  loss_rpn_cls: 0.02811  loss_rpn_loc: 0.04198    time: 0.3346  last_time: 0.3165  data_time: 0.0036  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:38:58 d2.utils.events]: \u001b[0m eta: 0:17:20  iter: 5819  total_loss: 0.9177  loss_cls: 0.2187  loss_box_reg: 0.3233  loss_mask: 0.3343  loss_rpn_cls: 0.02907  loss_rpn_loc: 0.02551    time: 0.3346  last_time: 0.3595  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:39:05 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 5839  total_loss: 0.8268  loss_cls: 0.1741  loss_box_reg: 0.2861  loss_mask: 0.3332  loss_rpn_cls: 0.02009  loss_rpn_loc: 0.02395    time: 0.3346  last_time: 0.3537  data_time: 0.0036  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:39:12 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 5859  total_loss: 0.8701  loss_cls: 0.2059  loss_box_reg: 0.3002  loss_mask: 0.3476  loss_rpn_cls: 0.0246  loss_rpn_loc: 0.02944    time: 0.3346  last_time: 0.3278  data_time: 0.0035  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:39:18 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 5879  total_loss: 0.8846  loss_cls: 0.2019  loss_box_reg: 0.2955  loss_mask: 0.3436  loss_rpn_cls: 0.02018  loss_rpn_loc: 0.02932    time: 0.3346  last_time: 0.3092  data_time: 0.0035  last_data_time: 0.0030   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:39:25 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 5899  total_loss: 1.001  loss_cls: 0.2213  loss_box_reg: 0.3502  loss_mask: 0.3507  loss_rpn_cls: 0.02388  loss_rpn_loc: 0.02794    time: 0.3346  last_time: 0.3772  data_time: 0.0038  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:39:32 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 5919  total_loss: 0.874  loss_cls: 0.1924  loss_box_reg: 0.3062  loss_mask: 0.3403  loss_rpn_cls: 0.02909  loss_rpn_loc: 0.02511    time: 0.3346  last_time: 0.3464  data_time: 0.0036  last_data_time: 0.0043   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:39:39 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 5939  total_loss: 1.029  loss_cls: 0.2253  loss_box_reg: 0.3248  loss_mask: 0.3542  loss_rpn_cls: 0.02076  loss_rpn_loc: 0.02637    time: 0.3346  last_time: 0.3461  data_time: 0.0036  last_data_time: 0.0034   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:39:46 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 5959  total_loss: 0.9791  loss_cls: 0.205  loss_box_reg: 0.362  loss_mask: 0.3423  loss_rpn_cls: 0.03183  loss_rpn_loc: 0.03003    time: 0.3347  last_time: 0.3661  data_time: 0.0037  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:39:53 d2.utils.events]: \u001b[0m eta: 0:16:28  iter: 5979  total_loss: 0.9592  loss_cls: 0.2194  loss_box_reg: 0.3322  loss_mask: 0.3289  loss_rpn_cls: 0.02247  loss_rpn_loc: 0.04354    time: 0.3347  last_time: 0.3664  data_time: 0.0038  last_data_time: 0.0043   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:40:00 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:40:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:40:00 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:40:00 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:40:00 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:40:00 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:40:00 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:40:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0012 s/iter. Inference: 0.0825 s/iter. Eval: 0.2308 s/iter. Total: 0.3146 s/iter. ETA=0:01:03\n",
      "\u001b[32m[06/23 13:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 26/213. Dataloading: 0.0013 s/iter. Inference: 0.0849 s/iter. Eval: 0.2456 s/iter. Total: 0.3320 s/iter. ETA=0:01:02\n",
      "\u001b[32m[06/23 13:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 42/213. Dataloading: 0.0013 s/iter. Inference: 0.0840 s/iter. Eval: 0.2499 s/iter. Total: 0.3354 s/iter. ETA=0:00:57\n",
      "\u001b[32m[06/23 13:40:18 d2.evaluation.evaluator]: \u001b[0mInference done 57/213. Dataloading: 0.0014 s/iter. Inference: 0.0835 s/iter. Eval: 0.2502 s/iter. Total: 0.3351 s/iter. ETA=0:00:52\n",
      "\u001b[32m[06/23 13:40:24 d2.evaluation.evaluator]: \u001b[0mInference done 75/213. Dataloading: 0.0014 s/iter. Inference: 0.0827 s/iter. Eval: 0.2396 s/iter. Total: 0.3238 s/iter. ETA=0:00:44\n",
      "\u001b[32m[06/23 13:40:29 d2.evaluation.evaluator]: \u001b[0mInference done 94/213. Dataloading: 0.0014 s/iter. Inference: 0.0809 s/iter. Eval: 0.2288 s/iter. Total: 0.3113 s/iter. ETA=0:00:37\n",
      "\u001b[32m[06/23 13:40:34 d2.evaluation.evaluator]: \u001b[0mInference done 109/213. Dataloading: 0.0014 s/iter. Inference: 0.0810 s/iter. Eval: 0.2333 s/iter. Total: 0.3158 s/iter. ETA=0:00:32\n",
      "\u001b[32m[06/23 13:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 126/213. Dataloading: 0.0014 s/iter. Inference: 0.0809 s/iter. Eval: 0.2306 s/iter. Total: 0.3129 s/iter. ETA=0:00:27\n",
      "\u001b[32m[06/23 13:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 139/213. Dataloading: 0.0014 s/iter. Inference: 0.0817 s/iter. Eval: 0.2386 s/iter. Total: 0.3218 s/iter. ETA=0:00:23\n",
      "\u001b[32m[06/23 13:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 162/213. Dataloading: 0.0014 s/iter. Inference: 0.0809 s/iter. Eval: 0.2298 s/iter. Total: 0.3121 s/iter. ETA=0:00:15\n",
      "\u001b[32m[06/23 13:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 176/213. Dataloading: 0.0014 s/iter. Inference: 0.0811 s/iter. Eval: 0.2343 s/iter. Total: 0.3168 s/iter. ETA=0:00:11\n",
      "\u001b[32m[06/23 13:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 195/213. Dataloading: 0.0014 s/iter. Inference: 0.0808 s/iter. Eval: 0.2296 s/iter. Total: 0.3120 s/iter. ETA=0:00:05\n",
      "\u001b[32m[06/23 13:41:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:04.135018 (0.308341 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:41:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.079520 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:41:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:41:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:41:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.60s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.511\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.276\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
      "\u001b[32m[06/23 13:41:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.045 | 51.055 | 6.666  | 4.436 | 18.023 | 19.110 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.82s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.484\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.253\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.383\n",
      "\u001b[32m[06/23 13:41:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.880 | 48.422 | 6.306  | 3.494 | 12.978 | 19.431 |\n",
      "\u001b[32m[06/23 13:41:07 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:41:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:41:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:41:07 d2.evaluation.testing]: \u001b[0mcopypaste: 18.0451,51.0546,6.6662,4.4363,18.0226,19.1100\n",
      "\u001b[32m[06/23 13:41:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:41:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:41:07 d2.evaluation.testing]: \u001b[0mcopypaste: 16.8803,48.4218,6.3065,3.4936,12.9782,19.4309\n",
      "\u001b[32m[06/23 13:41:07 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 5999  total_loss: 1.026  loss_cls: 0.2093  loss_box_reg: 0.3627  loss_mask: 0.3527  loss_rpn_cls: 0.02235  loss_rpn_loc: 0.03178    time: 0.3348  last_time: 0.3717  data_time: 0.0035  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "val_loss (0.8018699008971453, 6000)\n",
      "Iteration 6000: Validation Loss = 0.8019\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_6000.pth\n",
      "Early stopping triggered. Stopping training.\n",
      "\u001b[32m[06/23 13:41:14 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 6019  total_loss: 0.8358  loss_cls: 0.1873  loss_box_reg: 0.2844  loss_mask: 0.317  loss_rpn_cls: 0.02067  loss_rpn_loc: 0.03116    time: 0.3347  last_time: 0.2807  data_time: 0.0034  last_data_time: 0.0032   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:41:21 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 6039  total_loss: 1.077  loss_cls: 0.2547  loss_box_reg: 0.37  loss_mask: 0.3514  loss_rpn_cls: 0.03148  loss_rpn_loc: 0.03731    time: 0.3348  last_time: 0.3462  data_time: 0.0037  last_data_time: 0.0037   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:41:28 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 6059  total_loss: 1.05  loss_cls: 0.2372  loss_box_reg: 0.3526  loss_mask: 0.3569  loss_rpn_cls: 0.02573  loss_rpn_loc: 0.03689    time: 0.3348  last_time: 0.3176  data_time: 0.0036  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:41:35 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 6079  total_loss: 0.9808  loss_cls: 0.2184  loss_box_reg: 0.3502  loss_mask: 0.3228  loss_rpn_cls: 0.02194  loss_rpn_loc: 0.03448    time: 0.3349  last_time: 0.3504  data_time: 0.0036  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:41:42 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 6099  total_loss: 0.9885  loss_cls: 0.2263  loss_box_reg: 0.3533  loss_mask: 0.3415  loss_rpn_cls: 0.02536  loss_rpn_loc: 0.04064    time: 0.3349  last_time: 0.3247  data_time: 0.0037  last_data_time: 0.0035   lr: 0.00025  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:41:48 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 6119  total_loss: 0.9976  loss_cls: 0.2073  loss_box_reg: 0.3166  loss_mask: 0.3441  loss_rpn_cls: 0.02  loss_rpn_loc: 0.03456    time: 0.3349  last_time: 0.3468  data_time: 0.0038  last_data_time: 0.0037   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:41:55 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 6139  total_loss: 0.8727  loss_cls: 0.1673  loss_box_reg: 0.2679  loss_mask: 0.3534  loss_rpn_cls: 0.02216  loss_rpn_loc: 0.04131    time: 0.3349  last_time: 0.3344  data_time: 0.0037  last_data_time: 0.0036   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:42:02 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 6159  total_loss: 0.9257  loss_cls: 0.2163  loss_box_reg: 0.3278  loss_mask: 0.3438  loss_rpn_cls: 0.01855  loss_rpn_loc: 0.02813    time: 0.3349  last_time: 0.2868  data_time: 0.0037  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:42:09 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 6179  total_loss: 0.8591  loss_cls: 0.1989  loss_box_reg: 0.3117  loss_mask: 0.3255  loss_rpn_cls: 0.02078  loss_rpn_loc: 0.02544    time: 0.3349  last_time: 0.3780  data_time: 0.0036  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:42:16 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 6199  total_loss: 0.9306  loss_cls: 0.2148  loss_box_reg: 0.3202  loss_mask: 0.3406  loss_rpn_cls: 0.02331  loss_rpn_loc: 0.03306    time: 0.3350  last_time: 0.3749  data_time: 0.0040  last_data_time: 0.0026   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:42:22 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 6219  total_loss: 0.8381  loss_cls: 0.1787  loss_box_reg: 0.2631  loss_mask: 0.3487  loss_rpn_cls: 0.02054  loss_rpn_loc: 0.04276    time: 0.3350  last_time: 0.3112  data_time: 0.0034  last_data_time: 0.0035   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:42:29 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 6239  total_loss: 0.9277  loss_cls: 0.2081  loss_box_reg: 0.2948  loss_mask: 0.3421  loss_rpn_cls: 0.01886  loss_rpn_loc: 0.02564    time: 0.3350  last_time: 0.3522  data_time: 0.0035  last_data_time: 0.0036   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:42:36 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 6259  total_loss: 0.9968  loss_cls: 0.2303  loss_box_reg: 0.3712  loss_mask: 0.355  loss_rpn_cls: 0.02404  loss_rpn_loc: 0.03448    time: 0.3350  last_time: 0.3715  data_time: 0.0038  last_data_time: 0.0035   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:42:43 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 6279  total_loss: 0.8619  loss_cls: 0.176  loss_box_reg: 0.2645  loss_mask: 0.3307  loss_rpn_cls: 0.01815  loss_rpn_loc: 0.02521    time: 0.3350  last_time: 0.2183  data_time: 0.0036  last_data_time: 0.0033   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:42:50 d2.utils.events]: \u001b[0m eta: 0:14:44  iter: 6299  total_loss: 0.9523  loss_cls: 0.2203  loss_box_reg: 0.3514  loss_mask: 0.3136  loss_rpn_cls: 0.02311  loss_rpn_loc: 0.0379    time: 0.3350  last_time: 0.3957  data_time: 0.0038  last_data_time: 0.0048   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:42:56 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 6319  total_loss: 0.8618  loss_cls: 0.1849  loss_box_reg: 0.2801  loss_mask: 0.3258  loss_rpn_cls: 0.01987  loss_rpn_loc: 0.03568    time: 0.3350  last_time: 0.2787  data_time: 0.0036  last_data_time: 0.0030   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:43:03 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 6339  total_loss: 0.9595  loss_cls: 0.2112  loss_box_reg: 0.3442  loss_mask: 0.3255  loss_rpn_cls: 0.02536  loss_rpn_loc: 0.03045    time: 0.3351  last_time: 0.3338  data_time: 0.0036  last_data_time: 0.0039   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:43:10 d2.utils.events]: \u001b[0m eta: 0:14:24  iter: 6359  total_loss: 0.9619  loss_cls: 0.2283  loss_box_reg: 0.3592  loss_mask: 0.3393  loss_rpn_cls: 0.01747  loss_rpn_loc: 0.03342    time: 0.3351  last_time: 0.3512  data_time: 0.0036  last_data_time: 0.0035   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:43:17 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 6379  total_loss: 0.974  loss_cls: 0.2205  loss_box_reg: 0.3256  loss_mask: 0.3443  loss_rpn_cls: 0.03234  loss_rpn_loc: 0.04582    time: 0.3351  last_time: 0.3493  data_time: 0.0036  last_data_time: 0.0038   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:43:24 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 6399  total_loss: 0.7981  loss_cls: 0.1715  loss_box_reg: 0.2427  loss_mask: 0.3279  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.02429    time: 0.3351  last_time: 0.3454  data_time: 0.0036  last_data_time: 0.0036   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:43:30 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 6419  total_loss: 0.8907  loss_cls: 0.176  loss_box_reg: 0.2502  loss_mask: 0.3228  loss_rpn_cls: 0.01833  loss_rpn_loc: 0.02469    time: 0.3351  last_time: 0.3482  data_time: 0.0034  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:43:37 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 6439  total_loss: 0.9044  loss_cls: 0.2039  loss_box_reg: 0.3116  loss_mask: 0.3245  loss_rpn_cls: 0.02215  loss_rpn_loc: 0.0323    time: 0.3352  last_time: 0.3472  data_time: 0.0037  last_data_time: 0.0035   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:43:44 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 6459  total_loss: 1.055  loss_cls: 0.2407  loss_box_reg: 0.388  loss_mask: 0.3382  loss_rpn_cls: 0.02198  loss_rpn_loc: 0.04097    time: 0.3352  last_time: 0.2884  data_time: 0.0036  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:43:51 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 6479  total_loss: 0.9484  loss_cls: 0.2136  loss_box_reg: 0.3128  loss_mask: 0.3372  loss_rpn_cls: 0.02257  loss_rpn_loc: 0.03993    time: 0.3352  last_time: 0.3255  data_time: 0.0037  last_data_time: 0.0035   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:43:58 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:43:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:43:58 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:43:58 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:43:58 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:43:58 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:43:58 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:43:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0787 s/iter. Eval: 0.1924 s/iter. Total: 0.2722 s/iter. ETA=0:00:54\n",
      "\u001b[32m[06/23 13:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 28/213. Dataloading: 0.0014 s/iter. Inference: 0.0814 s/iter. Eval: 0.2130 s/iter. Total: 0.2959 s/iter. ETA=0:00:54\n",
      "\u001b[32m[06/23 13:44:11 d2.evaluation.evaluator]: \u001b[0mInference done 48/213. Dataloading: 0.0014 s/iter. Inference: 0.0787 s/iter. Eval: 0.1956 s/iter. Total: 0.2758 s/iter. ETA=0:00:45\n",
      "\u001b[32m[06/23 13:44:16 d2.evaluation.evaluator]: \u001b[0mInference done 64/213. Dataloading: 0.0014 s/iter. Inference: 0.0797 s/iter. Eval: 0.2062 s/iter. Total: 0.2873 s/iter. ETA=0:00:42\n",
      "\u001b[32m[06/23 13:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 91/213. Dataloading: 0.0014 s/iter. Inference: 0.0772 s/iter. Eval: 0.1815 s/iter. Total: 0.2602 s/iter. ETA=0:00:31\n",
      "\u001b[32m[06/23 13:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 110/213. Dataloading: 0.0014 s/iter. Inference: 0.0769 s/iter. Eval: 0.1857 s/iter. Total: 0.2641 s/iter. ETA=0:00:27\n",
      "\u001b[32m[06/23 13:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 129/213. Dataloading: 0.0014 s/iter. Inference: 0.0771 s/iter. Eval: 0.1862 s/iter. Total: 0.2648 s/iter. ETA=0:00:22\n",
      "\u001b[32m[06/23 13:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 151/213. Dataloading: 0.0014 s/iter. Inference: 0.0767 s/iter. Eval: 0.1815 s/iter. Total: 0.2597 s/iter. ETA=0:00:16\n",
      "\u001b[32m[06/23 13:44:43 d2.evaluation.evaluator]: \u001b[0mInference done 169/213. Dataloading: 0.0014 s/iter. Inference: 0.0768 s/iter. Eval: 0.1857 s/iter. Total: 0.2641 s/iter. ETA=0:00:11\n",
      "\u001b[32m[06/23 13:44:48 d2.evaluation.evaluator]: \u001b[0mInference done 193/213. Dataloading: 0.0014 s/iter. Inference: 0.0762 s/iter. Eval: 0.1798 s/iter. Total: 0.2575 s/iter. ETA=0:00:05\n",
      "\u001b[32m[06/23 13:44:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:53.258292 (0.256049 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:44:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.074896 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:44:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:44:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:44:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.47s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.535\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.405\n",
      "\u001b[32m[06/23 13:44:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.372 | 53.504 | 8.593  | 4.865 | 16.936 | 21.319 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.55s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.507\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
      "\u001b[32m[06/23 13:44:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.165 | 50.702 | 7.547  | 3.511 | 12.689 | 21.205 |\n",
      "\u001b[32m[06/23 13:44:54 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: 19.3722,53.5043,8.5929,4.8649,16.9365,21.3185\n",
      "\u001b[32m[06/23 13:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:44:54 d2.evaluation.testing]: \u001b[0mcopypaste: 18.1647,50.7017,7.5473,3.5108,12.6893,21.2052\n",
      "\u001b[32m[06/23 13:44:54 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 6499  total_loss: 1.01  loss_cls: 0.2303  loss_box_reg: 0.3684  loss_mask: 0.3239  loss_rpn_cls: 0.0248  loss_rpn_loc: 0.03407    time: 0.3353  last_time: 0.3663  data_time: 0.0036  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "val_loss (0.9039359795860946, 6500)\n",
      "Iteration 6500: Validation Loss = 0.9039\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_6500.pth\n",
      "Early stopping triggered. Stopping training.\n",
      "\u001b[32m[06/23 13:45:01 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 6519  total_loss: 0.8517  loss_cls: 0.194  loss_box_reg: 0.3189  loss_mask: 0.3058  loss_rpn_cls: 0.01738  loss_rpn_loc: 0.03035    time: 0.3353  last_time: 0.3156  data_time: 0.0036  last_data_time: 0.0033   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:45:08 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 6539  total_loss: 0.8759  loss_cls: 0.2082  loss_box_reg: 0.2978  loss_mask: 0.3181  loss_rpn_cls: 0.02006  loss_rpn_loc: 0.03523    time: 0.3353  last_time: 0.3314  data_time: 0.0036  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:45:15 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 6559  total_loss: 0.9274  loss_cls: 0.2165  loss_box_reg: 0.3545  loss_mask: 0.3088  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.02875    time: 0.3353  last_time: 0.3973  data_time: 0.0036  last_data_time: 0.0032   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:45:22 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 6579  total_loss: 0.9792  loss_cls: 0.2349  loss_box_reg: 0.352  loss_mask: 0.3276  loss_rpn_cls: 0.02093  loss_rpn_loc: 0.03905    time: 0.3354  last_time: 0.3736  data_time: 0.0036  last_data_time: 0.0033   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:45:28 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 6599  total_loss: 0.8314  loss_cls: 0.1714  loss_box_reg: 0.2956  loss_mask: 0.3137  loss_rpn_cls: 0.01522  loss_rpn_loc: 0.01689    time: 0.3354  last_time: 0.3253  data_time: 0.0035  last_data_time: 0.0036   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:45:35 d2.utils.events]: \u001b[0m eta: 0:12:59  iter: 6619  total_loss: 0.9879  loss_cls: 0.2373  loss_box_reg: 0.3202  loss_mask: 0.3435  loss_rpn_cls: 0.024  loss_rpn_loc: 0.03352    time: 0.3354  last_time: 0.3885  data_time: 0.0037  last_data_time: 0.0039   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:45:42 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 6639  total_loss: 0.8872  loss_cls: 0.1791  loss_box_reg: 0.2878  loss_mask: 0.3445  loss_rpn_cls: 0.01974  loss_rpn_loc: 0.02618    time: 0.3354  last_time: 0.3492  data_time: 0.0035  last_data_time: 0.0040   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:45:49 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 6659  total_loss: 1.108  loss_cls: 0.2555  loss_box_reg: 0.4192  loss_mask: 0.3327  loss_rpn_cls: 0.02221  loss_rpn_loc: 0.03239    time: 0.3354  last_time: 0.2970  data_time: 0.0036  last_data_time: 0.0036   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:45:56 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 6679  total_loss: 0.9206  loss_cls: 0.2019  loss_box_reg: 0.3403  loss_mask: 0.3586  loss_rpn_cls: 0.02126  loss_rpn_loc: 0.03144    time: 0.3355  last_time: 0.3586  data_time: 0.0036  last_data_time: 0.0031   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:46:02 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 6699  total_loss: 0.8936  loss_cls: 0.1889  loss_box_reg: 0.3289  loss_mask: 0.3629  loss_rpn_cls: 0.01409  loss_rpn_loc: 0.03279    time: 0.3354  last_time: 0.3277  data_time: 0.0035  last_data_time: 0.0032   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:46:09 d2.utils.events]: \u001b[0m eta: 0:12:25  iter: 6719  total_loss: 0.948  loss_cls: 0.2119  loss_box_reg: 0.3305  loss_mask: 0.3388  loss_rpn_cls: 0.02124  loss_rpn_loc: 0.03152    time: 0.3354  last_time: 0.3296  data_time: 0.0037  last_data_time: 0.0037   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:46:16 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 6739  total_loss: 1.01  loss_cls: 0.2117  loss_box_reg: 0.3533  loss_mask: 0.325  loss_rpn_cls: 0.02197  loss_rpn_loc: 0.03441    time: 0.3355  last_time: 0.3217  data_time: 0.0037  last_data_time: 0.0032   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:46:23 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 6759  total_loss: 0.9493  loss_cls: 0.2001  loss_box_reg: 0.328  loss_mask: 0.3163  loss_rpn_cls: 0.02468  loss_rpn_loc: 0.03475    time: 0.3355  last_time: 0.3635  data_time: 0.0037  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:46:30 d2.utils.events]: \u001b[0m eta: 0:12:05  iter: 6779  total_loss: 0.9754  loss_cls: 0.2065  loss_box_reg: 0.3526  loss_mask: 0.3289  loss_rpn_cls: 0.01971  loss_rpn_loc: 0.03252    time: 0.3356  last_time: 0.2975  data_time: 0.0037  last_data_time: 0.0030   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:46:37 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 6799  total_loss: 0.938  loss_cls: 0.2235  loss_box_reg: 0.3242  loss_mask: 0.329  loss_rpn_cls: 0.02481  loss_rpn_loc: 0.03206    time: 0.3356  last_time: 0.3203  data_time: 0.0038  last_data_time: 0.0039   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:46:44 d2.utils.events]: \u001b[0m eta: 0:11:52  iter: 6819  total_loss: 0.9195  loss_cls: 0.2306  loss_box_reg: 0.3509  loss_mask: 0.3234  loss_rpn_cls: 0.01905  loss_rpn_loc: 0.0266    time: 0.3356  last_time: 0.3617  data_time: 0.0036  last_data_time: 0.0038   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:46:50 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 6839  total_loss: 0.9217  loss_cls: 0.2166  loss_box_reg: 0.3175  loss_mask: 0.333  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.02752    time: 0.3356  last_time: 0.3229  data_time: 0.0038  last_data_time: 0.0035   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:46:57 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 6859  total_loss: 0.9322  loss_cls: 0.205  loss_box_reg: 0.3319  loss_mask: 0.3219  loss_rpn_cls: 0.01926  loss_rpn_loc: 0.03336    time: 0.3355  last_time: 0.3002  data_time: 0.0037  last_data_time: 0.0030   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:47:03 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 6879  total_loss: 0.8996  loss_cls: 0.1917  loss_box_reg: 0.3148  loss_mask: 0.3224  loss_rpn_cls: 0.01718  loss_rpn_loc: 0.03069    time: 0.3355  last_time: 0.3628  data_time: 0.0034  last_data_time: 0.0029   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:47:10 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 6899  total_loss: 0.9822  loss_cls: 0.2283  loss_box_reg: 0.3482  loss_mask: 0.3445  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.03129    time: 0.3355  last_time: 0.3395  data_time: 0.0038  last_data_time: 0.0040   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:47:17 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 6919  total_loss: 0.8469  loss_cls: 0.1824  loss_box_reg: 0.3005  loss_mask: 0.3117  loss_rpn_cls: 0.01955  loss_rpn_loc: 0.02918    time: 0.3356  last_time: 0.3251  data_time: 0.0037  last_data_time: 0.0033   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:47:24 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 6939  total_loss: 0.9341  loss_cls: 0.2009  loss_box_reg: 0.3196  loss_mask: 0.3315  loss_rpn_cls: 0.0247  loss_rpn_loc: 0.0349    time: 0.3356  last_time: 0.3377  data_time: 0.0038  last_data_time: 0.0033   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:47:31 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 6959  total_loss: 0.8737  loss_cls: 0.1947  loss_box_reg: 0.2953  loss_mask: 0.3374  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.03056    time: 0.3356  last_time: 0.3441  data_time: 0.0037  last_data_time: 0.0037   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:47:38 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 6979  total_loss: 0.9514  loss_cls: 0.2194  loss_box_reg: 0.3495  loss_mask: 0.3257  loss_rpn_cls: 0.01963  loss_rpn_loc: 0.02912    time: 0.3356  last_time: 0.3244  data_time: 0.0037  last_data_time: 0.0039   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:47:45 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:47:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:47:45 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:47:45 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:47:45 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:47:45 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:47:45 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:47:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0012 s/iter. Inference: 0.0780 s/iter. Eval: 0.1763 s/iter. Total: 0.2555 s/iter. ETA=0:00:51\n",
      "\u001b[32m[06/23 13:47:53 d2.evaluation.evaluator]: \u001b[0mInference done 30/213. Dataloading: 0.0013 s/iter. Inference: 0.0795 s/iter. Eval: 0.1881 s/iter. Total: 0.2690 s/iter. ETA=0:00:49\n",
      "\u001b[32m[06/23 13:47:58 d2.evaluation.evaluator]: \u001b[0mInference done 49/213. Dataloading: 0.0013 s/iter. Inference: 0.0790 s/iter. Eval: 0.1939 s/iter. Total: 0.2744 s/iter. ETA=0:00:44\n",
      "\u001b[32m[06/23 13:48:03 d2.evaluation.evaluator]: \u001b[0mInference done 69/213. Dataloading: 0.0014 s/iter. Inference: 0.0784 s/iter. Eval: 0.1880 s/iter. Total: 0.2678 s/iter. ETA=0:00:38\n",
      "\u001b[32m[06/23 13:48:08 d2.evaluation.evaluator]: \u001b[0mInference done 95/213. Dataloading: 0.0013 s/iter. Inference: 0.0762 s/iter. Eval: 0.1690 s/iter. Total: 0.2467 s/iter. ETA=0:00:29\n",
      "\u001b[32m[06/23 13:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 114/213. Dataloading: 0.0015 s/iter. Inference: 0.0765 s/iter. Eval: 0.1766 s/iter. Total: 0.2547 s/iter. ETA=0:00:25\n",
      "\u001b[32m[06/23 13:48:19 d2.evaluation.evaluator]: \u001b[0mInference done 136/213. Dataloading: 0.0015 s/iter. Inference: 0.0764 s/iter. Eval: 0.1730 s/iter. Total: 0.2509 s/iter. ETA=0:00:19\n",
      "\u001b[32m[06/23 13:48:24 d2.evaluation.evaluator]: \u001b[0mInference done 161/213. Dataloading: 0.0015 s/iter. Inference: 0.0756 s/iter. Eval: 0.1661 s/iter. Total: 0.2433 s/iter. ETA=0:00:12\n",
      "\u001b[32m[06/23 13:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 176/213. Dataloading: 0.0014 s/iter. Inference: 0.0760 s/iter. Eval: 0.1745 s/iter. Total: 0.2520 s/iter. ETA=0:00:09\n",
      "\u001b[32m[06/23 13:48:34 d2.evaluation.evaluator]: \u001b[0mInference done 202/213. Dataloading: 0.0014 s/iter. Inference: 0.0748 s/iter. Eval: 0.1677 s/iter. Total: 0.2441 s/iter. ETA=0:00:02\n",
      "\u001b[32m[06/23 13:48:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.883322 (0.244631 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:48:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.074258 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:48:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:48:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:48:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.46s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.536\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.405\n",
      "\u001b[32m[06/23 13:48:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.698 | 53.595 | 8.373  | 4.737 | 16.792 | 21.833 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.54s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.517\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374\n",
      "\u001b[32m[06/23 13:48:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.414 | 51.731 | 7.477  | 3.181 | 12.923 | 21.491 |\n",
      "\u001b[32m[06/23 13:48:38 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: 19.6978,53.5954,8.3730,4.7368,16.7925,21.8328\n",
      "\u001b[32m[06/23 13:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:48:38 d2.evaluation.testing]: \u001b[0mcopypaste: 18.4137,51.7309,7.4772,3.1812,12.9230,21.4915\n",
      "\u001b[32m[06/23 13:48:38 d2.utils.events]: \u001b[0m eta: 0:10:51  iter: 6999  total_loss: 0.8678  loss_cls: 0.1967  loss_box_reg: 0.2977  loss_mask: 0.3307  loss_rpn_cls: 0.01605  loss_rpn_loc: 0.0213    time: 0.3356  last_time: 0.3427  data_time: 0.0036  last_data_time: 0.0035   lr: 2.5e-05  max_mem: 5355M\n",
      "val_loss (1.126734210178256, 7000)\n",
      "Iteration 7000: Validation Loss = 1.1267\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_7000.pth\n",
      "Early stopping triggered. Stopping training.\n",
      "\u001b[32m[06/23 13:48:46 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 7019  total_loss: 1.029  loss_cls: 0.2266  loss_box_reg: 0.3827  loss_mask: 0.3153  loss_rpn_cls: 0.01917  loss_rpn_loc: 0.03785    time: 0.3357  last_time: 0.3380  data_time: 0.0039  last_data_time: 0.0041   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:48:52 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 7039  total_loss: 0.9242  loss_cls: 0.2134  loss_box_reg: 0.3223  loss_mask: 0.3287  loss_rpn_cls: 0.01851  loss_rpn_loc: 0.02946    time: 0.3357  last_time: 0.3609  data_time: 0.0038  last_data_time: 0.0038   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:48:59 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 7059  total_loss: 1.023  loss_cls: 0.2172  loss_box_reg: 0.3516  loss_mask: 0.3377  loss_rpn_cls: 0.03077  loss_rpn_loc: 0.03916    time: 0.3357  last_time: 0.3393  data_time: 0.0037  last_data_time: 0.0036   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:49:06 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 7079  total_loss: 0.8869  loss_cls: 0.2095  loss_box_reg: 0.3161  loss_mask: 0.3142  loss_rpn_cls: 0.02133  loss_rpn_loc: 0.0353    time: 0.3357  last_time: 0.3556  data_time: 0.0037  last_data_time: 0.0038   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:49:13 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 7099  total_loss: 0.9839  loss_cls: 0.1897  loss_box_reg: 0.3392  loss_mask: 0.309  loss_rpn_cls: 0.01878  loss_rpn_loc: 0.03328    time: 0.3358  last_time: 0.4120  data_time: 0.0036  last_data_time: 0.0038   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:49:20 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 7119  total_loss: 1.006  loss_cls: 0.2197  loss_box_reg: 0.3641  loss_mask: 0.3262  loss_rpn_cls: 0.01952  loss_rpn_loc: 0.03279    time: 0.3358  last_time: 0.3717  data_time: 0.0038  last_data_time: 0.0032   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:49:26 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 7139  total_loss: 0.9272  loss_cls: 0.1965  loss_box_reg: 0.2876  loss_mask: 0.3594  loss_rpn_cls: 0.02382  loss_rpn_loc: 0.03006    time: 0.3358  last_time: 0.3224  data_time: 0.0038  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:49:33 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 7159  total_loss: 0.9633  loss_cls: 0.214  loss_box_reg: 0.3673  loss_mask: 0.323  loss_rpn_cls: 0.02068  loss_rpn_loc: 0.03994    time: 0.3358  last_time: 0.3460  data_time: 0.0034  last_data_time: 0.0030   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:49:40 d2.utils.events]: \u001b[0m eta: 0:09:47  iter: 7179  total_loss: 0.8393  loss_cls: 0.1723  loss_box_reg: 0.2994  loss_mask: 0.3232  loss_rpn_cls: 0.0199  loss_rpn_loc: 0.02683    time: 0.3358  last_time: 0.3298  data_time: 0.0036  last_data_time: 0.0031   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:49:47 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 7199  total_loss: 0.9827  loss_cls: 0.2253  loss_box_reg: 0.335  loss_mask: 0.3233  loss_rpn_cls: 0.02422  loss_rpn_loc: 0.03682    time: 0.3358  last_time: 0.3447  data_time: 0.0037  last_data_time: 0.0042   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:49:54 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 7219  total_loss: 0.8271  loss_cls: 0.2033  loss_box_reg: 0.2754  loss_mask: 0.3321  loss_rpn_cls: 0.02153  loss_rpn_loc: 0.02775    time: 0.3358  last_time: 0.2670  data_time: 0.0039  last_data_time: 0.0061   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:50:01 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 7239  total_loss: 0.8536  loss_cls: 0.1854  loss_box_reg: 0.2898  loss_mask: 0.3158  loss_rpn_cls: 0.01671  loss_rpn_loc: 0.02631    time: 0.3358  last_time: 0.3255  data_time: 0.0036  last_data_time: 0.0040   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:50:07 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 7259  total_loss: 0.8749  loss_cls: 0.2057  loss_box_reg: 0.2958  loss_mask: 0.333  loss_rpn_cls: 0.01997  loss_rpn_loc: 0.03114    time: 0.3358  last_time: 0.3254  data_time: 0.0036  last_data_time: 0.0042   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:50:14 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 7279  total_loss: 0.8911  loss_cls: 0.1962  loss_box_reg: 0.3339  loss_mask: 0.3326  loss_rpn_cls: 0.02478  loss_rpn_loc: 0.02511    time: 0.3359  last_time: 0.3179  data_time: 0.0036  last_data_time: 0.0033   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:50:21 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 7299  total_loss: 0.9761  loss_cls: 0.2069  loss_box_reg: 0.3448  loss_mask: 0.3385  loss_rpn_cls: 0.01677  loss_rpn_loc: 0.03033    time: 0.3359  last_time: 0.3185  data_time: 0.0037  last_data_time: 0.0038   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:50:28 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 7319  total_loss: 0.9577  loss_cls: 0.2246  loss_box_reg: 0.3321  loss_mask: 0.3282  loss_rpn_cls: 0.02671  loss_rpn_loc: 0.03783    time: 0.3359  last_time: 0.3582  data_time: 0.0037  last_data_time: 0.0032   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:50:35 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 7339  total_loss: 0.9977  loss_cls: 0.2195  loss_box_reg: 0.3756  loss_mask: 0.3179  loss_rpn_cls: 0.02794  loss_rpn_loc: 0.0395    time: 0.3359  last_time: 0.2938  data_time: 0.0035  last_data_time: 0.0036   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:50:42 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 7359  total_loss: 1.133  loss_cls: 0.2527  loss_box_reg: 0.4341  loss_mask: 0.3304  loss_rpn_cls: 0.02175  loss_rpn_loc: 0.0586    time: 0.3359  last_time: 0.3317  data_time: 0.0037  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:50:48 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 7379  total_loss: 0.8867  loss_cls: 0.181  loss_box_reg: 0.2694  loss_mask: 0.3611  loss_rpn_cls: 0.02338  loss_rpn_loc: 0.02603    time: 0.3359  last_time: 0.3352  data_time: 0.0037  last_data_time: 0.0033   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:50:55 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 7399  total_loss: 0.8361  loss_cls: 0.1666  loss_box_reg: 0.2982  loss_mask: 0.3304  loss_rpn_cls: 0.02788  loss_rpn_loc: 0.0322    time: 0.3359  last_time: 0.3318  data_time: 0.0036  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:51:02 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 7419  total_loss: 0.9551  loss_cls: 0.2026  loss_box_reg: 0.3616  loss_mask: 0.3522  loss_rpn_cls: 0.02309  loss_rpn_loc: 0.03046    time: 0.3360  last_time: 0.2911  data_time: 0.0038  last_data_time: 0.0036   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:51:09 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 7439  total_loss: 0.8728  loss_cls: 0.196  loss_box_reg: 0.3132  loss_mask: 0.3421  loss_rpn_cls: 0.01253  loss_rpn_loc: 0.02538    time: 0.3360  last_time: 0.3707  data_time: 0.0038  last_data_time: 0.0039   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:51:16 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 7459  total_loss: 0.9195  loss_cls: 0.2026  loss_box_reg: 0.3297  loss_mask: 0.3173  loss_rpn_cls: 0.02119  loss_rpn_loc: 0.03239    time: 0.3360  last_time: 0.3325  data_time: 0.0035  last_data_time: 0.0035   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:51:22 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 7479  total_loss: 0.8993  loss_cls: 0.1893  loss_box_reg: 0.3333  loss_mask: 0.3218  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.02835    time: 0.3360  last_time: 0.3114  data_time: 0.0035  last_data_time: 0.0033   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:51:29 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:51:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:51:29 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:51:29 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:51:29 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:51:29 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:51:29 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:51:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:51:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0012 s/iter. Inference: 0.0759 s/iter. Eval: 0.1759 s/iter. Total: 0.2530 s/iter. ETA=0:00:51\n",
      "\u001b[32m[06/23 13:51:37 d2.evaluation.evaluator]: \u001b[0mInference done 28/213. Dataloading: 0.0013 s/iter. Inference: 0.0801 s/iter. Eval: 0.2039 s/iter. Total: 0.2854 s/iter. ETA=0:00:52\n",
      "\u001b[32m[06/23 13:51:42 d2.evaluation.evaluator]: \u001b[0mInference done 47/213. Dataloading: 0.0013 s/iter. Inference: 0.0788 s/iter. Eval: 0.1962 s/iter. Total: 0.2765 s/iter. ETA=0:00:45\n",
      "\u001b[32m[06/23 13:51:47 d2.evaluation.evaluator]: \u001b[0mInference done 63/213. Dataloading: 0.0014 s/iter. Inference: 0.0795 s/iter. Eval: 0.2080 s/iter. Total: 0.2890 s/iter. ETA=0:00:43\n",
      "\u001b[32m[06/23 13:51:52 d2.evaluation.evaluator]: \u001b[0mInference done 90/213. Dataloading: 0.0014 s/iter. Inference: 0.0768 s/iter. Eval: 0.1789 s/iter. Total: 0.2571 s/iter. ETA=0:00:31\n",
      "\u001b[32m[06/23 13:51:58 d2.evaluation.evaluator]: \u001b[0mInference done 109/213. Dataloading: 0.0014 s/iter. Inference: 0.0764 s/iter. Eval: 0.1829 s/iter. Total: 0.2608 s/iter. ETA=0:00:27\n",
      "\u001b[32m[06/23 13:52:03 d2.evaluation.evaluator]: \u001b[0mInference done 128/213. Dataloading: 0.0014 s/iter. Inference: 0.0767 s/iter. Eval: 0.1836 s/iter. Total: 0.2618 s/iter. ETA=0:00:22\n",
      "\u001b[32m[06/23 13:52:08 d2.evaluation.evaluator]: \u001b[0mInference done 150/213. Dataloading: 0.0013 s/iter. Inference: 0.0764 s/iter. Eval: 0.1789 s/iter. Total: 0.2568 s/iter. ETA=0:00:16\n",
      "\u001b[32m[06/23 13:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 169/213. Dataloading: 0.0013 s/iter. Inference: 0.0765 s/iter. Eval: 0.1818 s/iter. Total: 0.2597 s/iter. ETA=0:00:11\n",
      "\u001b[32m[06/23 13:52:18 d2.evaluation.evaluator]: \u001b[0mInference done 193/213. Dataloading: 0.0013 s/iter. Inference: 0.0761 s/iter. Eval: 0.1761 s/iter. Total: 0.2536 s/iter. ETA=0:00:05\n",
      "\u001b[32m[06/23 13:52:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:52.103308 (0.250497 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:52:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.074769 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:52:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:52:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:52:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.48s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.531\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
      "\u001b[32m[06/23 13:52:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.360 | 53.095 | 8.487  | 4.848 | 16.478 | 21.481 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.56s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.506\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n",
      "\u001b[32m[06/23 13:52:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.136 | 50.622 | 7.782  | 3.300 | 12.629 | 21.246 |\n",
      "\u001b[32m[06/23 13:52:24 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:52:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:52:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:52:24 d2.evaluation.testing]: \u001b[0mcopypaste: 19.3605,53.0955,8.4868,4.8480,16.4781,21.4810\n",
      "\u001b[32m[06/23 13:52:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:52:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:52:24 d2.evaluation.testing]: \u001b[0mcopypaste: 18.1358,50.6219,7.7825,3.2999,12.6290,21.2464\n",
      "\u001b[32m[06/23 13:52:24 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 7499  total_loss: 0.9221  loss_cls: 0.1967  loss_box_reg: 0.3208  loss_mask: 0.3167  loss_rpn_cls: 0.01685  loss_rpn_loc: 0.02967    time: 0.3360  last_time: 0.3508  data_time: 0.0036  last_data_time: 0.0036   lr: 2.5e-05  max_mem: 5355M\n",
      "val_loss (0.9881944395601749, 7500)\n",
      "Iteration 7500: Validation Loss = 0.9882\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_7500.pth\n",
      "Early stopping triggered. Stopping training.\n",
      "\u001b[32m[06/23 13:52:31 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 7519  total_loss: 1.001  loss_cls: 0.232  loss_box_reg: 0.3596  loss_mask: 0.3508  loss_rpn_cls: 0.02288  loss_rpn_loc: 0.04349    time: 0.3360  last_time: 0.3555  data_time: 0.0037  last_data_time: 0.0043   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:52:38 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 7539  total_loss: 0.989  loss_cls: 0.231  loss_box_reg: 0.3837  loss_mask: 0.3269  loss_rpn_cls: 0.02439  loss_rpn_loc: 0.03102    time: 0.3360  last_time: 0.2498  data_time: 0.0037  last_data_time: 0.0042   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:52:45 d2.utils.events]: \u001b[0m eta: 0:07:38  iter: 7559  total_loss: 0.9171  loss_cls: 0.1966  loss_box_reg: 0.3335  loss_mask: 0.3245  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.02749    time: 0.3361  last_time: 0.3563  data_time: 0.0037  last_data_time: 0.0039   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:52:52 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 7579  total_loss: 0.9207  loss_cls: 0.1978  loss_box_reg: 0.3268  loss_mask: 0.3149  loss_rpn_cls: 0.01716  loss_rpn_loc: 0.03035    time: 0.3361  last_time: 0.3281  data_time: 0.0038  last_data_time: 0.0037   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:52:59 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 7599  total_loss: 0.8091  loss_cls: 0.1943  loss_box_reg: 0.2599  loss_mask: 0.3178  loss_rpn_cls: 0.0184  loss_rpn_loc: 0.02375    time: 0.3361  last_time: 0.3276  data_time: 0.0037  last_data_time: 0.0040   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:53:06 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 7619  total_loss: 0.9504  loss_cls: 0.2304  loss_box_reg: 0.3716  loss_mask: 0.3174  loss_rpn_cls: 0.01851  loss_rpn_loc: 0.03501    time: 0.3362  last_time: 0.3514  data_time: 0.0035  last_data_time: 0.0033   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:53:12 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 7639  total_loss: 0.9296  loss_cls: 0.2055  loss_box_reg: 0.3347  loss_mask: 0.3296  loss_rpn_cls: 0.02073  loss_rpn_loc: 0.03186    time: 0.3362  last_time: 0.3713  data_time: 0.0035  last_data_time: 0.0041   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:53:19 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 7659  total_loss: 1.02  loss_cls: 0.2357  loss_box_reg: 0.3881  loss_mask: 0.3511  loss_rpn_cls: 0.02903  loss_rpn_loc: 0.03608    time: 0.3362  last_time: 0.3661  data_time: 0.0036  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:53:26 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 7679  total_loss: 0.9962  loss_cls: 0.2046  loss_box_reg: 0.3536  loss_mask: 0.3575  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.03272    time: 0.3362  last_time: 0.2988  data_time: 0.0037  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:53:33 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 7699  total_loss: 1.019  loss_cls: 0.2123  loss_box_reg: 0.3269  loss_mask: 0.3385  loss_rpn_cls: 0.02599  loss_rpn_loc: 0.03699    time: 0.3362  last_time: 0.3273  data_time: 0.0036  last_data_time: 0.0037   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:53:40 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 7719  total_loss: 0.9449  loss_cls: 0.1903  loss_box_reg: 0.3146  loss_mask: 0.3166  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.0293    time: 0.3362  last_time: 0.3437  data_time: 0.0037  last_data_time: 0.0043   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:53:47 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 7739  total_loss: 0.938  loss_cls: 0.2236  loss_box_reg: 0.317  loss_mask: 0.3164  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.02958    time: 0.3362  last_time: 0.3649  data_time: 0.0036  last_data_time: 0.0031   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:53:53 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 7759  total_loss: 0.8546  loss_cls: 0.2025  loss_box_reg: 0.3124  loss_mask: 0.3371  loss_rpn_cls: 0.01834  loss_rpn_loc: 0.02449    time: 0.3362  last_time: 0.2833  data_time: 0.0034  last_data_time: 0.0035   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:54:00 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 7779  total_loss: 0.9238  loss_cls: 0.2224  loss_box_reg: 0.337  loss_mask: 0.3167  loss_rpn_cls: 0.01982  loss_rpn_loc: 0.0321    time: 0.3362  last_time: 0.3635  data_time: 0.0036  last_data_time: 0.0042   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:54:07 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 7799  total_loss: 0.9511  loss_cls: 0.2086  loss_box_reg: 0.3234  loss_mask: 0.3376  loss_rpn_cls: 0.02467  loss_rpn_loc: 0.03776    time: 0.3363  last_time: 0.3477  data_time: 0.0035  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:54:14 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 7819  total_loss: 0.8311  loss_cls: 0.1817  loss_box_reg: 0.3101  loss_mask: 0.3164  loss_rpn_cls: 0.01534  loss_rpn_loc: 0.02376    time: 0.3363  last_time: 0.3387  data_time: 0.0035  last_data_time: 0.0034   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:54:21 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 7839  total_loss: 1.03  loss_cls: 0.2398  loss_box_reg: 0.3916  loss_mask: 0.3383  loss_rpn_cls: 0.02489  loss_rpn_loc: 0.03582    time: 0.3363  last_time: 0.3754  data_time: 0.0036  last_data_time: 0.0049   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:54:28 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 7859  total_loss: 0.9207  loss_cls: 0.2074  loss_box_reg: 0.3397  loss_mask: 0.3352  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.02892    time: 0.3363  last_time: 0.4041  data_time: 0.0038  last_data_time: 0.0036   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:54:35 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 7879  total_loss: 0.9838  loss_cls: 0.2141  loss_box_reg: 0.382  loss_mask: 0.3324  loss_rpn_cls: 0.02013  loss_rpn_loc: 0.03187    time: 0.3363  last_time: 0.3468  data_time: 0.0037  last_data_time: 0.0045   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:54:41 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 7899  total_loss: 0.915  loss_cls: 0.1856  loss_box_reg: 0.3303  loss_mask: 0.3164  loss_rpn_cls: 0.01858  loss_rpn_loc: 0.02788    time: 0.3363  last_time: 0.4230  data_time: 0.0037  last_data_time: 0.0066   lr: 2.5e-05  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:54:48 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 7919  total_loss: 0.9435  loss_cls: 0.2247  loss_box_reg: 0.3456  loss_mask: 0.3208  loss_rpn_cls: 0.02804  loss_rpn_loc: 0.0353    time: 0.3363  last_time: 0.3425  data_time: 0.0036  last_data_time: 0.0052   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:54:55 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 7939  total_loss: 0.8689  loss_cls: 0.1787  loss_box_reg: 0.3382  loss_mask: 0.3289  loss_rpn_cls: 0.02398  loss_rpn_loc: 0.03847    time: 0.3363  last_time: 0.3717  data_time: 0.0035  last_data_time: 0.0037   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:55:02 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 7959  total_loss: 0.9025  loss_cls: 0.2145  loss_box_reg: 0.3267  loss_mask: 0.348  loss_rpn_cls: 0.01958  loss_rpn_loc: 0.02784    time: 0.3364  last_time: 0.3284  data_time: 0.0036  last_data_time: 0.0033   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:55:08 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 7979  total_loss: 0.8552  loss_cls: 0.1759  loss_box_reg: 0.2627  loss_mask: 0.3504  loss_rpn_cls: 0.01327  loss_rpn_loc: 0.01883    time: 0.3364  last_time: 0.3825  data_time: 0.0038  last_data_time: 0.0034   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:55:15 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:55:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:55:15 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:55:15 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:55:15 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:55:15 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:55:15 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:55:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0761 s/iter. Eval: 0.1664 s/iter. Total: 0.2436 s/iter. ETA=0:00:49\n",
      "\u001b[32m[06/23 13:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 29/213. Dataloading: 0.0014 s/iter. Inference: 0.0789 s/iter. Eval: 0.1895 s/iter. Total: 0.2698 s/iter. ETA=0:00:49\n",
      "\u001b[32m[06/23 13:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 49/213. Dataloading: 0.0014 s/iter. Inference: 0.0782 s/iter. Eval: 0.1906 s/iter. Total: 0.2702 s/iter. ETA=0:00:44\n",
      "\u001b[32m[06/23 13:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 71/213. Dataloading: 0.0014 s/iter. Inference: 0.0774 s/iter. Eval: 0.1781 s/iter. Total: 0.2569 s/iter. ETA=0:00:36\n",
      "\u001b[32m[06/23 13:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 98/213. Dataloading: 0.0014 s/iter. Inference: 0.0748 s/iter. Eval: 0.1600 s/iter. Total: 0.2363 s/iter. ETA=0:00:27\n",
      "\u001b[32m[06/23 13:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 114/213. Dataloading: 0.0016 s/iter. Inference: 0.0756 s/iter. Eval: 0.1712 s/iter. Total: 0.2485 s/iter. ETA=0:00:24\n",
      "\u001b[32m[06/23 13:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 136/213. Dataloading: 0.0015 s/iter. Inference: 0.0756 s/iter. Eval: 0.1681 s/iter. Total: 0.2453 s/iter. ETA=0:00:18\n",
      "\u001b[32m[06/23 13:55:54 d2.evaluation.evaluator]: \u001b[0mInference done 162/213. Dataloading: 0.0015 s/iter. Inference: 0.0751 s/iter. Eval: 0.1644 s/iter. Total: 0.2411 s/iter. ETA=0:00:12\n",
      "\u001b[32m[06/23 13:55:59 d2.evaluation.evaluator]: \u001b[0mInference done 180/213. Dataloading: 0.0015 s/iter. Inference: 0.0752 s/iter. Eval: 0.1682 s/iter. Total: 0.2449 s/iter. ETA=0:00:08\n",
      "\u001b[32m[06/23 13:56:04 d2.evaluation.evaluator]: \u001b[0mInference done 207/213. Dataloading: 0.0015 s/iter. Inference: 0.0740 s/iter. Eval: 0.1615 s/iter. Total: 0.2370 s/iter. ETA=0:00:01\n",
      "\u001b[32m[06/23 13:56:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.452744 (0.237754 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:56:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.073679 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:56:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:56:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:56:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.46s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.528\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "\u001b[32m[06/23 13:56:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.321 | 52.760 | 8.355  | 4.808 | 16.534 | 21.487 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.54s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.511\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.071\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
      "\u001b[32m[06/23 13:56:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.178 | 51.110 | 7.056  | 3.139 | 12.613 | 21.292 |\n",
      "\u001b[32m[06/23 13:56:07 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: 19.3208,52.7601,8.3549,4.8081,16.5345,21.4866\n",
      "\u001b[32m[06/23 13:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:56:07 d2.evaluation.testing]: \u001b[0mcopypaste: 18.1782,51.1100,7.0561,3.1391,12.6133,21.2917\n",
      "\u001b[32m[06/23 13:56:07 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 7999  total_loss: 0.9074  loss_cls: 0.189  loss_box_reg: 0.3517  loss_mask: 0.3234  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.04388    time: 0.3364  last_time: 0.3648  data_time: 0.0036  last_data_time: 0.0033   lr: 2.5e-06  max_mem: 5355M\n",
      "val_loss (0.7655275743454695, 8000)\n",
      "Iteration 8000: Validation Loss = 0.7655\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_8000.pth\n",
      "Early stopping triggered. Stopping training.\n",
      "\u001b[32m[06/23 13:56:14 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 8019  total_loss: 0.8161  loss_cls: 0.1945  loss_box_reg: 0.2755  loss_mask: 0.3175  loss_rpn_cls: 0.02253  loss_rpn_loc: 0.02632    time: 0.3364  last_time: 0.3321  data_time: 0.0037  last_data_time: 0.0038   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:56:21 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 8039  total_loss: 0.9047  loss_cls: 0.2027  loss_box_reg: 0.3178  loss_mask: 0.3368  loss_rpn_cls: 0.01676  loss_rpn_loc: 0.03717    time: 0.3364  last_time: 0.3718  data_time: 0.0035  last_data_time: 0.0035   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:56:28 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 8059  total_loss: 0.9753  loss_cls: 0.2122  loss_box_reg: 0.3644  loss_mask: 0.3197  loss_rpn_cls: 0.02672  loss_rpn_loc: 0.03675    time: 0.3365  last_time: 0.4078  data_time: 0.0038  last_data_time: 0.0046   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:56:36 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 8079  total_loss: 0.9745  loss_cls: 0.2338  loss_box_reg: 0.38  loss_mask: 0.338  loss_rpn_cls: 0.0216  loss_rpn_loc: 0.03446    time: 0.3365  last_time: 0.3863  data_time: 0.0038  last_data_time: 0.0033   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:56:42 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 8099  total_loss: 0.8942  loss_cls: 0.1847  loss_box_reg: 0.308  loss_mask: 0.3221  loss_rpn_cls: 0.02009  loss_rpn_loc: 0.03457    time: 0.3365  last_time: 0.3809  data_time: 0.0038  last_data_time: 0.0052   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:56:49 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 8119  total_loss: 0.8665  loss_cls: 0.1777  loss_box_reg: 0.2603  loss_mask: 0.3564  loss_rpn_cls: 0.02559  loss_rpn_loc: 0.03197    time: 0.3365  last_time: 0.2986  data_time: 0.0037  last_data_time: 0.0036   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:56:56 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 8139  total_loss: 0.9833  loss_cls: 0.2201  loss_box_reg: 0.3427  loss_mask: 0.3306  loss_rpn_cls: 0.02761  loss_rpn_loc: 0.03577    time: 0.3365  last_time: 0.3235  data_time: 0.0036  last_data_time: 0.0035   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:57:03 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 8159  total_loss: 0.9443  loss_cls: 0.2103  loss_box_reg: 0.3614  loss_mask: 0.3249  loss_rpn_cls: 0.01967  loss_rpn_loc: 0.03375    time: 0.3366  last_time: 0.3158  data_time: 0.0048  last_data_time: 0.0041   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:57:10 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 8179  total_loss: 0.9801  loss_cls: 0.2163  loss_box_reg: 0.3591  loss_mask: 0.3125  loss_rpn_cls: 0.0193  loss_rpn_loc: 0.03822    time: 0.3366  last_time: 0.2873  data_time: 0.0037  last_data_time: 0.0035   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:57:17 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 8199  total_loss: 0.8543  loss_cls: 0.1956  loss_box_reg: 0.2812  loss_mask: 0.3254  loss_rpn_cls: 0.01616  loss_rpn_loc: 0.02395    time: 0.3366  last_time: 0.3507  data_time: 0.0036  last_data_time: 0.0033   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:57:24 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 8219  total_loss: 0.9169  loss_cls: 0.197  loss_box_reg: 0.3115  loss_mask: 0.3335  loss_rpn_cls: 0.0193  loss_rpn_loc: 0.03354    time: 0.3366  last_time: 0.2753  data_time: 0.0036  last_data_time: 0.0035   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:57:31 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 8239  total_loss: 0.884  loss_cls: 0.197  loss_box_reg: 0.3255  loss_mask: 0.3142  loss_rpn_cls: 0.01965  loss_rpn_loc: 0.02519    time: 0.3366  last_time: 0.3200  data_time: 0.0037  last_data_time: 0.0035   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:57:37 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 8259  total_loss: 1.016  loss_cls: 0.2121  loss_box_reg: 0.3728  loss_mask: 0.3319  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.0347    time: 0.3366  last_time: 0.3601  data_time: 0.0036  last_data_time: 0.0034   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:57:44 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 8279  total_loss: 1.014  loss_cls: 0.2427  loss_box_reg: 0.4012  loss_mask: 0.3329  loss_rpn_cls: 0.0209  loss_rpn_loc: 0.03235    time: 0.3367  last_time: 0.3252  data_time: 0.0038  last_data_time: 0.0035   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:57:51 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 8299  total_loss: 0.8577  loss_cls: 0.1836  loss_box_reg: 0.3391  loss_mask: 0.3288  loss_rpn_cls: 0.0193  loss_rpn_loc: 0.03002    time: 0.3367  last_time: 0.3599  data_time: 0.0036  last_data_time: 0.0040   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:57:58 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 8319  total_loss: 0.975  loss_cls: 0.2076  loss_box_reg: 0.3714  loss_mask: 0.3298  loss_rpn_cls: 0.01823  loss_rpn_loc: 0.03902    time: 0.3367  last_time: 0.3750  data_time: 0.0035  last_data_time: 0.0035   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:58:05 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 8339  total_loss: 1.074  loss_cls: 0.2426  loss_box_reg: 0.3701  loss_mask: 0.3264  loss_rpn_cls: 0.03208  loss_rpn_loc: 0.04487    time: 0.3367  last_time: 0.3215  data_time: 0.0035  last_data_time: 0.0033   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:58:12 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 8359  total_loss: 0.9438  loss_cls: 0.2124  loss_box_reg: 0.3406  loss_mask: 0.3303  loss_rpn_cls: 0.01892  loss_rpn_loc: 0.02786    time: 0.3367  last_time: 0.3005  data_time: 0.0038  last_data_time: 0.0034   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:58:18 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 8379  total_loss: 0.8132  loss_cls: 0.1712  loss_box_reg: 0.268  loss_mask: 0.3276  loss_rpn_cls: 0.0194  loss_rpn_loc: 0.02966    time: 0.3367  last_time: 0.3895  data_time: 0.0035  last_data_time: 0.0039   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:58:26 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 8399  total_loss: 0.9558  loss_cls: 0.203  loss_box_reg: 0.3129  loss_mask: 0.3237  loss_rpn_cls: 0.02026  loss_rpn_loc: 0.02882    time: 0.3368  last_time: 0.3525  data_time: 0.0037  last_data_time: 0.0033   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:58:32 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 8419  total_loss: 0.8206  loss_cls: 0.185  loss_box_reg: 0.2957  loss_mask: 0.3085  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.02651    time: 0.3367  last_time: 0.3714  data_time: 0.0035  last_data_time: 0.0039   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:58:39 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 8439  total_loss: 0.8855  loss_cls: 0.1816  loss_box_reg: 0.3147  loss_mask: 0.3106  loss_rpn_cls: 0.018  loss_rpn_loc: 0.03257    time: 0.3367  last_time: 0.2912  data_time: 0.0037  last_data_time: 0.0034   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:58:46 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 8459  total_loss: 0.924  loss_cls: 0.1942  loss_box_reg: 0.3225  loss_mask: 0.3164  loss_rpn_cls: 0.0182  loss_rpn_loc: 0.02559    time: 0.3367  last_time: 0.1842  data_time: 0.0035  last_data_time: 0.0038   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:58:53 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 8479  total_loss: 0.9399  loss_cls: 0.1724  loss_box_reg: 0.3142  loss_mask: 0.3437  loss_rpn_cls: 0.0193  loss_rpn_loc: 0.03707    time: 0.3368  last_time: 0.3439  data_time: 0.0035  last_data_time: 0.0041   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 13:58:59 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 13:58:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 13:58:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 13:58:59 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 13:58:59 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 13:58:59 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 13:58:59 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 13:58:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 13:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0761 s/iter. Eval: 0.1725 s/iter. Total: 0.2497 s/iter. ETA=0:00:50\n",
      "\u001b[32m[06/23 13:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 29/213. Dataloading: 0.0013 s/iter. Inference: 0.0786 s/iter. Eval: 0.1935 s/iter. Total: 0.2735 s/iter. ETA=0:00:50\n",
      "\u001b[32m[06/23 13:59:13 d2.evaluation.evaluator]: \u001b[0mInference done 49/213. Dataloading: 0.0013 s/iter. Inference: 0.0781 s/iter. Eval: 0.1930 s/iter. Total: 0.2724 s/iter. ETA=0:00:44\n",
      "\u001b[32m[06/23 13:59:18 d2.evaluation.evaluator]: \u001b[0mInference done 71/213. Dataloading: 0.0013 s/iter. Inference: 0.0770 s/iter. Eval: 0.1798 s/iter. Total: 0.2582 s/iter. ETA=0:00:36\n",
      "\u001b[32m[06/23 13:59:23 d2.evaluation.evaluator]: \u001b[0mInference done 99/213. Dataloading: 0.0015 s/iter. Inference: 0.0743 s/iter. Eval: 0.1599 s/iter. Total: 0.2357 s/iter. ETA=0:00:26\n",
      "\u001b[32m[06/23 13:59:28 d2.evaluation.evaluator]: \u001b[0mInference done 114/213. Dataloading: 0.0015 s/iter. Inference: 0.0752 s/iter. Eval: 0.1727 s/iter. Total: 0.2495 s/iter. ETA=0:00:24\n",
      "\u001b[32m[06/23 13:59:33 d2.evaluation.evaluator]: \u001b[0mInference done 136/213. Dataloading: 0.0015 s/iter. Inference: 0.0752 s/iter. Eval: 0.1694 s/iter. Total: 0.2462 s/iter. ETA=0:00:18\n",
      "\u001b[32m[06/23 13:59:39 d2.evaluation.evaluator]: \u001b[0mInference done 162/213. Dataloading: 0.0015 s/iter. Inference: 0.0748 s/iter. Eval: 0.1657 s/iter. Total: 0.2420 s/iter. ETA=0:00:12\n",
      "\u001b[32m[06/23 13:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 180/213. Dataloading: 0.0015 s/iter. Inference: 0.0749 s/iter. Eval: 0.1696 s/iter. Total: 0.2460 s/iter. ETA=0:00:08\n",
      "\u001b[32m[06/23 13:59:49 d2.evaluation.evaluator]: \u001b[0mInference done 208/213. Dataloading: 0.0014 s/iter. Inference: 0.0736 s/iter. Eval: 0.1628 s/iter. Total: 0.2379 s/iter. ETA=0:00:01\n",
      "\u001b[32m[06/23 13:59:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.579894 (0.238365 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:59:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.073308 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 13:59:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 13:59:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 13:59:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.46s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.529\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
      "\u001b[32m[06/23 13:59:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.506 | 52.920 | 8.320  | 4.756 | 16.615 | 21.737 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.54s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.513\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
      "\u001b[32m[06/23 13:59:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.232 | 51.302 | 6.799  | 3.170 | 12.669 | 21.334 |\n",
      "\u001b[32m[06/23 13:59:51 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 13:59:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 13:59:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:59:51 d2.evaluation.testing]: \u001b[0mcopypaste: 19.5061,52.9197,8.3198,4.7563,16.6145,21.7366\n",
      "\u001b[32m[06/23 13:59:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 13:59:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 13:59:51 d2.evaluation.testing]: \u001b[0mcopypaste: 18.2321,51.3021,6.7988,3.1702,12.6691,21.3336\n",
      "\u001b[32m[06/23 13:59:51 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 8499  total_loss: 0.9194  loss_cls: 0.1992  loss_box_reg: 0.3207  loss_mask: 0.3406  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.02699    time: 0.3368  last_time: 0.3235  data_time: 0.0036  last_data_time: 0.0033   lr: 2.5e-06  max_mem: 5355M\n",
      "val_loss (1.1431154776364565, 8500)\n",
      "Iteration 8500: Validation Loss = 1.1431\n",
      "Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_iter_8500.pth\n",
      "Early stopping triggered. Stopping training.\n",
      "\u001b[32m[06/23 13:59:59 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 8519  total_loss: 0.9678  loss_cls: 0.2264  loss_box_reg: 0.3558  loss_mask: 0.3161  loss_rpn_cls: 0.02071  loss_rpn_loc: 0.03718    time: 0.3368  last_time: 0.3368  data_time: 0.0036  last_data_time: 0.0029   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:00:06 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 8539  total_loss: 0.9773  loss_cls: 0.2189  loss_box_reg: 0.3297  loss_mask: 0.336  loss_rpn_cls: 0.02123  loss_rpn_loc: 0.04125    time: 0.3368  last_time: 0.3221  data_time: 0.0036  last_data_time: 0.0032   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:00:12 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 8559  total_loss: 0.9246  loss_cls: 0.2503  loss_box_reg: 0.3748  loss_mask: 0.3036  loss_rpn_cls: 0.0177  loss_rpn_loc: 0.0332    time: 0.3368  last_time: 0.3109  data_time: 0.0038  last_data_time: 0.0034   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:00:19 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 8579  total_loss: 0.92  loss_cls: 0.211  loss_box_reg: 0.3227  loss_mask: 0.3287  loss_rpn_cls: 0.02164  loss_rpn_loc: 0.02798    time: 0.3368  last_time: 0.3504  data_time: 0.0036  last_data_time: 0.0041   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:00:26 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 8599  total_loss: 0.9672  loss_cls: 0.2289  loss_box_reg: 0.3477  loss_mask: 0.3175  loss_rpn_cls: 0.02454  loss_rpn_loc: 0.03692    time: 0.3368  last_time: 0.3450  data_time: 0.0036  last_data_time: 0.0036   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:00:33 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 8619  total_loss: 0.755  loss_cls: 0.1501  loss_box_reg: 0.2246  loss_mask: 0.3166  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.0221    time: 0.3368  last_time: 0.3522  data_time: 0.0037  last_data_time: 0.0035   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:00:39 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 8639  total_loss: 0.8673  loss_cls: 0.1915  loss_box_reg: 0.2955  loss_mask: 0.3289  loss_rpn_cls: 0.02084  loss_rpn_loc: 0.03296    time: 0.3368  last_time: 0.3317  data_time: 0.0036  last_data_time: 0.0038   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:00:47 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 8659  total_loss: 0.9938  loss_cls: 0.2021  loss_box_reg: 0.3646  loss_mask: 0.3193  loss_rpn_cls: 0.02012  loss_rpn_loc: 0.03122    time: 0.3369  last_time: 0.3755  data_time: 0.0038  last_data_time: 0.0034   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:00:53 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 8679  total_loss: 0.9707  loss_cls: 0.216  loss_box_reg: 0.3329  loss_mask: 0.3479  loss_rpn_cls: 0.02517  loss_rpn_loc: 0.03489    time: 0.3369  last_time: 0.3486  data_time: 0.0037  last_data_time: 0.0035   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:01:00 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 8699  total_loss: 0.9875  loss_cls: 0.2239  loss_box_reg: 0.3483  loss_mask: 0.3213  loss_rpn_cls: 0.0228  loss_rpn_loc: 0.04723    time: 0.3369  last_time: 0.2986  data_time: 0.0037  last_data_time: 0.0026   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:01:07 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 8719  total_loss: 1.029  loss_cls: 0.2409  loss_box_reg: 0.381  loss_mask: 0.3181  loss_rpn_cls: 0.0249  loss_rpn_loc: 0.03726    time: 0.3369  last_time: 0.2098  data_time: 0.0036  last_data_time: 0.0036   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:01:14 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 8739  total_loss: 0.8234  loss_cls: 0.1684  loss_box_reg: 0.2723  loss_mask: 0.3263  loss_rpn_cls: 0.01861  loss_rpn_loc: 0.02733    time: 0.3369  last_time: 0.3285  data_time: 0.0035  last_data_time: 0.0035   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:01:21 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 8759  total_loss: 0.8909  loss_cls: 0.2109  loss_box_reg: 0.3104  loss_mask: 0.306  loss_rpn_cls: 0.01701  loss_rpn_loc: 0.02765    time: 0.3369  last_time: 0.3945  data_time: 0.0035  last_data_time: 0.0029   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:01:28 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 8779  total_loss: 0.9941  loss_cls: 0.2276  loss_box_reg: 0.3073  loss_mask: 0.3232  loss_rpn_cls: 0.02262  loss_rpn_loc: 0.03903    time: 0.3369  last_time: 0.3527  data_time: 0.0035  last_data_time: 0.0039   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:01:35 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 8799  total_loss: 0.9232  loss_cls: 0.2022  loss_box_reg: 0.3034  loss_mask: 0.3142  loss_rpn_cls: 0.02149  loss_rpn_loc: 0.03499    time: 0.3370  last_time: 0.3509  data_time: 0.0037  last_data_time: 0.0039   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:01:42 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 8819  total_loss: 0.97  loss_cls: 0.2114  loss_box_reg: 0.3307  loss_mask: 0.3463  loss_rpn_cls: 0.02767  loss_rpn_loc: 0.0411    time: 0.3370  last_time: 0.3716  data_time: 0.0036  last_data_time: 0.0034   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:01:48 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 8839  total_loss: 0.8479  loss_cls: 0.1612  loss_box_reg: 0.2567  loss_mask: 0.3352  loss_rpn_cls: 0.02192  loss_rpn_loc: 0.02376    time: 0.3370  last_time: 0.3867  data_time: 0.0035  last_data_time: 0.0032   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:01:55 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 8859  total_loss: 0.9364  loss_cls: 0.2111  loss_box_reg: 0.3726  loss_mask: 0.3522  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.03699    time: 0.3370  last_time: 0.3755  data_time: 0.0035  last_data_time: 0.0033   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:02:02 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 8879  total_loss: 0.8485  loss_cls: 0.1983  loss_box_reg: 0.2837  loss_mask: 0.3221  loss_rpn_cls: 0.02102  loss_rpn_loc: 0.03049    time: 0.3370  last_time: 0.3821  data_time: 0.0035  last_data_time: 0.0044   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:02:09 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 8899  total_loss: 0.9198  loss_cls: 0.2093  loss_box_reg: 0.3151  loss_mask: 0.34  loss_rpn_cls: 0.01983  loss_rpn_loc: 0.02473    time: 0.3370  last_time: 0.3377  data_time: 0.0035  last_data_time: 0.0032   lr: 2.5e-06  max_mem: 5355M\n",
      "\u001b[32m[06/23 14:02:09 d2.engine.hooks]: \u001b[0mOverall training speed: 8898 iterations in 0:49:58 (0.3370 s / it)\n",
      "\u001b[32m[06/23 14:02:09 d2.engine.hooks]: \u001b[0mTotal training time: 1:10:32 (0:20:34 on hooks)\n",
      "\u001b[32m[06/23 14:02:09 d2.data.datasets.coco]: \u001b[0mLoaded 213 images in COCO format from /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/test/test.json\n",
      "\u001b[32m[06/23 14:02:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/23 14:02:09 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/23 14:02:09 d2.data.common]: \u001b[0mSerializing 213 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/23 14:02:09 d2.data.common]: \u001b[0mSerialized dataset takes 4.76 MiB\n",
      "\u001b[32m[06/23 14:02:09 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/23 14:02:09 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/23 14:02:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 213 batches\n",
      "\u001b[32m[06/23 14:02:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/213. Dataloading: 0.0011 s/iter. Inference: 0.0750 s/iter. Eval: 0.1670 s/iter. Total: 0.2431 s/iter. ETA=0:00:49\n",
      "\u001b[32m[06/23 14:02:17 d2.evaluation.evaluator]: \u001b[0mInference done 29/213. Dataloading: 0.0014 s/iter. Inference: 0.0781 s/iter. Eval: 0.1903 s/iter. Total: 0.2699 s/iter. ETA=0:00:49\n",
      "\u001b[32m[06/23 14:02:22 d2.evaluation.evaluator]: \u001b[0mInference done 49/213. Dataloading: 0.0014 s/iter. Inference: 0.0775 s/iter. Eval: 0.1933 s/iter. Total: 0.2723 s/iter. ETA=0:00:44\n",
      "\u001b[32m[06/23 14:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 70/213. Dataloading: 0.0014 s/iter. Inference: 0.0773 s/iter. Eval: 0.1830 s/iter. Total: 0.2617 s/iter. ETA=0:00:37\n",
      "\u001b[32m[06/23 14:02:32 d2.evaluation.evaluator]: \u001b[0mInference done 97/213. Dataloading: 0.0013 s/iter. Inference: 0.0752 s/iter. Eval: 0.1636 s/iter. Total: 0.2402 s/iter. ETA=0:00:27\n",
      "\u001b[32m[06/23 14:02:38 d2.evaluation.evaluator]: \u001b[0mInference done 114/213. Dataloading: 0.0015 s/iter. Inference: 0.0757 s/iter. Eval: 0.1728 s/iter. Total: 0.2502 s/iter. ETA=0:00:24\n",
      "\u001b[32m[06/23 14:02:43 d2.evaluation.evaluator]: \u001b[0mInference done 136/213. Dataloading: 0.0015 s/iter. Inference: 0.0758 s/iter. Eval: 0.1697 s/iter. Total: 0.2470 s/iter. ETA=0:00:19\n",
      "\u001b[32m[06/23 14:02:48 d2.evaluation.evaluator]: \u001b[0mInference done 162/213. Dataloading: 0.0015 s/iter. Inference: 0.0754 s/iter. Eval: 0.1655 s/iter. Total: 0.2425 s/iter. ETA=0:00:12\n",
      "\u001b[32m[06/23 14:02:53 d2.evaluation.evaluator]: \u001b[0mInference done 180/213. Dataloading: 0.0015 s/iter. Inference: 0.0755 s/iter. Eval: 0.1692 s/iter. Total: 0.2463 s/iter. ETA=0:00:08\n",
      "\u001b[32m[06/23 14:02:59 d2.evaluation.evaluator]: \u001b[0mInference done 208/213. Dataloading: 0.0014 s/iter. Inference: 0.0743 s/iter. Eval: 0.1623 s/iter. Total: 0.2381 s/iter. ETA=0:00:01\n",
      "\u001b[32m[06/23 14:03:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.608225 (0.238501 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 14:03:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.073972 s / iter per device, on 1 devices)\n",
      "\u001b[32m[06/23 14:03:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/23 14:03:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/eval/coco_instances_results.json\n",
      "\u001b[32m[06/23 14:03:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.47s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.528\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "\u001b[32m[06/23 14:03:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.511 | 52.811 | 8.849  | 4.756 | 16.522 | 21.750 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.54s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.512\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374\n",
      "\u001b[32m[06/23 14:03:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.199 | 51.217 | 6.943  | 3.170 | 12.727 | 21.308 |\n",
      "\u001b[32m[06/23 14:03:01 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[06/23 14:03:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/23 14:03:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 14:03:01 d2.evaluation.testing]: \u001b[0mcopypaste: 19.5113,52.8113,8.8492,4.7563,16.5217,21.7498\n",
      "\u001b[32m[06/23 14:03:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[06/23 14:03:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/23 14:03:01 d2.evaluation.testing]: \u001b[0mcopypaste: 18.1988,51.2175,6.9429,3.1702,12.7271,21.3081\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1872,
     "status": "ok",
     "timestamp": 1740394196496,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "Xvhx2nCLVVdS",
    "outputId": "b98f673c-4030-4e98-ed51-fc9923f61b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Model saved at: /home/ai_train/skyhub_project/june/23rd_new_dataset_to_train/train/output/model_final_1.pth\n"
     ]
    }
   ],
   "source": [
    "# Save final model\n",
    "final_model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final_1.pth\")\n",
    "torch.save(trainer.model.state_dict(), final_model_path)\n",
    "print(f\"Training complete. Model saved at: {final_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 4231,
     "status": "error",
     "timestamp": 1740394200723,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "sEYeyokzT3dq",
    "outputId": "32626404-dc1e-412b-927f-6bd3dc68633f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Mount Google Drive\u001b[39;00m\n\u001b[1;32m     16\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer, HookBase\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.model_zoo import get_config_file, get_checkpoint_url\n",
    "import numpy as np\n",
    "import time\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "drive_folder = \"/content/drive/My Drive/detectron2_training\"  # Change as needed\n",
    "os.makedirs(drive_folder, exist_ok=True)\n",
    "\n",
    "print(\"Training started...\")\n",
    "setup_logger()\n",
    "\n",
    "# Paths\n",
    "dataset_folder = \"/content/dataset\"  # Update this if dataset is elsewhere\n",
    "train_json = os.path.join(dataset_folder, \"train_annotations.json\")\n",
    "val_json = os.path.join(dataset_folder, \"val_annotations.json\")\n",
    "train_images = os.path.join(dataset_folder, \"train\")\n",
    "val_images = os.path.join(dataset_folder, \"val\")\n",
    "output_dir = os.path.join(drive_folder, \"output\")  # Save output to Google Drive\n",
    "\n",
    "# Register datasets\n",
    "register_coco_instances(\"my_dataset_train\", {}, train_json, train_images)\n",
    "register_coco_instances(\"my_dataset_val\", {}, val_json, val_images)\n",
    "\n",
    "# Get metadata\n",
    "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n",
    "\n",
    "# Configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2  # Reduce for Colab\n",
    "cfg.MODEL.WEIGHTS = get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # Reduce for Colab\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 3750\n",
    "cfg.SOLVER.STEPS = (2500, 3200)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "cfg.OUTPUT_DIR = output_dir\n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Early Stopping & Model Saving Hook\n",
    "class EarlyStoppingHook(HookBase):\n",
    "    def __init__(self, patience=3):  # Stop if no improvement for 3 evals\n",
    "        self.patience = patience\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def after_step(self):\n",
    "        if self.trainer.iter % cfg.TEST.EVAL_PERIOD == 0:\n",
    "            eval_results = self.trainer.storage.latest()\n",
    "            val_loss = eval_results.get(\"total_loss\", None)\n",
    "            if val_loss is not None:\n",
    "                print(f\"Iteration {self.trainer.iter}: Validation Loss = {val_loss:.4f}\")\n",
    "                model_path = os.path.join(cfg.OUTPUT_DIR, f\"model_iter_{self.trainer.iter}.pth\")\n",
    "                torch.save(self.trainer.model.state_dict(), model_path)\n",
    "                print(f\"Model saved at: {model_path}\")\n",
    "                if val_loss < self.best_loss:\n",
    "                    self.best_loss = val_loss\n",
    "                    self.counter = 0\n",
    "                    # Save the best model\n",
    "                    torch.save(self.trainer.model.state_dict(), os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\"))\n",
    "                else:\n",
    "                    self.counter += 1\n",
    "                    if self.counter >= self.patience:\n",
    "                        print(\"Early stopping triggered. Stopping training.\")\n",
    "                        self.trainer.iter = cfg.SOLVER.MAX_ITER  # Force training to stop\n",
    "\n",
    "# Custom Trainer\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"eval\")\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.append(EarlyStoppingHook(patience=3))  # Add early stopping & model saving\n",
    "        return hooks\n",
    "\n",
    "# Train\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "final_model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "torch.save(trainer.model.state_dict(), final_model_path)\n",
    "print(f\"Training complete. Model saved at: {final_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1740394200724,
     "user": {
      "displayName": "Shinu jawade",
      "userId": "11052200146099704379"
     },
     "user_tz": -330
    },
    "id": "TSGaOcWvOBJx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer, HookBase\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.model_zoo import get_config_file, get_checkpoint_url\n",
    "import numpy as np\n",
    "import time\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "drive_folder = \"/content/drive/My Drive/detectron2_training\"  # Change as needed\n",
    "os.makedirs(drive_folder, exist_ok=True)\n",
    "\n",
    "print(\"Training started...\")\n",
    "setup_logger()\n",
    "\n",
    "# Paths\n",
    "dataset_folder = \"/content/dataset\"  # Update this if dataset is elsewhere\n",
    "train_json = os.path.join(dataset_folder, \"train_annotations.json\")\n",
    "val_json = os.path.join(dataset_folder, \"val_annotations.json\")\n",
    "train_images = os.path.join(dataset_folder, \"train\")\n",
    "val_images = os.path.join(dataset_folder, \"val\")\n",
    "output_dir = os.path.join(drive_folder, \"output\")  # Save output to Google Drive\n",
    "\n",
    "# Register datasets\n",
    "register_coco_instances(\"my_dataset_train\", {}, train_json, train_images)\n",
    "register_coco_instances(\"my_dataset_val\", {}, val_json, val_images)\n",
    "\n",
    "# Get metadata\n",
    "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n",
    "\n",
    "# Configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2  # Reduce for Colab\n",
    "cfg.MODEL.WEIGHTS = get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # Reduce for Colab\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 3750\n",
    "cfg.SOLVER.STEPS = (2500, 3200)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "cfg.OUTPUT_DIR = output_dir\n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Early Stopping Hook\n",
    "class EarlyStoppingHook(HookBase):\n",
    "    def __init__(self, patience=3):  # Stop if no improvement for 3 evals\n",
    "        self.patience = patience\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def after_step(self):\n",
    "        if self.trainer.iter % cfg.TEST.EVAL_PERIOD == 0:\n",
    "            eval_results = self.trainer.storage.latest()\n",
    "            val_loss = eval_results.get(\"total_loss\", None)\n",
    "            if val_loss is not None:\n",
    "                print(f\"Iteration {self.trainer.iter}: Validation Loss = {val_loss:.4f}\")\n",
    "                if val_loss < self.best_loss:\n",
    "                    self.best_loss = val_loss\n",
    "                    self.counter = 0\n",
    "                    # Save the best model\n",
    "                    torch.save(self.trainer.model.state_dict(), os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\"))\n",
    "                else:\n",
    "                    self.counter += 1\n",
    "                    if self.counter >= self.patience:\n",
    "                        print(\"Early stopping triggered. Stopping training.\")\n",
    "                        self.trainer.iter = cfg.SOLVER.MAX_ITER  # Force training to stop\n",
    "\n",
    "# Custom Trainer\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"eval\")\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.append(EarlyStoppingHook(patience=3))  # Add early stopping\n",
    "        return hooks\n",
    "\n",
    "# Train\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "final_model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "torch.save(trainer.model.state_dict(), final_model_path)\n",
    "print(f\"Training complete. Model saved at: {final_model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyONyGVwRVHQHSc8GsbW3PLZ",
   "gpuType": "T4",
   "mount_file_id": "158BVD8txxAtemHOURro_wOrrBQULfBQl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
