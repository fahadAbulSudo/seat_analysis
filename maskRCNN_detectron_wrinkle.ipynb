{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5Qz6nOyN5Sb",
        "outputId": "a23e79c6-a4cc-40ff-875c-79a3e93c8cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Detectron2 (specific version for compatibility)\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "# Install COCO API (for dataset handling)\n",
        "!pip install pycocotools\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8djTb37OH9U",
        "outputId": "fd89f253-9f39-4707-94f1-8495037e4185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-c2prqssh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-c2prqssh\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 9604f5995cc628619f0e4fd913453b4d7d61db3f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.5.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (25.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.1.8)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "print(torch.__version__)  # Should match Colab's default (e.g., 2.x)\n",
        "print(detectron2.__version__)  # Should print a version number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNptMke9OoZe",
        "outputId": "b3fabf37-4738-4df3-af9d-7fd3b1860a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n",
            "0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import detectron2\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer, HookBase\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2.model_zoo import get_config_file, get_checkpoint_url\n",
        "import numpy as np\n",
        "import time\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "LNnbO8EcSkJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_folder = \"/content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train\"  # Change as needed\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "print(\"Training started...\")\n",
        "setup_logger()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ8AGJf5Sr6B",
        "outputId": "fe6cbcdd-b4b4-4224-ae14-6d40c382f91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Logger detectron2 (DEBUG)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "dataset_folder = r\"/content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset\"  # Update this if dataset is elsewhere\n",
        "train_json =r'/content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/train_annotations.coco.json' # os.path.join(dataset_folder, \"train_annotations.json\")\n",
        "val_json =r'/content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/val_annotations.coco.json'  #os.path.join(dataset_folder, \"val_annotations.json\")\n",
        "train_images = os.path.join(dataset_folder, \"train\")\n",
        "val_images = os.path.join(dataset_folder, \"valid\")\n",
        "output_dir = os.path.join(drive_folder, \"output\")  # Save output to Google Drive"
      ],
      "metadata": {
        "id": "FRYCW7JGTDe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register datasets\n",
        "register_coco_instances(\"my_dataset_train\", {}, train_json, train_images)\n",
        "register_coco_instances(\"my_dataset_val\", {}, val_json, val_images)"
      ],
      "metadata": {
        "id": "xDXdCixhU2Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get metadata\n",
        "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
        "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n"
      ],
      "metadata": {
        "id": "jMOq1NHrU7J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2  # Reduce for Colab\n",
        "cfg.MODEL.WEIGHTS = get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # Reduce for Colab\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 3750\n",
        "cfg.SOLVER.STEPS = (2500, 3200)\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.TEST.EVAL_PERIOD = 500\n",
        "cfg.OUTPUT_DIR = output_dir\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "e7jThSSUVBQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create output directory\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "j5t-4PduVFcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping & Model Saving Hook\n",
        "class EarlyStoppingHook(HookBase):\n",
        "    def __init__(self, patience=3):  # Stop if no improvement for 3 evals\n",
        "        self.patience = patience\n",
        "        self.best_loss = float('inf')\n",
        "        self.counter = 0\n",
        "\n",
        "    def after_step(self):\n",
        "        if self.trainer.iter % cfg.TEST.EVAL_PERIOD == 0:\n",
        "            eval_results = self.trainer.storage.latest()\n",
        "            val_loss = eval_results.get(\"total_loss\", None)\n",
        "\n",
        "            print(\"val_loss\", val_loss)\n",
        "\n",
        "            # Check if val_loss is not None and is a tuple, then access the first element\n",
        "            if val_loss is not None:\n",
        "                val_loss_value = val_loss[0]  # Access the actual validation loss value\n",
        "\n",
        "                # Print the validation loss correctly\n",
        "                print(f\"Iteration {self.trainer.iter}: Validation Loss = {val_loss_value:.4f}\")\n",
        "\n",
        "                model_path = os.path.join(cfg.OUTPUT_DIR, f\"model_iter_{self.trainer.iter}.pth\")\n",
        "                torch.save(self.trainer.model.state_dict(), model_path)\n",
        "                print(f\"Model saved at: {model_path}\")\n",
        "\n",
        "                # Compare and save the best model based on the loss\n",
        "                if val_loss_value < self.best_loss:\n",
        "                    self.best_loss = val_loss_value\n",
        "                    self.counter = 0\n",
        "                    # Save the best model\n",
        "                    torch.save(self.trainer.model.state_dict(), os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\"))\n",
        "                else:\n",
        "                    self.counter += 1\n",
        "                    if self.counter >= self.patience:\n",
        "                        print(\"Early stopping triggered. Stopping training.\")\n",
        "                        self.trainer.iter = cfg.SOLVER.MAX_ITER  # Force training to stop"
      ],
      "metadata": {
        "id": "bWARjDFzVJ8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Trainer\n",
        "class CocoTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"eval\")\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
        "\n",
        "    def build_hooks(self):\n",
        "        hooks = super().build_hooks()\n",
        "        hooks.append(EarlyStoppingHook(patience=3))  # Add early stopping & model saving\n",
        "        return hooks"
      ],
      "metadata": {
        "id": "GUMS3bRVVNED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "trainer = CocoTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akEXGjMiVQZL",
        "outputId": "0f614dcd-bdae-428a-dfdb-c59ebaf4a43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02/24 10:21:39 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[02/24 10:21:39 d2.data.datasets.coco]: Loaded 144 images in COCO format from /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/train_annotations.coco.json\n",
            "[02/24 10:21:39 d2.data.build]: Removed 3 images with no usable annotations. 141 images left.\n",
            "[02/24 10:21:39 d2.data.build]: Distribution of instances among all 1 categories:\n",
            "|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "|  wrinkle   | 563          |\n",
            "|            |              |\n",
            "[02/24 10:21:39 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[02/24 10:21:39 d2.data.build]: Using training sampler TrainingSampler\n",
            "[02/24 10:21:39 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[02/24 10:21:39 d2.data.common]: Serializing 141 elements to byte tensors and concatenating them all ...\n",
            "[02/24 10:21:39 d2.data.common]: Serialized dataset takes 0.26 MiB\n",
            "[02/24 10:21:39 d2.data.build]: Making batched data loader with batch_size=2\n",
            "[02/24 10:21:39 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02/24 10:21:40 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss (2.5457489900290966, 0)\n",
            "Iteration 0: Validation Loss = 2.5457\n",
            "Model saved at: /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/model_iter_0.pth\n",
            "[02/24 10:21:50 d2.utils.events]:  eta: 0:24:34  iter: 19  total_loss: 2.036  loss_cls: 0.7847  loss_box_reg: 0.09022  loss_mask: 0.6936  loss_rpn_cls: 0.342  loss_rpn_loc: 0.03972    time: 0.3941  last_time: 0.3741  data_time: 0.0165  last_data_time: 0.0058   lr: 4.9953e-06  max_mem: 1770M\n",
            "[02/24 10:22:08 d2.utils.events]:  eta: 0:25:27  iter: 39  total_loss: 2.005  loss_cls: 0.6788  loss_box_reg: 0.1009  loss_mask: 0.6924  loss_rpn_cls: 0.4811  loss_rpn_loc: 0.04567    time: 0.4490  last_time: 0.4074  data_time: 0.0228  last_data_time: 0.0047   lr: 9.9902e-06  max_mem: 1770M\n",
            "[02/24 10:22:16 d2.utils.events]:  eta: 0:25:01  iter: 59  total_loss: 1.735  loss_cls: 0.4817  loss_box_reg: 0.1419  loss_mask: 0.6882  loss_rpn_cls: 0.3507  loss_rpn_loc: 0.04257    time: 0.4306  last_time: 0.3622  data_time: 0.0097  last_data_time: 0.0053   lr: 1.4985e-05  max_mem: 1770M\n",
            "[02/24 10:22:24 d2.utils.events]:  eta: 0:24:35  iter: 79  total_loss: 1.41  loss_cls: 0.3425  loss_box_reg: 0.1353  loss_mask: 0.6833  loss_rpn_cls: 0.2295  loss_rpn_loc: 0.03008    time: 0.4171  last_time: 0.3880  data_time: 0.0054  last_data_time: 0.0054   lr: 1.998e-05  max_mem: 1770M\n",
            "[02/24 10:22:32 d2.utils.events]:  eta: 0:24:21  iter: 99  total_loss: 1.511  loss_cls: 0.278  loss_box_reg: 0.1548  loss_mask: 0.6757  loss_rpn_cls: 0.3946  loss_rpn_loc: 0.04248    time: 0.4123  last_time: 0.3703  data_time: 0.0085  last_data_time: 0.0055   lr: 2.4975e-05  max_mem: 1771M\n",
            "[02/24 10:22:39 d2.utils.events]:  eta: 0:24:07  iter: 119  total_loss: 1.356  loss_cls: 0.2323  loss_box_reg: 0.1649  loss_mask: 0.6759  loss_rpn_cls: 0.1826  loss_rpn_loc: 0.03236    time: 0.4071  last_time: 0.4141  data_time: 0.0097  last_data_time: 0.0364   lr: 2.997e-05  max_mem: 1771M\n",
            "[02/24 10:22:47 d2.utils.events]:  eta: 0:23:42  iter: 139  total_loss: 1.205  loss_cls: 0.212  loss_box_reg: 0.1885  loss_mask: 0.6629  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.02534    time: 0.4043  last_time: 0.3688  data_time: 0.0084  last_data_time: 0.0066   lr: 3.4965e-05  max_mem: 1771M\n",
            "[02/24 10:22:55 d2.utils.events]:  eta: 0:23:39  iter: 159  total_loss: 1.252  loss_cls: 0.213  loss_box_reg: 0.1925  loss_mask: 0.6569  loss_rpn_cls: 0.1192  loss_rpn_loc: 0.02638    time: 0.4031  last_time: 0.3619  data_time: 0.0093  last_data_time: 0.0116   lr: 3.996e-05  max_mem: 1771M\n",
            "[02/24 10:23:03 d2.utils.events]:  eta: 0:23:26  iter: 179  total_loss: 1.283  loss_cls: 0.223  loss_box_reg: 0.2362  loss_mask: 0.6574  loss_rpn_cls: 0.1338  loss_rpn_loc: 0.03855    time: 0.4012  last_time: 0.4252  data_time: 0.0060  last_data_time: 0.0050   lr: 4.4955e-05  max_mem: 1771M\n",
            "[02/24 10:23:11 d2.utils.events]:  eta: 0:23:30  iter: 199  total_loss: 1.246  loss_cls: 0.2207  loss_box_reg: 0.2145  loss_mask: 0.6432  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.03283    time: 0.4026  last_time: 0.3955  data_time: 0.0096  last_data_time: 0.0044   lr: 4.995e-05  max_mem: 1771M\n",
            "[02/24 10:23:19 d2.utils.events]:  eta: 0:23:26  iter: 219  total_loss: 1.222  loss_cls: 0.2069  loss_box_reg: 0.2331  loss_mask: 0.637  loss_rpn_cls: 0.06802  loss_rpn_loc: 0.0323    time: 0.4029  last_time: 0.4329  data_time: 0.0075  last_data_time: 0.0256   lr: 5.4945e-05  max_mem: 1771M\n",
            "[02/24 10:23:27 d2.utils.events]:  eta: 0:23:22  iter: 239  total_loss: 1.25  loss_cls: 0.2179  loss_box_reg: 0.2273  loss_mask: 0.6459  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.0353    time: 0.4038  last_time: 0.3443  data_time: 0.0059  last_data_time: 0.0057   lr: 5.994e-05  max_mem: 1771M\n",
            "[02/24 10:23:35 d2.utils.events]:  eta: 0:23:15  iter: 259  total_loss: 1.229  loss_cls: 0.2328  loss_box_reg: 0.2938  loss_mask: 0.6203  loss_rpn_cls: 0.07861  loss_rpn_loc: 0.03099    time: 0.4035  last_time: 0.4043  data_time: 0.0081  last_data_time: 0.0048   lr: 6.4935e-05  max_mem: 1771M\n",
            "[02/24 10:23:43 d2.utils.events]:  eta: 0:23:08  iter: 279  total_loss: 1.09  loss_cls: 0.1896  loss_box_reg: 0.2175  loss_mask: 0.579  loss_rpn_cls: 0.05758  loss_rpn_loc: 0.02727    time: 0.4034  last_time: 0.4315  data_time: 0.0053  last_data_time: 0.0046   lr: 6.993e-05  max_mem: 1771M\n",
            "[02/24 10:23:51 d2.utils.events]:  eta: 0:22:59  iter: 299  total_loss: 1.179  loss_cls: 0.1981  loss_box_reg: 0.2396  loss_mask: 0.6067  loss_rpn_cls: 0.09352  loss_rpn_loc: 0.03158    time: 0.4028  last_time: 0.3588  data_time: 0.0110  last_data_time: 0.0051   lr: 7.4925e-05  max_mem: 1772M\n",
            "[02/24 10:23:59 d2.utils.events]:  eta: 0:22:48  iter: 319  total_loss: 1.152  loss_cls: 0.2017  loss_box_reg: 0.2503  loss_mask: 0.5881  loss_rpn_cls: 0.05882  loss_rpn_loc: 0.03995    time: 0.4024  last_time: 0.4148  data_time: 0.0057  last_data_time: 0.0169   lr: 7.992e-05  max_mem: 1772M\n",
            "[02/24 10:24:07 d2.utils.events]:  eta: 0:22:43  iter: 339  total_loss: 1.167  loss_cls: 0.2181  loss_box_reg: 0.2651  loss_mask: 0.5708  loss_rpn_cls: 0.06382  loss_rpn_loc: 0.03412    time: 0.4027  last_time: 0.3776  data_time: 0.0083  last_data_time: 0.0072   lr: 8.4915e-05  max_mem: 1772M\n",
            "[02/24 10:24:15 d2.utils.events]:  eta: 0:22:35  iter: 359  total_loss: 1.165  loss_cls: 0.2136  loss_box_reg: 0.246  loss_mask: 0.558  loss_rpn_cls: 0.05169  loss_rpn_loc: 0.03201    time: 0.4028  last_time: 0.4121  data_time: 0.0122  last_data_time: 0.0047   lr: 8.991e-05  max_mem: 1772M\n",
            "[02/24 10:24:24 d2.utils.events]:  eta: 0:22:27  iter: 379  total_loss: 1.126  loss_cls: 0.2194  loss_box_reg: 0.2886  loss_mask: 0.5441  loss_rpn_cls: 0.05078  loss_rpn_loc: 0.03817    time: 0.4028  last_time: 0.4814  data_time: 0.0058  last_data_time: 0.0051   lr: 9.4905e-05  max_mem: 1837M\n",
            "[02/24 10:24:32 d2.utils.events]:  eta: 0:22:22  iter: 399  total_loss: 1.133  loss_cls: 0.2104  loss_box_reg: 0.2909  loss_mask: 0.54  loss_rpn_cls: 0.07814  loss_rpn_loc: 0.03007    time: 0.4030  last_time: 0.4035  data_time: 0.0067  last_data_time: 0.0056   lr: 9.99e-05  max_mem: 1837M\n",
            "[02/24 10:24:40 d2.utils.events]:  eta: 0:22:14  iter: 419  total_loss: 1.106  loss_cls: 0.2073  loss_box_reg: 0.2573  loss_mask: 0.5215  loss_rpn_cls: 0.08146  loss_rpn_loc: 0.02977    time: 0.4031  last_time: 0.4411  data_time: 0.0068  last_data_time: 0.0089   lr: 0.0001049  max_mem: 1837M\n",
            "[02/24 10:24:48 d2.utils.events]:  eta: 0:22:07  iter: 439  total_loss: 1.091  loss_cls: 0.2041  loss_box_reg: 0.2846  loss_mask: 0.5228  loss_rpn_cls: 0.05725  loss_rpn_loc: 0.02775    time: 0.4031  last_time: 0.4442  data_time: 0.0095  last_data_time: 0.0055   lr: 0.00010989  max_mem: 1837M\n",
            "[02/24 10:24:56 d2.utils.events]:  eta: 0:22:01  iter: 459  total_loss: 1.178  loss_cls: 0.2116  loss_box_reg: 0.3008  loss_mask: 0.5227  loss_rpn_cls: 0.05446  loss_rpn_loc: 0.02775    time: 0.4034  last_time: 0.4213  data_time: 0.0115  last_data_time: 0.0053   lr: 0.00011489  max_mem: 1837M\n",
            "[02/24 10:25:05 d2.utils.events]:  eta: 0:21:55  iter: 479  total_loss: 1.118  loss_cls: 0.2122  loss_box_reg: 0.3273  loss_mask: 0.4804  loss_rpn_cls: 0.07816  loss_rpn_loc: 0.02797    time: 0.4042  last_time: 0.4341  data_time: 0.0056  last_data_time: 0.0051   lr: 0.00011988  max_mem: 1837M\n",
            "[02/24 10:25:13 d2.data.datasets.coco]: Loaded 36 images in COCO format from /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/val_annotations.coco.json\n",
            "[02/24 10:25:13 d2.data.build]: Distribution of instances among all 1 categories:\n",
            "|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "|  wrinkle   | 130          |\n",
            "|            |              |\n",
            "[02/24 10:25:13 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[02/24 10:25:13 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[02/24 10:25:13 d2.data.common]: Serializing 36 elements to byte tensors and concatenating them all ...\n",
            "[02/24 10:25:13 d2.data.common]: Serialized dataset takes 0.06 MiB\n",
            "WARNING [02/24 10:25:13 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[02/24 10:25:13 d2.evaluation.evaluator]: Start inference on 36 batches\n",
            "[02/24 10:25:18 d2.evaluation.evaluator]: Inference done 11/36. Dataloading: 0.0952 s/iter. Inference: 0.1118 s/iter. Eval: 0.1503 s/iter. Total: 0.3572 s/iter. ETA=0:00:08\n",
            "[02/24 10:25:23 d2.evaluation.evaluator]: Inference done 25/36. Dataloading: 0.1097 s/iter. Inference: 0.1108 s/iter. Eval: 0.1452 s/iter. Total: 0.3661 s/iter. ETA=0:00:04\n",
            "[02/24 10:25:26 d2.evaluation.evaluator]: Total inference time: 0:00:10.645908 (0.343416 s / iter per device, on 1 devices)\n",
            "[02/24 10:25:26 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:03 (0.108982 s / iter per device, on 1 devices)\n",
            "[02/24 10:25:26 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[02/24 10:25:26 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/eval/coco_instances_results.json\n",
            "[02/24 10:25:26 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:25:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[02/24 10:25:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "[02/24 10:25:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:25:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.238\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.203\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.380\n",
            "[02/24 10:25:26 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.674 | 23.843 | 8.807  |  nan  | 0.630 | 13.272 |\n",
            "[02/24 10:25:26 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:25:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[02/24 10:25:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.\n",
            "[02/24 10:25:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:25:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.152\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
            "[02/24 10:25:26 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 8.264 | 17.415 | 6.476  |  nan  | 0.117 | 10.425 |\n",
            "[02/24 10:25:26 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[02/24 10:25:26 d2.engine.defaults]: Evaluation results for my_dataset_val in csv format:\n",
            "[02/24 10:25:26 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[02/24 10:25:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:25:26 d2.evaluation.testing]: copypaste: 10.6738,23.8429,8.8065,nan,0.6305,13.2720\n",
            "[02/24 10:25:26 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[02/24 10:25:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:25:26 d2.evaluation.testing]: copypaste: 8.2644,17.4147,6.4759,nan,0.1174,10.4252\n",
            "[02/24 10:25:26 d2.utils.events]:  eta: 0:21:50  iter: 499  total_loss: 1.201  loss_cls: 0.2095  loss_box_reg: 0.3166  loss_mask: 0.5578  loss_rpn_cls: 0.04584  loss_rpn_loc: 0.02842    time: 0.4052  last_time: 0.4435  data_time: 0.0067  last_data_time: 0.0050   lr: 0.00012488  max_mem: 1837M\n",
            "val_loss (1.2013898082077503, 500)\n",
            "Iteration 500: Validation Loss = 1.2014\n",
            "Model saved at: /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/model_iter_500.pth\n",
            "[02/24 10:25:36 d2.utils.events]:  eta: 0:21:43  iter: 519  total_loss: 1.129  loss_cls: 0.2101  loss_box_reg: 0.2988  loss_mask: 0.4836  loss_rpn_cls: 0.04508  loss_rpn_loc: 0.03015    time: 0.4059  last_time: 0.5122  data_time: 0.0063  last_data_time: 0.0080   lr: 0.00012987  max_mem: 1837M\n",
            "[02/24 10:25:45 d2.utils.events]:  eta: 0:21:36  iter: 539  total_loss: 1.114  loss_cls: 0.2096  loss_box_reg: 0.3167  loss_mask: 0.5435  loss_rpn_cls: 0.05698  loss_rpn_loc: 0.02893    time: 0.4065  last_time: 0.3934  data_time: 0.0067  last_data_time: 0.0048   lr: 0.00013487  max_mem: 1837M\n",
            "[02/24 10:25:53 d2.utils.events]:  eta: 0:21:29  iter: 559  total_loss: 1.089  loss_cls: 0.1919  loss_box_reg: 0.29  loss_mask: 0.4572  loss_rpn_cls: 0.05503  loss_rpn_loc: 0.02366    time: 0.4066  last_time: 0.3609  data_time: 0.0088  last_data_time: 0.0054   lr: 0.00013986  max_mem: 1837M\n",
            "[02/24 10:26:01 d2.utils.events]:  eta: 0:21:26  iter: 579  total_loss: 1.294  loss_cls: 0.2622  loss_box_reg: 0.3628  loss_mask: 0.5246  loss_rpn_cls: 0.06632  loss_rpn_loc: 0.03569    time: 0.4074  last_time: 0.5093  data_time: 0.0080  last_data_time: 0.0348   lr: 0.00014486  max_mem: 1892M\n",
            "[02/24 10:26:10 d2.utils.events]:  eta: 0:21:19  iter: 599  total_loss: 1.111  loss_cls: 0.205  loss_box_reg: 0.3352  loss_mask: 0.4584  loss_rpn_cls: 0.05694  loss_rpn_loc: 0.02957    time: 0.4078  last_time: 0.3923  data_time: 0.0061  last_data_time: 0.0050   lr: 0.00014985  max_mem: 1892M\n",
            "[02/24 10:26:18 d2.utils.events]:  eta: 0:21:15  iter: 619  total_loss: 1.057  loss_cls: 0.2159  loss_box_reg: 0.3295  loss_mask: 0.4671  loss_rpn_cls: 0.03614  loss_rpn_loc: 0.02859    time: 0.4085  last_time: 0.4292  data_time: 0.0093  last_data_time: 0.0091   lr: 0.00015485  max_mem: 1892M\n",
            "[02/24 10:26:26 d2.utils.events]:  eta: 0:21:07  iter: 639  total_loss: 0.9491  loss_cls: 0.1706  loss_box_reg: 0.2923  loss_mask: 0.4642  loss_rpn_cls: 0.03021  loss_rpn_loc: 0.02323    time: 0.4082  last_time: 0.3652  data_time: 0.0056  last_data_time: 0.0047   lr: 0.00015984  max_mem: 1910M\n",
            "[02/24 10:26:35 d2.utils.events]:  eta: 0:20:59  iter: 659  total_loss: 1.185  loss_cls: 0.233  loss_box_reg: 0.3549  loss_mask: 0.5008  loss_rpn_cls: 0.04287  loss_rpn_loc: 0.03134    time: 0.4083  last_time: 0.3654  data_time: 0.0102  last_data_time: 0.0057   lr: 0.00016484  max_mem: 1910M\n",
            "[02/24 10:26:43 d2.utils.events]:  eta: 0:20:53  iter: 679  total_loss: 1.17  loss_cls: 0.2466  loss_box_reg: 0.3206  loss_mask: 0.4911  loss_rpn_cls: 0.03918  loss_rpn_loc: 0.02853    time: 0.4087  last_time: 0.4537  data_time: 0.0078  last_data_time: 0.0061   lr: 0.00016983  max_mem: 1910M\n",
            "[02/24 10:26:51 d2.utils.events]:  eta: 0:20:45  iter: 699  total_loss: 1.147  loss_cls: 0.2488  loss_box_reg: 0.3213  loss_mask: 0.4467  loss_rpn_cls: 0.04353  loss_rpn_loc: 0.02508    time: 0.4089  last_time: 0.3678  data_time: 0.0070  last_data_time: 0.0124   lr: 0.00017483  max_mem: 1910M\n",
            "[02/24 10:27:00 d2.utils.events]:  eta: 0:20:38  iter: 719  total_loss: 1.035  loss_cls: 0.204  loss_box_reg: 0.2966  loss_mask: 0.4429  loss_rpn_cls: 0.02706  loss_rpn_loc: 0.02175    time: 0.4091  last_time: 0.4462  data_time: 0.0097  last_data_time: 0.0053   lr: 0.00017982  max_mem: 1910M\n",
            "[02/24 10:27:08 d2.utils.events]:  eta: 0:20:30  iter: 739  total_loss: 1.048  loss_cls: 0.224  loss_box_reg: 0.3461  loss_mask: 0.4556  loss_rpn_cls: 0.02337  loss_rpn_loc: 0.02444    time: 0.4093  last_time: 0.4015  data_time: 0.0053  last_data_time: 0.0050   lr: 0.00018482  max_mem: 1910M\n",
            "[02/24 10:27:17 d2.utils.events]:  eta: 0:20:22  iter: 759  total_loss: 1.136  loss_cls: 0.251  loss_box_reg: 0.3507  loss_mask: 0.4677  loss_rpn_cls: 0.03187  loss_rpn_loc: 0.02694    time: 0.4097  last_time: 0.3830  data_time: 0.0062  last_data_time: 0.0057   lr: 0.00018981  max_mem: 1914M\n",
            "[02/24 10:27:25 d2.utils.events]:  eta: 0:20:13  iter: 779  total_loss: 1.049  loss_cls: 0.2142  loss_box_reg: 0.2949  loss_mask: 0.4719  loss_rpn_cls: 0.04098  loss_rpn_loc: 0.03179    time: 0.4099  last_time: 0.4806  data_time: 0.0073  last_data_time: 0.0188   lr: 0.00019481  max_mem: 1914M\n",
            "[02/24 10:27:34 d2.utils.events]:  eta: 0:20:07  iter: 799  total_loss: 1.065  loss_cls: 0.2139  loss_box_reg: 0.2818  loss_mask: 0.4314  loss_rpn_cls: 0.03681  loss_rpn_loc: 0.02414    time: 0.4104  last_time: 0.4038  data_time: 0.0061  last_data_time: 0.0057   lr: 0.0001998  max_mem: 1914M\n",
            "[02/24 10:27:42 d2.utils.events]:  eta: 0:19:59  iter: 819  total_loss: 0.9318  loss_cls: 0.1863  loss_box_reg: 0.2859  loss_mask: 0.4252  loss_rpn_cls: 0.02689  loss_rpn_loc: 0.01625    time: 0.4104  last_time: 0.4227  data_time: 0.0085  last_data_time: 0.0053   lr: 0.0002048  max_mem: 1944M\n",
            "[02/24 10:27:50 d2.utils.events]:  eta: 0:19:52  iter: 839  total_loss: 0.9918  loss_cls: 0.2169  loss_box_reg: 0.2935  loss_mask: 0.4443  loss_rpn_cls: 0.03307  loss_rpn_loc: 0.02377    time: 0.4107  last_time: 0.4289  data_time: 0.0052  last_data_time: 0.0052   lr: 0.00020979  max_mem: 1944M\n",
            "[02/24 10:27:59 d2.utils.events]:  eta: 0:19:46  iter: 859  total_loss: 0.9283  loss_cls: 0.1968  loss_box_reg: 0.2754  loss_mask: 0.3988  loss_rpn_cls: 0.02789  loss_rpn_loc: 0.02309    time: 0.4112  last_time: 0.4343  data_time: 0.0059  last_data_time: 0.0057   lr: 0.00021479  max_mem: 1944M\n",
            "[02/24 10:28:07 d2.utils.events]:  eta: 0:19:38  iter: 879  total_loss: 0.9448  loss_cls: 0.2006  loss_box_reg: 0.243  loss_mask: 0.4206  loss_rpn_cls: 0.03613  loss_rpn_loc: 0.03194    time: 0.4114  last_time: 0.3857  data_time: 0.0111  last_data_time: 0.0048   lr: 0.00021978  max_mem: 1944M\n",
            "[02/24 10:28:16 d2.utils.events]:  eta: 0:19:29  iter: 899  total_loss: 0.9656  loss_cls: 0.2025  loss_box_reg: 0.2406  loss_mask: 0.4672  loss_rpn_cls: 0.02837  loss_rpn_loc: 0.02314    time: 0.4114  last_time: 0.3238  data_time: 0.0055  last_data_time: 0.0077   lr: 0.00022478  max_mem: 1989M\n",
            "[02/24 10:28:24 d2.utils.events]:  eta: 0:19:22  iter: 919  total_loss: 1.03  loss_cls: 0.2093  loss_box_reg: 0.3229  loss_mask: 0.4182  loss_rpn_cls: 0.02293  loss_rpn_loc: 0.02077    time: 0.4120  last_time: 0.3896  data_time: 0.0142  last_data_time: 0.0074   lr: 0.00022977  max_mem: 1989M\n",
            "[02/24 10:28:33 d2.utils.events]:  eta: 0:19:15  iter: 939  total_loss: 0.9865  loss_cls: 0.2194  loss_box_reg: 0.2655  loss_mask: 0.4355  loss_rpn_cls: 0.03152  loss_rpn_loc: 0.03303    time: 0.4125  last_time: 0.4872  data_time: 0.0095  last_data_time: 0.0067   lr: 0.00023477  max_mem: 1989M\n",
            "[02/24 10:28:42 d2.utils.events]:  eta: 0:19:07  iter: 959  total_loss: 1.113  loss_cls: 0.2511  loss_box_reg: 0.351  loss_mask: 0.435  loss_rpn_cls: 0.02645  loss_rpn_loc: 0.0283    time: 0.4129  last_time: 0.4882  data_time: 0.0055  last_data_time: 0.0053   lr: 0.00023976  max_mem: 1989M\n",
            "[02/24 10:28:50 d2.utils.events]:  eta: 0:18:59  iter: 979  total_loss: 0.8193  loss_cls: 0.154  loss_box_reg: 0.2206  loss_mask: 0.3828  loss_rpn_cls: 0.01716  loss_rpn_loc: 0.0204    time: 0.4129  last_time: 0.3873  data_time: 0.0088  last_data_time: 0.0047   lr: 0.00024476  max_mem: 1989M\n",
            "[02/24 10:28:59 d2.data.datasets.coco]: Loaded 36 images in COCO format from /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/val_annotations.coco.json\n",
            "[02/24 10:28:59 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[02/24 10:28:59 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[02/24 10:28:59 d2.data.common]: Serializing 36 elements to byte tensors and concatenating them all ...\n",
            "[02/24 10:28:59 d2.data.common]: Serialized dataset takes 0.06 MiB\n",
            "WARNING [02/24 10:28:59 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[02/24 10:28:59 d2.evaluation.evaluator]: Start inference on 36 batches\n",
            "[02/24 10:29:01 d2.evaluation.evaluator]: Inference done 11/36. Dataloading: 0.0013 s/iter. Inference: 0.0901 s/iter. Eval: 0.0362 s/iter. Total: 0.1276 s/iter. ETA=0:00:03\n",
            "[02/24 10:29:04 d2.evaluation.evaluator]: Total inference time: 0:00:03.848253 (0.124137 s / iter per device, on 1 devices)\n",
            "[02/24 10:29:04 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.089678 s / iter per device, on 1 devices)\n",
            "[02/24 10:29:04 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[02/24 10:29:04 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/eval/coco_instances_results.json\n",
            "[02/24 10:29:04 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:29:04 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[02/24 10:29:04 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "[02/24 10:29:04 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:29:04 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.444\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.202\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.253\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476\n",
            "[02/24 10:29:04 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 21.123 | 44.414 | 20.232 |  nan  | 5.670 | 25.268 |\n",
            "[02/24 10:29:04 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:29:04 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[02/24 10:29:04 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "[02/24 10:29:04 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:29:04 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.122\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.245\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.274\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "[02/24 10:29:04 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 15.133 | 37.787 | 9.924  |  nan  | 3.933 | 18.251 |\n",
            "[02/24 10:29:04 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[02/24 10:29:04 d2.engine.defaults]: Evaluation results for my_dataset_val in csv format:\n",
            "[02/24 10:29:04 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[02/24 10:29:04 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:29:04 d2.evaluation.testing]: copypaste: 21.1234,44.4135,20.2322,nan,5.6701,25.2679\n",
            "[02/24 10:29:04 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[02/24 10:29:04 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:29:04 d2.evaluation.testing]: copypaste: 15.1330,37.7871,9.9242,nan,3.9328,18.2515\n",
            "[02/24 10:29:04 d2.utils.events]:  eta: 0:18:52  iter: 999  total_loss: 0.9846  loss_cls: 0.2054  loss_box_reg: 0.313  loss_mask: 0.4128  loss_rpn_cls: 0.02439  loss_rpn_loc: 0.02252    time: 0.4135  last_time: 0.4461  data_time: 0.0077  last_data_time: 0.0194   lr: 0.00024975  max_mem: 1989M\n",
            "val_loss (0.953982787206769, 1000)\n",
            "Iteration 1000: Validation Loss = 0.9540\n",
            "Model saved at: /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/model_iter_1000.pth\n",
            "[02/24 10:29:14 d2.utils.events]:  eta: 0:18:45  iter: 1019  total_loss: 0.9025  loss_cls: 0.1931  loss_box_reg: 0.2225  loss_mask: 0.377  loss_rpn_cls: 0.01907  loss_rpn_loc: 0.0197    time: 0.4140  last_time: 0.3911  data_time: 0.0108  last_data_time: 0.0208   lr: 0.00025  max_mem: 1989M\n",
            "[02/24 10:29:23 d2.utils.events]:  eta: 0:18:36  iter: 1039  total_loss: 0.9054  loss_cls: 0.2081  loss_box_reg: 0.286  loss_mask: 0.4048  loss_rpn_cls: 0.03346  loss_rpn_loc: 0.02668    time: 0.4145  last_time: 0.4172  data_time: 0.0067  last_data_time: 0.0061   lr: 0.00025  max_mem: 1989M\n",
            "[02/24 10:29:31 d2.utils.events]:  eta: 0:18:31  iter: 1059  total_loss: 0.8053  loss_cls: 0.1685  loss_box_reg: 0.2056  loss_mask: 0.3868  loss_rpn_cls: 0.01914  loss_rpn_loc: 0.01927    time: 0.4147  last_time: 0.3519  data_time: 0.0085  last_data_time: 0.0083   lr: 0.00025  max_mem: 1989M\n",
            "[02/24 10:29:40 d2.utils.events]:  eta: 0:18:25  iter: 1079  total_loss: 0.8249  loss_cls: 0.1567  loss_box_reg: 0.2345  loss_mask: 0.4162  loss_rpn_cls: 0.01753  loss_rpn_loc: 0.02467    time: 0.4148  last_time: 0.5037  data_time: 0.0083  last_data_time: 0.0105   lr: 0.00025  max_mem: 1989M\n",
            "[02/24 10:29:48 d2.utils.events]:  eta: 0:18:18  iter: 1099  total_loss: 0.8764  loss_cls: 0.183  loss_box_reg: 0.2966  loss_mask: 0.3759  loss_rpn_cls: 0.01882  loss_rpn_loc: 0.01953    time: 0.4151  last_time: 0.4642  data_time: 0.0054  last_data_time: 0.0055   lr: 0.00025  max_mem: 1989M\n",
            "[02/24 10:29:57 d2.utils.events]:  eta: 0:18:11  iter: 1119  total_loss: 0.8841  loss_cls: 0.1809  loss_box_reg: 0.269  loss_mask: 0.3828  loss_rpn_cls: 0.02394  loss_rpn_loc: 0.02208    time: 0.4151  last_time: 0.3820  data_time: 0.0076  last_data_time: 0.0053   lr: 0.00025  max_mem: 1989M\n",
            "[02/24 10:30:05 d2.utils.events]:  eta: 0:18:04  iter: 1139  total_loss: 0.9845  loss_cls: 0.214  loss_box_reg: 0.32  loss_mask: 0.4042  loss_rpn_cls: 0.02495  loss_rpn_loc: 0.0176    time: 0.4151  last_time: 0.3247  data_time: 0.0062  last_data_time: 0.0123   lr: 0.00025  max_mem: 1989M\n",
            "[02/24 10:30:14 d2.utils.events]:  eta: 0:17:58  iter: 1159  total_loss: 0.876  loss_cls: 0.1702  loss_box_reg: 0.2679  loss_mask: 0.3799  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.01848    time: 0.4154  last_time: 0.4555  data_time: 0.0064  last_data_time: 0.0056   lr: 0.00025  max_mem: 1989M\n",
            "[02/24 10:30:23 d2.utils.events]:  eta: 0:17:52  iter: 1179  total_loss: 0.8854  loss_cls: 0.2014  loss_box_reg: 0.2882  loss_mask: 0.3776  loss_rpn_cls: 0.01796  loss_rpn_loc: 0.01625    time: 0.4158  last_time: 0.4524  data_time: 0.0069  last_data_time: 0.0048   lr: 0.00025  max_mem: 1989M\n",
            "[02/24 10:30:31 d2.utils.events]:  eta: 0:17:44  iter: 1199  total_loss: 0.9544  loss_cls: 0.198  loss_box_reg: 0.2595  loss_mask: 0.3883  loss_rpn_cls: 0.02375  loss_rpn_loc: 0.02326    time: 0.4160  last_time: 0.4544  data_time: 0.0055  last_data_time: 0.0051   lr: 0.00025  max_mem: 2089M\n",
            "[02/24 10:30:40 d2.utils.events]:  eta: 0:17:36  iter: 1219  total_loss: 0.735  loss_cls: 0.1593  loss_box_reg: 0.2135  loss_mask: 0.3654  loss_rpn_cls: 0.01608  loss_rpn_loc: 0.01174    time: 0.4162  last_time: 0.4747  data_time: 0.0079  last_data_time: 0.0048   lr: 0.00025  max_mem: 2089M\n",
            "[02/24 10:30:48 d2.utils.events]:  eta: 0:17:31  iter: 1239  total_loss: 0.9094  loss_cls: 0.1993  loss_box_reg: 0.2761  loss_mask: 0.3799  loss_rpn_cls: 0.01664  loss_rpn_loc: 0.02141    time: 0.4164  last_time: 0.3797  data_time: 0.0060  last_data_time: 0.0049   lr: 0.00025  max_mem: 2089M\n",
            "[02/24 10:30:57 d2.utils.events]:  eta: 0:17:23  iter: 1259  total_loss: 0.8603  loss_cls: 0.1754  loss_box_reg: 0.277  loss_mask: 0.3522  loss_rpn_cls: 0.01768  loss_rpn_loc: 0.02328    time: 0.4165  last_time: 0.4941  data_time: 0.0054  last_data_time: 0.0064   lr: 0.00025  max_mem: 2089M\n",
            "[02/24 10:31:05 d2.utils.events]:  eta: 0:17:16  iter: 1279  total_loss: 0.8061  loss_cls: 0.1675  loss_box_reg: 0.2612  loss_mask: 0.3726  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.01872    time: 0.4168  last_time: 0.4094  data_time: 0.0095  last_data_time: 0.0051   lr: 0.00025  max_mem: 2089M\n",
            "[02/24 10:31:14 d2.utils.events]:  eta: 0:17:10  iter: 1299  total_loss: 0.8992  loss_cls: 0.2013  loss_box_reg: 0.2864  loss_mask: 0.3846  loss_rpn_cls: 0.01385  loss_rpn_loc: 0.01868    time: 0.4169  last_time: 0.4278  data_time: 0.0053  last_data_time: 0.0060   lr: 0.00025  max_mem: 2089M\n",
            "[02/24 10:31:23 d2.utils.events]:  eta: 0:17:05  iter: 1319  total_loss: 0.8249  loss_cls: 0.172  loss_box_reg: 0.2406  loss_mask: 0.345  loss_rpn_cls: 0.009435  loss_rpn_loc: 0.01517    time: 0.4172  last_time: 0.4423  data_time: 0.0056  last_data_time: 0.0053   lr: 0.00025  max_mem: 2089M\n",
            "[02/24 10:31:32 d2.utils.events]:  eta: 0:16:58  iter: 1339  total_loss: 1.024  loss_cls: 0.2299  loss_box_reg: 0.3456  loss_mask: 0.3946  loss_rpn_cls: 0.02335  loss_rpn_loc: 0.02645    time: 0.4177  last_time: 0.4568  data_time: 0.0107  last_data_time: 0.0075   lr: 0.00025  max_mem: 2089M\n",
            "[02/24 10:31:40 d2.utils.events]:  eta: 0:16:52  iter: 1359  total_loss: 0.8018  loss_cls: 0.1744  loss_box_reg: 0.2338  loss_mask: 0.3356  loss_rpn_cls: 0.01859  loss_rpn_loc: 0.01683    time: 0.4179  last_time: 0.3856  data_time: 0.0083  last_data_time: 0.0052   lr: 0.00025  max_mem: 2089M\n",
            "[02/24 10:31:49 d2.utils.events]:  eta: 0:16:46  iter: 1379  total_loss: 0.754  loss_cls: 0.1532  loss_box_reg: 0.2435  loss_mask: 0.3618  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.02147    time: 0.4182  last_time: 0.4389  data_time: 0.0070  last_data_time: 0.0051   lr: 0.00025  max_mem: 2089M\n",
            "[02/24 10:31:58 d2.utils.events]:  eta: 0:16:39  iter: 1399  total_loss: 0.7392  loss_cls: 0.143  loss_box_reg: 0.2233  loss_mask: 0.3522  loss_rpn_cls: 0.01271  loss_rpn_loc: 0.01733    time: 0.4184  last_time: 0.3675  data_time: 0.0075  last_data_time: 0.0056   lr: 0.00025  max_mem: 2089M\n",
            "[02/24 10:32:06 d2.utils.events]:  eta: 0:16:31  iter: 1419  total_loss: 0.9138  loss_cls: 0.2118  loss_box_reg: 0.295  loss_mask: 0.3592  loss_rpn_cls: 0.01983  loss_rpn_loc: 0.02165    time: 0.4184  last_time: 0.4038  data_time: 0.0068  last_data_time: 0.0249   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:32:15 d2.utils.events]:  eta: 0:16:25  iter: 1439  total_loss: 0.8096  loss_cls: 0.1756  loss_box_reg: 0.2575  loss_mask: 0.3472  loss_rpn_cls: 0.01718  loss_rpn_loc: 0.01955    time: 0.4186  last_time: 0.5137  data_time: 0.0056  last_data_time: 0.0051   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:32:23 d2.utils.events]:  eta: 0:16:18  iter: 1459  total_loss: 0.8591  loss_cls: 0.1731  loss_box_reg: 0.2356  loss_mask: 0.3586  loss_rpn_cls: 0.009264  loss_rpn_loc: 0.0214    time: 0.4188  last_time: 0.4168  data_time: 0.0099  last_data_time: 0.0056   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:32:32 d2.utils.events]:  eta: 0:16:10  iter: 1479  total_loss: 0.7754  loss_cls: 0.1693  loss_box_reg: 0.2249  loss_mask: 0.3461  loss_rpn_cls: 0.01425  loss_rpn_loc: 0.01891    time: 0.4189  last_time: 0.4297  data_time: 0.0056  last_data_time: 0.0055   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:32:41 d2.data.datasets.coco]: Loaded 36 images in COCO format from /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/val_annotations.coco.json\n",
            "[02/24 10:32:41 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[02/24 10:32:41 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[02/24 10:32:41 d2.data.common]: Serializing 36 elements to byte tensors and concatenating them all ...\n",
            "[02/24 10:32:41 d2.data.common]: Serialized dataset takes 0.06 MiB\n",
            "WARNING [02/24 10:32:41 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[02/24 10:32:41 d2.evaluation.evaluator]: Start inference on 36 batches\n",
            "[02/24 10:32:42 d2.evaluation.evaluator]: Inference done 11/36. Dataloading: 0.0014 s/iter. Inference: 0.0863 s/iter. Eval: 0.0213 s/iter. Total: 0.1090 s/iter. ETA=0:00:02\n",
            "[02/24 10:32:45 d2.evaluation.evaluator]: Total inference time: 0:00:03.371999 (0.108774 s / iter per device, on 1 devices)\n",
            "[02/24 10:32:45 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.086099 s / iter per device, on 1 devices)\n",
            "[02/24 10:32:45 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[02/24 10:32:45 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/eval/coco_instances_results.json\n",
            "[02/24 10:32:45 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:32:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[02/24 10:32:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
            "[02/24 10:32:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:32:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.437\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.249\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.132\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n",
            "[02/24 10:32:45 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 20.954 | 43.666 | 18.843 |  nan  | 7.383 | 24.899 |\n",
            "[02/24 10:32:45 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:32:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[02/24 10:32:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "[02/24 10:32:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:32:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.136\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.234\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n",
            "[02/24 10:32:45 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 13.585 | 35.515 | 7.405  |  nan  | 4.398 | 16.540 |\n",
            "[02/24 10:32:45 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[02/24 10:32:45 d2.engine.defaults]: Evaluation results for my_dataset_val in csv format:\n",
            "[02/24 10:32:45 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[02/24 10:32:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:32:45 d2.evaluation.testing]: copypaste: 20.9538,43.6665,18.8433,nan,7.3831,24.8993\n",
            "[02/24 10:32:45 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[02/24 10:32:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:32:45 d2.evaluation.testing]: copypaste: 13.5845,35.5145,7.4051,nan,4.3975,16.5398\n",
            "[02/24 10:32:45 d2.utils.events]:  eta: 0:16:01  iter: 1499  total_loss: 0.7304  loss_cls: 0.1492  loss_box_reg: 0.2398  loss_mask: 0.3103  loss_rpn_cls: 0.008912  loss_rpn_loc: 0.01505    time: 0.4191  last_time: 0.3636  data_time: 0.0068  last_data_time: 0.0055   lr: 0.00025  max_mem: 2093M\n",
            "val_loss (0.8690455593168736, 1500)\n",
            "Iteration 1500: Validation Loss = 0.8690\n",
            "Model saved at: /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/model_iter_1500.pth\n",
            "[02/24 10:32:56 d2.utils.events]:  eta: 0:15:54  iter: 1519  total_loss: 0.7741  loss_cls: 0.1562  loss_box_reg: 0.2344  loss_mask: 0.3567  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.02119    time: 0.4195  last_time: 0.4915  data_time: 0.0111  last_data_time: 0.0091   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:33:05 d2.utils.events]:  eta: 0:15:46  iter: 1539  total_loss: 0.8461  loss_cls: 0.1902  loss_box_reg: 0.2903  loss_mask: 0.3391  loss_rpn_cls: 0.01464  loss_rpn_loc: 0.02613    time: 0.4200  last_time: 0.4536  data_time: 0.0093  last_data_time: 0.0054   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:33:14 d2.utils.events]:  eta: 0:15:38  iter: 1559  total_loss: 0.9294  loss_cls: 0.1989  loss_box_reg: 0.3307  loss_mask: 0.3647  loss_rpn_cls: 0.01631  loss_rpn_loc: 0.01826    time: 0.4202  last_time: 0.3820  data_time: 0.0057  last_data_time: 0.0055   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:33:22 d2.utils.events]:  eta: 0:15:30  iter: 1579  total_loss: 0.7845  loss_cls: 0.1579  loss_box_reg: 0.2339  loss_mask: 0.3546  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.01688    time: 0.4204  last_time: 0.4443  data_time: 0.0115  last_data_time: 0.0062   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:33:31 d2.utils.events]:  eta: 0:15:22  iter: 1599  total_loss: 0.7493  loss_cls: 0.1615  loss_box_reg: 0.2426  loss_mask: 0.332  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.02075    time: 0.4207  last_time: 0.4230  data_time: 0.0078  last_data_time: 0.0061   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:33:40 d2.utils.events]:  eta: 0:15:13  iter: 1619  total_loss: 0.7384  loss_cls: 0.1584  loss_box_reg: 0.2068  loss_mask: 0.3465  loss_rpn_cls: 0.01734  loss_rpn_loc: 0.01666    time: 0.4207  last_time: 0.4456  data_time: 0.0061  last_data_time: 0.0055   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:33:49 d2.utils.events]:  eta: 0:15:07  iter: 1639  total_loss: 0.6899  loss_cls: 0.1378  loss_box_reg: 0.2056  loss_mask: 0.3204  loss_rpn_cls: 0.006984  loss_rpn_loc: 0.01539    time: 0.4210  last_time: 0.4048  data_time: 0.0084  last_data_time: 0.0055   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:33:57 d2.utils.events]:  eta: 0:15:00  iter: 1659  total_loss: 0.6593  loss_cls: 0.1257  loss_box_reg: 0.1778  loss_mask: 0.3196  loss_rpn_cls: 0.01014  loss_rpn_loc: 0.009765    time: 0.4212  last_time: 0.4837  data_time: 0.0093  last_data_time: 0.0068   lr: 0.00025  max_mem: 2093M\n",
            "[02/24 10:34:06 d2.utils.events]:  eta: 0:14:51  iter: 1679  total_loss: 0.9007  loss_cls: 0.2053  loss_box_reg: 0.3131  loss_mask: 0.3457  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.02567    time: 0.4214  last_time: 0.4178  data_time: 0.0067  last_data_time: 0.0047   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:34:15 d2.utils.events]:  eta: 0:14:43  iter: 1699  total_loss: 0.6232  loss_cls: 0.1141  loss_box_reg: 0.1811  loss_mask: 0.3023  loss_rpn_cls: 0.00686  loss_rpn_loc: 0.01429    time: 0.4216  last_time: 0.4304  data_time: 0.0129  last_data_time: 0.0049   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:34:23 d2.utils.events]:  eta: 0:14:35  iter: 1719  total_loss: 0.7722  loss_cls: 0.1468  loss_box_reg: 0.2488  loss_mask: 0.3425  loss_rpn_cls: 0.006142  loss_rpn_loc: 0.02117    time: 0.4217  last_time: 0.3866  data_time: 0.0068  last_data_time: 0.0212   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:34:32 d2.utils.events]:  eta: 0:14:27  iter: 1739  total_loss: 0.7062  loss_cls: 0.1517  loss_box_reg: 0.2292  loss_mask: 0.3315  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.0184    time: 0.4219  last_time: 0.4058  data_time: 0.0073  last_data_time: 0.0056   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:34:41 d2.utils.events]:  eta: 0:14:20  iter: 1759  total_loss: 0.7814  loss_cls: 0.1526  loss_box_reg: 0.2517  loss_mask: 0.3368  loss_rpn_cls: 0.007433  loss_rpn_loc: 0.01796    time: 0.4222  last_time: 0.4498  data_time: 0.0103  last_data_time: 0.0049   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:34:50 d2.utils.events]:  eta: 0:14:11  iter: 1779  total_loss: 0.6242  loss_cls: 0.1186  loss_box_reg: 0.1823  loss_mask: 0.2984  loss_rpn_cls: 0.00739  loss_rpn_loc: 0.01743    time: 0.4224  last_time: 0.3935  data_time: 0.0084  last_data_time: 0.0134   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:34:59 d2.utils.events]:  eta: 0:14:03  iter: 1799  total_loss: 0.7675  loss_cls: 0.1613  loss_box_reg: 0.2211  loss_mask: 0.3167  loss_rpn_cls: 0.008106  loss_rpn_loc: 0.01983    time: 0.4225  last_time: 0.4607  data_time: 0.0064  last_data_time: 0.0051   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:35:08 d2.utils.events]:  eta: 0:13:56  iter: 1819  total_loss: 0.6721  loss_cls: 0.1448  loss_box_reg: 0.2057  loss_mask: 0.3064  loss_rpn_cls: 0.006869  loss_rpn_loc: 0.01621    time: 0.4228  last_time: 0.4942  data_time: 0.0086  last_data_time: 0.0055   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:35:16 d2.utils.events]:  eta: 0:13:47  iter: 1839  total_loss: 0.7145  loss_cls: 0.1339  loss_box_reg: 0.2052  loss_mask: 0.3085  loss_rpn_cls: 0.008477  loss_rpn_loc: 0.01773    time: 0.4228  last_time: 0.4649  data_time: 0.0079  last_data_time: 0.0072   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:35:25 d2.utils.events]:  eta: 0:13:39  iter: 1859  total_loss: 0.6539  loss_cls: 0.1279  loss_box_reg: 0.2072  loss_mask: 0.3113  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.01544    time: 0.4229  last_time: 0.4425  data_time: 0.0084  last_data_time: 0.0058   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:35:34 d2.utils.events]:  eta: 0:13:32  iter: 1879  total_loss: 0.7134  loss_cls: 0.1562  loss_box_reg: 0.254  loss_mask: 0.2942  loss_rpn_cls: 0.007282  loss_rpn_loc: 0.02299    time: 0.4232  last_time: 0.4467  data_time: 0.0061  last_data_time: 0.0056   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:35:42 d2.utils.events]:  eta: 0:13:23  iter: 1899  total_loss: 0.7008  loss_cls: 0.1402  loss_box_reg: 0.2134  loss_mask: 0.3222  loss_rpn_cls: 0.008551  loss_rpn_loc: 0.01582    time: 0.4231  last_time: 0.4394  data_time: 0.0054  last_data_time: 0.0055   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:35:51 d2.utils.events]:  eta: 0:13:14  iter: 1919  total_loss: 0.6508  loss_cls: 0.1275  loss_box_reg: 0.202  loss_mask: 0.3029  loss_rpn_cls: 0.005388  loss_rpn_loc: 0.0168    time: 0.4233  last_time: 0.4301  data_time: 0.0104  last_data_time: 0.0066   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:36:00 d2.utils.events]:  eta: 0:13:05  iter: 1939  total_loss: 0.7675  loss_cls: 0.1537  loss_box_reg: 0.2331  loss_mask: 0.2989  loss_rpn_cls: 0.007052  loss_rpn_loc: 0.02298    time: 0.4234  last_time: 0.3678  data_time: 0.0058  last_data_time: 0.0048   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:36:08 d2.utils.events]:  eta: 0:12:56  iter: 1959  total_loss: 0.6597  loss_cls: 0.1209  loss_box_reg: 0.2251  loss_mask: 0.2744  loss_rpn_cls: 0.00469  loss_rpn_loc: 0.0191    time: 0.4235  last_time: 0.4298  data_time: 0.0058  last_data_time: 0.0052   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:36:17 d2.utils.events]:  eta: 0:12:47  iter: 1979  total_loss: 0.6343  loss_cls: 0.1065  loss_box_reg: 0.1694  loss_mask: 0.3149  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.01793    time: 0.4237  last_time: 0.4140  data_time: 0.0109  last_data_time: 0.0051   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:36:26 d2.data.datasets.coco]: Loaded 36 images in COCO format from /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/val_annotations.coco.json\n",
            "[02/24 10:36:26 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[02/24 10:36:26 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[02/24 10:36:26 d2.data.common]: Serializing 36 elements to byte tensors and concatenating them all ...\n",
            "[02/24 10:36:26 d2.data.common]: Serialized dataset takes 0.06 MiB\n",
            "WARNING [02/24 10:36:26 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[02/24 10:36:26 d2.evaluation.evaluator]: Start inference on 36 batches\n",
            "[02/24 10:36:28 d2.evaluation.evaluator]: Inference done 11/36. Dataloading: 0.0022 s/iter. Inference: 0.0847 s/iter. Eval: 0.0151 s/iter. Total: 0.1019 s/iter. ETA=0:00:02\n",
            "[02/24 10:36:30 d2.evaluation.evaluator]: Total inference time: 0:00:03.114323 (0.100462 s / iter per device, on 1 devices)\n",
            "[02/24 10:36:30 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.084735 s / iter per device, on 1 devices)\n",
            "[02/24 10:36:30 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[02/24 10:36:30 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/eval/coco_instances_results.json\n",
            "[02/24 10:36:30 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:36:30 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[02/24 10:36:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.37 seconds.\n",
            "[02/24 10:36:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:36:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.172\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.123\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.380\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n",
            "[02/24 10:36:31 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 21.141 | 42.788 | 17.220 |  nan  | 8.776 | 25.480 |\n",
            "[02/24 10:36:31 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:36:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[02/24 10:36:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "[02/24 10:36:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:36:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.061\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.155\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.101\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.236\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.189\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267\n",
            "[02/24 10:36:31 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 12.563 | 31.639 | 8.248  |  nan  | 6.055 | 15.474 |\n",
            "[02/24 10:36:31 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[02/24 10:36:31 d2.engine.defaults]: Evaluation results for my_dataset_val in csv format:\n",
            "[02/24 10:36:31 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[02/24 10:36:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:36:31 d2.evaluation.testing]: copypaste: 21.1413,42.7875,17.2204,nan,8.7763,25.4801\n",
            "[02/24 10:36:31 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[02/24 10:36:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:36:31 d2.evaluation.testing]: copypaste: 12.5631,31.6393,8.2483,nan,6.0550,15.4735\n",
            "[02/24 10:36:31 d2.utils.events]:  eta: 0:12:39  iter: 1999  total_loss: 0.7396  loss_cls: 0.156  loss_box_reg: 0.2509  loss_mask: 0.3152  loss_rpn_cls: 0.008005  loss_rpn_loc: 0.02008    time: 0.4240  last_time: 0.4355  data_time: 0.0080  last_data_time: 0.0055   lr: 0.00025  max_mem: 2101M\n",
            "val_loss (1.0974961263127625, 2000)\n",
            "Iteration 2000: Validation Loss = 1.0975\n",
            "Model saved at: /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/model_iter_2000.pth\n",
            "[02/24 10:36:41 d2.utils.events]:  eta: 0:12:32  iter: 2019  total_loss: 0.6531  loss_cls: 0.1147  loss_box_reg: 0.2144  loss_mask: 0.2936  loss_rpn_cls: 0.004767  loss_rpn_loc: 0.01753    time: 0.4244  last_time: 0.4912  data_time: 0.0120  last_data_time: 0.0049   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:36:49 d2.utils.events]:  eta: 0:12:23  iter: 2039  total_loss: 0.6511  loss_cls: 0.1161  loss_box_reg: 0.1872  loss_mask: 0.2929  loss_rpn_cls: 0.008765  loss_rpn_loc: 0.01359    time: 0.4245  last_time: 0.4384  data_time: 0.0073  last_data_time: 0.0060   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:36:58 d2.utils.events]:  eta: 0:12:15  iter: 2059  total_loss: 0.7411  loss_cls: 0.138  loss_box_reg: 0.2412  loss_mask: 0.3089  loss_rpn_cls: 0.006199  loss_rpn_loc: 0.01942    time: 0.4247  last_time: 0.3783  data_time: 0.0068  last_data_time: 0.0050   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:37:07 d2.utils.events]:  eta: 0:12:08  iter: 2079  total_loss: 0.741  loss_cls: 0.1393  loss_box_reg: 0.2744  loss_mask: 0.294  loss_rpn_cls: 0.006318  loss_rpn_loc: 0.0204    time: 0.4250  last_time: 0.4479  data_time: 0.0105  last_data_time: 0.0053   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:37:16 d2.utils.events]:  eta: 0:11:59  iter: 2099  total_loss: 0.6229  loss_cls: 0.1155  loss_box_reg: 0.1528  loss_mask: 0.2956  loss_rpn_cls: 0.004176  loss_rpn_loc: 0.0092    time: 0.4250  last_time: 0.4630  data_time: 0.0057  last_data_time: 0.0109   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:37:24 d2.utils.events]:  eta: 0:11:50  iter: 2119  total_loss: 0.551  loss_cls: 0.1073  loss_box_reg: 0.1529  loss_mask: 0.296  loss_rpn_cls: 0.004113  loss_rpn_loc: 0.01226    time: 0.4251  last_time: 0.3305  data_time: 0.0093  last_data_time: 0.0054   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:37:33 d2.utils.events]:  eta: 0:11:43  iter: 2139  total_loss: 0.4915  loss_cls: 0.09295  loss_box_reg: 0.1625  loss_mask: 0.2701  loss_rpn_cls: 0.003192  loss_rpn_loc: 0.01448    time: 0.4253  last_time: 0.4720  data_time: 0.0093  last_data_time: 0.0049   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:37:43 d2.utils.events]:  eta: 0:11:35  iter: 2159  total_loss: 0.6478  loss_cls: 0.1174  loss_box_reg: 0.218  loss_mask: 0.2861  loss_rpn_cls: 0.005237  loss_rpn_loc: 0.0216    time: 0.4255  last_time: 0.4800  data_time: 0.0086  last_data_time: 0.0050   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:37:52 d2.utils.events]:  eta: 0:11:26  iter: 2179  total_loss: 0.6639  loss_cls: 0.1347  loss_box_reg: 0.2121  loss_mask: 0.2971  loss_rpn_cls: 0.006251  loss_rpn_loc: 0.01573    time: 0.4258  last_time: 0.4028  data_time: 0.0078  last_data_time: 0.0050   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:38:01 d2.utils.events]:  eta: 0:11:18  iter: 2199  total_loss: 0.7921  loss_cls: 0.1637  loss_box_reg: 0.2845  loss_mask: 0.3268  loss_rpn_cls: 0.008261  loss_rpn_loc: 0.02074    time: 0.4260  last_time: 0.4253  data_time: 0.0105  last_data_time: 0.0055   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:38:09 d2.utils.events]:  eta: 0:11:09  iter: 2219  total_loss: 0.541  loss_cls: 0.09163  loss_box_reg: 0.1873  loss_mask: 0.267  loss_rpn_cls: 0.006853  loss_rpn_loc: 0.01751    time: 0.4260  last_time: 0.4847  data_time: 0.0056  last_data_time: 0.0052   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:38:18 d2.utils.events]:  eta: 0:11:01  iter: 2239  total_loss: 0.5184  loss_cls: 0.09531  loss_box_reg: 0.1556  loss_mask: 0.2677  loss_rpn_cls: 0.004553  loss_rpn_loc: 0.01282    time: 0.4261  last_time: 0.4241  data_time: 0.0118  last_data_time: 0.0058   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:38:27 d2.utils.events]:  eta: 0:10:53  iter: 2259  total_loss: 0.5984  loss_cls: 0.1193  loss_box_reg: 0.1839  loss_mask: 0.2964  loss_rpn_cls: 0.003676  loss_rpn_loc: 0.01447    time: 0.4263  last_time: 0.5329  data_time: 0.0083  last_data_time: 0.0067   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:38:35 d2.utils.events]:  eta: 0:10:43  iter: 2279  total_loss: 0.5934  loss_cls: 0.1015  loss_box_reg: 0.1859  loss_mask: 0.2761  loss_rpn_cls: 0.005389  loss_rpn_loc: 0.01191    time: 0.4263  last_time: 0.3712  data_time: 0.0058  last_data_time: 0.0049   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:38:44 d2.utils.events]:  eta: 0:10:35  iter: 2299  total_loss: 0.5686  loss_cls: 0.1078  loss_box_reg: 0.1978  loss_mask: 0.2726  loss_rpn_cls: 0.004102  loss_rpn_loc: 0.01523    time: 0.4265  last_time: 0.4458  data_time: 0.0082  last_data_time: 0.0058   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:38:53 d2.utils.events]:  eta: 0:10:26  iter: 2319  total_loss: 0.7108  loss_cls: 0.1329  loss_box_reg: 0.2422  loss_mask: 0.3372  loss_rpn_cls: 0.00732  loss_rpn_loc: 0.0161    time: 0.4266  last_time: 0.4520  data_time: 0.0058  last_data_time: 0.0069   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:39:02 d2.utils.events]:  eta: 0:10:17  iter: 2339  total_loss: 0.5302  loss_cls: 0.09884  loss_box_reg: 0.174  loss_mask: 0.2772  loss_rpn_cls: 0.003071  loss_rpn_loc: 0.01338    time: 0.4267  last_time: 0.4953  data_time: 0.0059  last_data_time: 0.0055   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:39:11 d2.utils.events]:  eta: 0:10:09  iter: 2359  total_loss: 0.6543  loss_cls: 0.1289  loss_box_reg: 0.2308  loss_mask: 0.2691  loss_rpn_cls: 0.003851  loss_rpn_loc: 0.01557    time: 0.4269  last_time: 0.4340  data_time: 0.0067  last_data_time: 0.0050   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:39:20 d2.utils.events]:  eta: 0:10:01  iter: 2379  total_loss: 0.6444  loss_cls: 0.1134  loss_box_reg: 0.2228  loss_mask: 0.3132  loss_rpn_cls: 0.003895  loss_rpn_loc: 0.01388    time: 0.4271  last_time: 0.4731  data_time: 0.0062  last_data_time: 0.0058   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:39:29 d2.utils.events]:  eta: 0:09:52  iter: 2399  total_loss: 0.6921  loss_cls: 0.1362  loss_box_reg: 0.2261  loss_mask: 0.2865  loss_rpn_cls: 0.005147  loss_rpn_loc: 0.02004    time: 0.4273  last_time: 0.4863  data_time: 0.0056  last_data_time: 0.0052   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:39:38 d2.utils.events]:  eta: 0:09:43  iter: 2419  total_loss: 0.5874  loss_cls: 0.103  loss_box_reg: 0.1553  loss_mask: 0.2985  loss_rpn_cls: 0.00419  loss_rpn_loc: 0.01401    time: 0.4273  last_time: 0.4079  data_time: 0.0084  last_data_time: 0.0064   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:39:46 d2.utils.events]:  eta: 0:09:35  iter: 2439  total_loss: 0.5453  loss_cls: 0.09958  loss_box_reg: 0.1814  loss_mask: 0.2653  loss_rpn_cls: 0.002814  loss_rpn_loc: 0.01274    time: 0.4274  last_time: 0.4669  data_time: 0.0056  last_data_time: 0.0090   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:39:55 d2.utils.events]:  eta: 0:09:26  iter: 2459  total_loss: 0.6769  loss_cls: 0.1181  loss_box_reg: 0.23  loss_mask: 0.3012  loss_rpn_cls: 0.004945  loss_rpn_loc: 0.01429    time: 0.4275  last_time: 0.4136  data_time: 0.0069  last_data_time: 0.0076   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:40:04 d2.utils.events]:  eta: 0:09:18  iter: 2479  total_loss: 0.5348  loss_cls: 0.09169  loss_box_reg: 0.1761  loss_mask: 0.2636  loss_rpn_cls: 0.003599  loss_rpn_loc: 0.01113    time: 0.4276  last_time: 0.4036  data_time: 0.0068  last_data_time: 0.0051   lr: 0.00025  max_mem: 2101M\n",
            "[02/24 10:40:13 d2.data.datasets.coco]: Loaded 36 images in COCO format from /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/val_annotations.coco.json\n",
            "[02/24 10:40:13 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[02/24 10:40:13 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[02/24 10:40:13 d2.data.common]: Serializing 36 elements to byte tensors and concatenating them all ...\n",
            "[02/24 10:40:13 d2.data.common]: Serialized dataset takes 0.06 MiB\n",
            "WARNING [02/24 10:40:13 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[02/24 10:40:13 d2.evaluation.evaluator]: Start inference on 36 batches\n",
            "[02/24 10:40:15 d2.evaluation.evaluator]: Inference done 11/36. Dataloading: 0.0024 s/iter. Inference: 0.0891 s/iter. Eval: 0.0178 s/iter. Total: 0.1093 s/iter. ETA=0:00:02\n",
            "[02/24 10:40:17 d2.evaluation.evaluator]: Total inference time: 0:00:03.123741 (0.100766 s / iter per device, on 1 devices)\n",
            "[02/24 10:40:17 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.085250 s / iter per device, on 1 devices)\n",
            "[02/24 10:40:17 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[02/24 10:40:17 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/eval/coco_instances_results.json\n",
            "[02/24 10:40:17 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:40:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[02/24 10:40:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
            "[02/24 10:40:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:40:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.429\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.105\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
            "[02/24 10:40:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 20.761 | 42.929 | 17.723 |  nan  | 10.514 | 25.137 |\n",
            "[02/24 10:40:17 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:40:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[02/24 10:40:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "[02/24 10:40:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:40:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.153\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.228\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.189\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.282\n",
            "[02/24 10:40:17 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 12.313 | 34.368 | 8.159  |  nan  | 7.377 | 15.271 |\n",
            "[02/24 10:40:17 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[02/24 10:40:17 d2.engine.defaults]: Evaluation results for my_dataset_val in csv format:\n",
            "[02/24 10:40:17 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[02/24 10:40:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:40:17 d2.evaluation.testing]: copypaste: 20.7607,42.9291,17.7234,nan,10.5143,25.1371\n",
            "[02/24 10:40:17 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[02/24 10:40:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:40:17 d2.evaluation.testing]: copypaste: 12.3134,34.3681,8.1593,nan,7.3772,15.2714\n",
            "[02/24 10:40:17 d2.utils.events]:  eta: 0:09:10  iter: 2499  total_loss: 0.5216  loss_cls: 0.08374  loss_box_reg: 0.1583  loss_mask: 0.271  loss_rpn_cls: 0.003003  loss_rpn_loc: 0.012    time: 0.4278  last_time: 0.4446  data_time: 0.0054  last_data_time: 0.0064   lr: 0.00025  max_mem: 2101M\n",
            "val_loss (0.5914420071057975, 2500)\n",
            "Iteration 2500: Validation Loss = 0.5914\n",
            "Model saved at: /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/model_iter_2500.pth\n",
            "[02/24 10:40:28 d2.utils.events]:  eta: 0:09:01  iter: 2519  total_loss: 0.6668  loss_cls: 0.118  loss_box_reg: 0.2223  loss_mask: 0.3025  loss_rpn_cls: 0.003363  loss_rpn_loc: 0.01816    time: 0.4279  last_time: 0.4466  data_time: 0.0071  last_data_time: 0.0080   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:40:37 d2.utils.events]:  eta: 0:08:52  iter: 2539  total_loss: 0.6232  loss_cls: 0.1169  loss_box_reg: 0.1963  loss_mask: 0.2865  loss_rpn_cls: 0.006147  loss_rpn_loc: 0.01478    time: 0.4281  last_time: 0.4275  data_time: 0.0074  last_data_time: 0.0057   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:40:46 d2.utils.events]:  eta: 0:08:44  iter: 2559  total_loss: 0.4568  loss_cls: 0.07692  loss_box_reg: 0.1422  loss_mask: 0.2371  loss_rpn_cls: 0.001669  loss_rpn_loc: 0.01251    time: 0.4282  last_time: 0.4524  data_time: 0.0082  last_data_time: 0.0049   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:40:54 d2.utils.events]:  eta: 0:08:35  iter: 2579  total_loss: 0.6167  loss_cls: 0.1102  loss_box_reg: 0.2153  loss_mask: 0.2636  loss_rpn_cls: 0.004625  loss_rpn_loc: 0.01267    time: 0.4283  last_time: 0.4678  data_time: 0.0059  last_data_time: 0.0060   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:41:03 d2.utils.events]:  eta: 0:08:26  iter: 2599  total_loss: 0.625  loss_cls: 0.1126  loss_box_reg: 0.2208  loss_mask: 0.2738  loss_rpn_cls: 0.002374  loss_rpn_loc: 0.01688    time: 0.4284  last_time: 0.4014  data_time: 0.0055  last_data_time: 0.0054   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:41:12 d2.utils.events]:  eta: 0:08:18  iter: 2619  total_loss: 0.6586  loss_cls: 0.1126  loss_box_reg: 0.1901  loss_mask: 0.2839  loss_rpn_cls: 0.004959  loss_rpn_loc: 0.01612    time: 0.4287  last_time: 0.4711  data_time: 0.0134  last_data_time: 0.0060   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:41:21 d2.utils.events]:  eta: 0:08:09  iter: 2639  total_loss: 0.5365  loss_cls: 0.0961  loss_box_reg: 0.1758  loss_mask: 0.2728  loss_rpn_cls: 0.003594  loss_rpn_loc: 0.01557    time: 0.4288  last_time: 0.5230  data_time: 0.0082  last_data_time: 0.0246   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:41:30 d2.utils.events]:  eta: 0:08:00  iter: 2659  total_loss: 0.5638  loss_cls: 0.1032  loss_box_reg: 0.1658  loss_mask: 0.2519  loss_rpn_cls: 0.004543  loss_rpn_loc: 0.01285    time: 0.4288  last_time: 0.4907  data_time: 0.0060  last_data_time: 0.0051   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:41:39 d2.utils.events]:  eta: 0:07:52  iter: 2679  total_loss: 0.5678  loss_cls: 0.08297  loss_box_reg: 0.1879  loss_mask: 0.2655  loss_rpn_cls: 0.003986  loss_rpn_loc: 0.01417    time: 0.4290  last_time: 0.4472  data_time: 0.0080  last_data_time: 0.0046   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:41:48 d2.utils.events]:  eta: 0:07:44  iter: 2699  total_loss: 0.4832  loss_cls: 0.08735  loss_box_reg: 0.155  loss_mask: 0.2526  loss_rpn_cls: 0.00323  loss_rpn_loc: 0.01505    time: 0.4291  last_time: 0.4160  data_time: 0.0061  last_data_time: 0.0063   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:41:57 d2.utils.events]:  eta: 0:07:36  iter: 2719  total_loss: 0.6308  loss_cls: 0.123  loss_box_reg: 0.2218  loss_mask: 0.272  loss_rpn_cls: 0.006093  loss_rpn_loc: 0.01801    time: 0.4292  last_time: 0.3340  data_time: 0.0058  last_data_time: 0.0056   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:42:05 d2.utils.events]:  eta: 0:07:27  iter: 2739  total_loss: 0.489  loss_cls: 0.07898  loss_box_reg: 0.1372  loss_mask: 0.2589  loss_rpn_cls: 0.001663  loss_rpn_loc: 0.007821    time: 0.4292  last_time: 0.3736  data_time: 0.0063  last_data_time: 0.0051   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:42:14 d2.utils.events]:  eta: 0:07:18  iter: 2759  total_loss: 0.5897  loss_cls: 0.1053  loss_box_reg: 0.2077  loss_mask: 0.2656  loss_rpn_cls: 0.0021  loss_rpn_loc: 0.01401    time: 0.4293  last_time: 0.5010  data_time: 0.0059  last_data_time: 0.0140   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:42:23 d2.utils.events]:  eta: 0:07:09  iter: 2779  total_loss: 0.5282  loss_cls: 0.08833  loss_box_reg: 0.1482  loss_mask: 0.2462  loss_rpn_cls: 0.002564  loss_rpn_loc: 0.01051    time: 0.4293  last_time: 0.4292  data_time: 0.0086  last_data_time: 0.0058   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:42:32 d2.utils.events]:  eta: 0:07:01  iter: 2799  total_loss: 0.6096  loss_cls: 0.1162  loss_box_reg: 0.1781  loss_mask: 0.2689  loss_rpn_cls: 0.002494  loss_rpn_loc: 0.01544    time: 0.4295  last_time: 0.5108  data_time: 0.0076  last_data_time: 0.0052   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:42:41 d2.utils.events]:  eta: 0:06:51  iter: 2819  total_loss: 0.5464  loss_cls: 0.08564  loss_box_reg: 0.1577  loss_mask: 0.2674  loss_rpn_cls: 0.002763  loss_rpn_loc: 0.01377    time: 0.4295  last_time: 0.4405  data_time: 0.0058  last_data_time: 0.0063   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:42:50 d2.utils.events]:  eta: 0:06:42  iter: 2839  total_loss: 0.429  loss_cls: 0.06539  loss_box_reg: 0.1265  loss_mask: 0.232  loss_rpn_cls: 0.001322  loss_rpn_loc: 0.009462    time: 0.4296  last_time: 0.4248  data_time: 0.0072  last_data_time: 0.0056   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:42:58 d2.utils.events]:  eta: 0:06:34  iter: 2859  total_loss: 0.5073  loss_cls: 0.08672  loss_box_reg: 0.142  loss_mask: 0.2669  loss_rpn_cls: 0.002247  loss_rpn_loc: 0.01196    time: 0.4298  last_time: 0.4355  data_time: 0.0064  last_data_time: 0.0068   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:43:07 d2.utils.events]:  eta: 0:06:25  iter: 2879  total_loss: 0.5244  loss_cls: 0.09247  loss_box_reg: 0.1828  loss_mask: 0.2405  loss_rpn_cls: 0.003843  loss_rpn_loc: 0.01607    time: 0.4299  last_time: 0.3834  data_time: 0.0054  last_data_time: 0.0055   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:43:16 d2.utils.events]:  eta: 0:06:16  iter: 2899  total_loss: 0.6105  loss_cls: 0.1116  loss_box_reg: 0.189  loss_mask: 0.2827  loss_rpn_cls: 0.002402  loss_rpn_loc: 0.01239    time: 0.4300  last_time: 0.4612  data_time: 0.0059  last_data_time: 0.0059   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:43:25 d2.utils.events]:  eta: 0:06:07  iter: 2919  total_loss: 0.5486  loss_cls: 0.1021  loss_box_reg: 0.1571  loss_mask: 0.2593  loss_rpn_cls: 0.002737  loss_rpn_loc: 0.01397    time: 0.4301  last_time: 0.3802  data_time: 0.0093  last_data_time: 0.0051   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:43:34 d2.utils.events]:  eta: 0:05:59  iter: 2939  total_loss: 0.5818  loss_cls: 0.1042  loss_box_reg: 0.1622  loss_mask: 0.2707  loss_rpn_cls: 0.003161  loss_rpn_loc: 0.01686    time: 0.4302  last_time: 0.4191  data_time: 0.0054  last_data_time: 0.0052   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:43:43 d2.utils.events]:  eta: 0:05:50  iter: 2959  total_loss: 0.5041  loss_cls: 0.08512  loss_box_reg: 0.1539  loss_mask: 0.2392  loss_rpn_cls: 0.005026  loss_rpn_loc: 0.01355    time: 0.4303  last_time: 0.4663  data_time: 0.0071  last_data_time: 0.0050   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:43:52 d2.utils.events]:  eta: 0:05:41  iter: 2979  total_loss: 0.5503  loss_cls: 0.09625  loss_box_reg: 0.1766  loss_mask: 0.2511  loss_rpn_cls: 0.003004  loss_rpn_loc: 0.01341    time: 0.4305  last_time: 0.5685  data_time: 0.0086  last_data_time: 0.0098   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:44:01 d2.data.datasets.coco]: Loaded 36 images in COCO format from /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/val_annotations.coco.json\n",
            "[02/24 10:44:01 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[02/24 10:44:01 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[02/24 10:44:01 d2.data.common]: Serializing 36 elements to byte tensors and concatenating them all ...\n",
            "[02/24 10:44:01 d2.data.common]: Serialized dataset takes 0.06 MiB\n",
            "WARNING [02/24 10:44:01 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[02/24 10:44:01 d2.evaluation.evaluator]: Start inference on 36 batches\n",
            "[02/24 10:44:03 d2.evaluation.evaluator]: Inference done 11/36. Dataloading: 0.0013 s/iter. Inference: 0.0840 s/iter. Eval: 0.0110 s/iter. Total: 0.0964 s/iter. ETA=0:00:02\n",
            "[02/24 10:44:05 d2.evaluation.evaluator]: Total inference time: 0:00:03.408626 (0.109956 s / iter per device, on 1 devices)\n",
            "[02/24 10:44:05 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.088148 s / iter per device, on 1 devices)\n",
            "[02/24 10:44:06 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[02/24 10:44:06 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/eval/coco_instances_results.json\n",
            "[02/24 10:44:06 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:44:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[02/24 10:44:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
            "[02/24 10:44:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:44:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.401\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.153\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396\n",
            "[02/24 10:44:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 18.348 | 40.132 | 15.348 |  nan  | 10.279 | 21.889 |\n",
            "[02/24 10:44:06 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:44:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[02/24 10:44:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "[02/24 10:44:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:44:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.101\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.075\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.121\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.090\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.212\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.232\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
            "[02/24 10:44:06 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.087 | 29.474 | 7.007  |  nan  | 7.458 | 12.069 |\n",
            "[02/24 10:44:06 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[02/24 10:44:06 d2.engine.defaults]: Evaluation results for my_dataset_val in csv format:\n",
            "[02/24 10:44:06 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[02/24 10:44:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:44:06 d2.evaluation.testing]: copypaste: 18.3483,40.1318,15.3482,nan,10.2793,21.8891\n",
            "[02/24 10:44:06 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[02/24 10:44:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:44:06 d2.evaluation.testing]: copypaste: 10.0866,29.4742,7.0066,nan,7.4578,12.0694\n",
            "[02/24 10:44:06 d2.utils.events]:  eta: 0:05:32  iter: 2999  total_loss: 0.5129  loss_cls: 0.09302  loss_box_reg: 0.167  loss_mask: 0.2624  loss_rpn_cls: 0.00249  loss_rpn_loc: 0.01426    time: 0.4306  last_time: 0.4574  data_time: 0.0070  last_data_time: 0.0046   lr: 2.5e-05  max_mem: 2101M\n",
            "val_loss (0.38498748606070876, 3000)\n",
            "Iteration 3000: Validation Loss = 0.3850\n",
            "Model saved at: /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/model_iter_3000.pth\n",
            "[02/24 10:44:16 d2.utils.events]:  eta: 0:05:23  iter: 3019  total_loss: 0.476  loss_cls: 0.07606  loss_box_reg: 0.1403  loss_mask: 0.2336  loss_rpn_cls: 0.002278  loss_rpn_loc: 0.00982    time: 0.4307  last_time: 0.4154  data_time: 0.0071  last_data_time: 0.0054   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:44:26 d2.utils.events]:  eta: 0:05:14  iter: 3039  total_loss: 0.5658  loss_cls: 0.09897  loss_box_reg: 0.1754  loss_mask: 0.2423  loss_rpn_cls: 0.001977  loss_rpn_loc: 0.01296    time: 0.4310  last_time: 0.4300  data_time: 0.0086  last_data_time: 0.0178   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:44:35 d2.utils.events]:  eta: 0:05:06  iter: 3059  total_loss: 0.5538  loss_cls: 0.1061  loss_box_reg: 0.194  loss_mask: 0.2552  loss_rpn_cls: 0.003644  loss_rpn_loc: 0.01682    time: 0.4312  last_time: 0.5151  data_time: 0.0110  last_data_time: 0.0049   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:44:44 d2.utils.events]:  eta: 0:04:57  iter: 3079  total_loss: 0.5467  loss_cls: 0.08174  loss_box_reg: 0.1466  loss_mask: 0.2709  loss_rpn_cls: 0.002514  loss_rpn_loc: 0.01218    time: 0.4313  last_time: 0.4003  data_time: 0.0053  last_data_time: 0.0048   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:44:53 d2.utils.events]:  eta: 0:04:48  iter: 3099  total_loss: 0.4639  loss_cls: 0.07835  loss_box_reg: 0.1358  loss_mask: 0.2484  loss_rpn_cls: 0.002027  loss_rpn_loc: 0.0103    time: 0.4314  last_time: 0.4205  data_time: 0.0080  last_data_time: 0.0050   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:45:01 d2.utils.events]:  eta: 0:04:39  iter: 3119  total_loss: 0.5533  loss_cls: 0.09417  loss_box_reg: 0.1661  loss_mask: 0.2612  loss_rpn_cls: 0.004364  loss_rpn_loc: 0.0118    time: 0.4314  last_time: 0.4110  data_time: 0.0072  last_data_time: 0.0062   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:45:10 d2.utils.events]:  eta: 0:04:30  iter: 3139  total_loss: 0.5352  loss_cls: 0.09433  loss_box_reg: 0.144  loss_mask: 0.2651  loss_rpn_cls: 0.00134  loss_rpn_loc: 0.01296    time: 0.4315  last_time: 0.4420  data_time: 0.0067  last_data_time: 0.0053   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:45:20 d2.utils.events]:  eta: 0:04:21  iter: 3159  total_loss: 0.543  loss_cls: 0.1071  loss_box_reg: 0.1682  loss_mask: 0.2436  loss_rpn_cls: 0.002793  loss_rpn_loc: 0.01663    time: 0.4317  last_time: 0.4368  data_time: 0.0103  last_data_time: 0.0054   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:45:29 d2.utils.events]:  eta: 0:04:13  iter: 3179  total_loss: 0.5314  loss_cls: 0.0887  loss_box_reg: 0.1722  loss_mask: 0.2569  loss_rpn_cls: 0.003479  loss_rpn_loc: 0.01337    time: 0.4318  last_time: 0.5256  data_time: 0.0076  last_data_time: 0.0061   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:45:37 d2.utils.events]:  eta: 0:04:04  iter: 3199  total_loss: 0.5251  loss_cls: 0.0869  loss_box_reg: 0.1673  loss_mask: 0.2759  loss_rpn_cls: 0.00336  loss_rpn_loc: 0.01356    time: 0.4319  last_time: 0.4329  data_time: 0.0054  last_data_time: 0.0060   lr: 2.5e-05  max_mem: 2101M\n",
            "[02/24 10:45:46 d2.utils.events]:  eta: 0:03:55  iter: 3219  total_loss: 0.4358  loss_cls: 0.06473  loss_box_reg: 0.1182  loss_mask: 0.2402  loss_rpn_cls: 0.00245  loss_rpn_loc: 0.01178    time: 0.4319  last_time: 0.5156  data_time: 0.0080  last_data_time: 0.0054   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:45:55 d2.utils.events]:  eta: 0:03:46  iter: 3239  total_loss: 0.5661  loss_cls: 0.112  loss_box_reg: 0.1848  loss_mask: 0.2708  loss_rpn_cls: 0.001527  loss_rpn_loc: 0.01623    time: 0.4320  last_time: 0.4966  data_time: 0.0086  last_data_time: 0.0110   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:46:04 d2.utils.events]:  eta: 0:03:38  iter: 3259  total_loss: 0.4842  loss_cls: 0.07963  loss_box_reg: 0.1354  loss_mask: 0.2442  loss_rpn_cls: 0.001427  loss_rpn_loc: 0.01199    time: 0.4321  last_time: 0.5225  data_time: 0.0057  last_data_time: 0.0056   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:46:13 d2.utils.events]:  eta: 0:03:29  iter: 3279  total_loss: 0.5561  loss_cls: 0.09652  loss_box_reg: 0.1844  loss_mask: 0.2699  loss_rpn_cls: 0.002313  loss_rpn_loc: 0.0149    time: 0.4322  last_time: 0.4650  data_time: 0.0076  last_data_time: 0.0050   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:46:22 d2.utils.events]:  eta: 0:03:20  iter: 3299  total_loss: 0.5442  loss_cls: 0.09599  loss_box_reg: 0.1775  loss_mask: 0.2512  loss_rpn_cls: 0.003989  loss_rpn_loc: 0.0164    time: 0.4323  last_time: 0.4718  data_time: 0.0077  last_data_time: 0.0062   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:46:31 d2.utils.events]:  eta: 0:03:11  iter: 3319  total_loss: 0.5929  loss_cls: 0.112  loss_box_reg: 0.174  loss_mask: 0.2687  loss_rpn_cls: 0.00326  loss_rpn_loc: 0.01542    time: 0.4323  last_time: 0.4931  data_time: 0.0055  last_data_time: 0.0048   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:46:40 d2.utils.events]:  eta: 0:03:02  iter: 3339  total_loss: 0.5027  loss_cls: 0.0741  loss_box_reg: 0.1483  loss_mask: 0.2572  loss_rpn_cls: 0.001956  loss_rpn_loc: 0.0153    time: 0.4324  last_time: 0.4620  data_time: 0.0100  last_data_time: 0.0063   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:46:48 d2.utils.events]:  eta: 0:02:53  iter: 3359  total_loss: 0.5008  loss_cls: 0.07811  loss_box_reg: 0.1405  loss_mask: 0.2608  loss_rpn_cls: 0.003415  loss_rpn_loc: 0.01583    time: 0.4324  last_time: 0.3644  data_time: 0.0072  last_data_time: 0.0253   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:46:57 d2.utils.events]:  eta: 0:02:44  iter: 3379  total_loss: 0.5215  loss_cls: 0.08691  loss_box_reg: 0.1567  loss_mask: 0.2486  loss_rpn_cls: 0.003165  loss_rpn_loc: 0.01161    time: 0.4324  last_time: 0.4584  data_time: 0.0077  last_data_time: 0.0050   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:47:06 d2.utils.events]:  eta: 0:02:35  iter: 3399  total_loss: 0.516  loss_cls: 0.08177  loss_box_reg: 0.1644  loss_mask: 0.2633  loss_rpn_cls: 0.00243  loss_rpn_loc: 0.01057    time: 0.4325  last_time: 0.4149  data_time: 0.0063  last_data_time: 0.0051   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:47:15 d2.utils.events]:  eta: 0:02:26  iter: 3419  total_loss: 0.5897  loss_cls: 0.109  loss_box_reg: 0.1943  loss_mask: 0.246  loss_rpn_cls: 0.002623  loss_rpn_loc: 0.01499    time: 0.4327  last_time: 0.4974  data_time: 0.0074  last_data_time: 0.0066   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:47:24 d2.utils.events]:  eta: 0:02:17  iter: 3439  total_loss: 0.5605  loss_cls: 0.08777  loss_box_reg: 0.174  loss_mask: 0.2435  loss_rpn_cls: 0.003442  loss_rpn_loc: 0.01431    time: 0.4327  last_time: 0.4977  data_time: 0.0055  last_data_time: 0.0048   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:47:33 d2.utils.events]:  eta: 0:02:08  iter: 3459  total_loss: 0.4917  loss_cls: 0.1139  loss_box_reg: 0.1506  loss_mask: 0.2365  loss_rpn_cls: 0.003618  loss_rpn_loc: 0.013    time: 0.4328  last_time: 0.3858  data_time: 0.0069  last_data_time: 0.0051   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:47:42 d2.utils.events]:  eta: 0:02:00  iter: 3479  total_loss: 0.5172  loss_cls: 0.08656  loss_box_reg: 0.1482  loss_mask: 0.2674  loss_rpn_cls: 0.002646  loss_rpn_loc: 0.01577    time: 0.4328  last_time: 0.4612  data_time: 0.0066  last_data_time: 0.0202   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:47:51 d2.data.datasets.coco]: Loaded 36 images in COCO format from /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/val_annotations.coco.json\n",
            "[02/24 10:47:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[02/24 10:47:51 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[02/24 10:47:51 d2.data.common]: Serializing 36 elements to byte tensors and concatenating them all ...\n",
            "[02/24 10:47:51 d2.data.common]: Serialized dataset takes 0.06 MiB\n",
            "WARNING [02/24 10:47:51 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[02/24 10:47:51 d2.evaluation.evaluator]: Start inference on 36 batches\n",
            "[02/24 10:47:52 d2.evaluation.evaluator]: Inference done 11/36. Dataloading: 0.0013 s/iter. Inference: 0.0851 s/iter. Eval: 0.0109 s/iter. Total: 0.0973 s/iter. ETA=0:00:02\n",
            "[02/24 10:47:54 d2.evaluation.evaluator]: Total inference time: 0:00:03.236763 (0.104412 s / iter per device, on 1 devices)\n",
            "[02/24 10:47:54 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.086366 s / iter per device, on 1 devices)\n",
            "[02/24 10:47:54 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[02/24 10:47:54 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/eval/coco_instances_results.json\n",
            "[02/24 10:47:55 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:47:55 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[02/24 10:47:55 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
            "[02/24 10:47:55 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:47:55 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.386\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.395\n",
            "[02/24 10:47:55 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.890 | 38.636 | 15.705 |  nan  | 9.678 | 21.675 |\n",
            "[02/24 10:47:55 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:47:55 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[02/24 10:47:55 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "[02/24 10:47:55 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:47:55 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.073\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.203\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.185\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.236\n",
            "[02/24 10:47:55 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 9.393 | 27.700 | 6.420  |  nan  | 7.332 | 11.173 |\n",
            "[02/24 10:47:55 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[02/24 10:47:55 d2.engine.defaults]: Evaluation results for my_dataset_val in csv format:\n",
            "[02/24 10:47:55 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[02/24 10:47:55 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:47:55 d2.evaluation.testing]: copypaste: 17.8903,38.6357,15.7052,nan,9.6782,21.6745\n",
            "[02/24 10:47:55 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[02/24 10:47:55 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:47:55 d2.evaluation.testing]: copypaste: 9.3925,27.6995,6.4204,nan,7.3317,11.1730\n",
            "[02/24 10:47:55 d2.utils.events]:  eta: 0:01:50  iter: 3499  total_loss: 0.6143  loss_cls: 0.1162  loss_box_reg: 0.2007  loss_mask: 0.2748  loss_rpn_cls: 0.005734  loss_rpn_loc: 0.01545    time: 0.4328  last_time: 0.4209  data_time: 0.0093  last_data_time: 0.0048   lr: 2.5e-06  max_mem: 2101M\n",
            "val_loss (0.31403472437523305, 3500)\n",
            "Iteration 3500: Validation Loss = 0.3140\n",
            "Model saved at: /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/model_iter_3500.pth\n",
            "[02/24 10:48:05 d2.utils.events]:  eta: 0:01:42  iter: 3519  total_loss: 0.5201  loss_cls: 0.09962  loss_box_reg: 0.1372  loss_mask: 0.2537  loss_rpn_cls: 0.003529  loss_rpn_loc: 0.01479    time: 0.4329  last_time: 0.4475  data_time: 0.0067  last_data_time: 0.0061   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:48:15 d2.utils.events]:  eta: 0:01:33  iter: 3539  total_loss: 0.5032  loss_cls: 0.08235  loss_box_reg: 0.159  loss_mask: 0.2428  loss_rpn_cls: 0.001058  loss_rpn_loc: 0.01288    time: 0.4331  last_time: 0.4517  data_time: 0.0067  last_data_time: 0.0054   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:48:23 d2.utils.events]:  eta: 0:01:24  iter: 3559  total_loss: 0.5035  loss_cls: 0.08038  loss_box_reg: 0.1503  loss_mask: 0.2507  loss_rpn_cls: 0.003703  loss_rpn_loc: 0.01554    time: 0.4331  last_time: 0.4625  data_time: 0.0064  last_data_time: 0.0066   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:48:32 d2.utils.events]:  eta: 0:01:15  iter: 3579  total_loss: 0.5776  loss_cls: 0.1077  loss_box_reg: 0.1748  loss_mask: 0.265  loss_rpn_cls: 0.003032  loss_rpn_loc: 0.01415    time: 0.4331  last_time: 0.4710  data_time: 0.0059  last_data_time: 0.0051   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:48:41 d2.utils.events]:  eta: 0:01:06  iter: 3599  total_loss: 0.6067  loss_cls: 0.1065  loss_box_reg: 0.1981  loss_mask: 0.2743  loss_rpn_cls: 0.002531  loss_rpn_loc: 0.01347    time: 0.4332  last_time: 0.4887  data_time: 0.0065  last_data_time: 0.0068   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:48:50 d2.utils.events]:  eta: 0:00:57  iter: 3619  total_loss: 0.5155  loss_cls: 0.08604  loss_box_reg: 0.1453  loss_mask: 0.262  loss_rpn_cls: 0.002593  loss_rpn_loc: 0.01439    time: 0.4333  last_time: 0.5103  data_time: 0.0098  last_data_time: 0.0170   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:48:59 d2.utils.events]:  eta: 0:00:48  iter: 3639  total_loss: 0.5152  loss_cls: 0.08348  loss_box_reg: 0.1529  loss_mask: 0.2447  loss_rpn_cls: 0.002436  loss_rpn_loc: 0.01193    time: 0.4333  last_time: 0.4365  data_time: 0.0071  last_data_time: 0.0057   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:49:08 d2.utils.events]:  eta: 0:00:40  iter: 3659  total_loss: 0.5071  loss_cls: 0.08798  loss_box_reg: 0.1565  loss_mask: 0.2496  loss_rpn_cls: 0.002276  loss_rpn_loc: 0.01097    time: 0.4334  last_time: 0.4390  data_time: 0.0075  last_data_time: 0.0055   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:49:17 d2.utils.events]:  eta: 0:00:31  iter: 3679  total_loss: 0.5821  loss_cls: 0.09639  loss_box_reg: 0.2163  loss_mask: 0.2647  loss_rpn_cls: 0.003375  loss_rpn_loc: 0.0119    time: 0.4337  last_time: 0.4824  data_time: 0.0098  last_data_time: 0.0271   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:49:26 d2.utils.events]:  eta: 0:00:22  iter: 3699  total_loss: 0.5176  loss_cls: 0.08905  loss_box_reg: 0.1683  loss_mask: 0.2406  loss_rpn_cls: 0.002142  loss_rpn_loc: 0.0139    time: 0.4337  last_time: 0.4002  data_time: 0.0059  last_data_time: 0.0050   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:49:35 d2.utils.events]:  eta: 0:00:13  iter: 3719  total_loss: 0.6131  loss_cls: 0.1108  loss_box_reg: 0.1929  loss_mask: 0.274  loss_rpn_cls: 0.006405  loss_rpn_loc: 0.01629    time: 0.4337  last_time: 0.4506  data_time: 0.0072  last_data_time: 0.0054   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:49:44 d2.utils.events]:  eta: 0:00:04  iter: 3739  total_loss: 0.4878  loss_cls: 0.08412  loss_box_reg: 0.127  loss_mask: 0.2426  loss_rpn_cls: 0.001296  loss_rpn_loc: 0.01014    time: 0.4337  last_time: 0.4566  data_time: 0.0060  last_data_time: 0.0071   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:49:49 d2.utils.events]:  eta: 0:00:00  iter: 3749  total_loss: 0.4725  loss_cls: 0.08508  loss_box_reg: 0.1327  loss_mask: 0.246  loss_rpn_cls: 0.0006613  loss_rpn_loc: 0.01094    time: 0.4338  last_time: 0.4557  data_time: 0.0068  last_data_time: 0.0049   lr: 2.5e-06  max_mem: 2101M\n",
            "[02/24 10:49:49 d2.engine.hooks]: Overall training speed: 3748 iterations in 0:27:05 (0.4338 s / it)\n",
            "[02/24 10:49:49 d2.engine.hooks]: Total training time: 0:28:06 (0:01:00 on hooks)\n",
            "[02/24 10:49:49 d2.data.datasets.coco]: Loaded 36 images in COCO format from /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/val_annotations.coco.json\n",
            "[02/24 10:49:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[02/24 10:49:49 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[02/24 10:49:49 d2.data.common]: Serializing 36 elements to byte tensors and concatenating them all ...\n",
            "[02/24 10:49:49 d2.data.common]: Serialized dataset takes 0.06 MiB\n",
            "WARNING [02/24 10:49:49 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[02/24 10:49:49 d2.evaluation.evaluator]: Start inference on 36 batches\n",
            "[02/24 10:49:51 d2.evaluation.evaluator]: Inference done 11/36. Dataloading: 0.0013 s/iter. Inference: 0.0851 s/iter. Eval: 0.0109 s/iter. Total: 0.0974 s/iter. ETA=0:00:02\n",
            "[02/24 10:49:53 d2.evaluation.evaluator]: Total inference time: 0:00:03.019105 (0.097390 s / iter per device, on 1 devices)\n",
            "[02/24 10:49:53 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.084140 s / iter per device, on 1 devices)\n",
            "[02/24 10:49:53 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[02/24 10:49:53 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/eval/coco_instances_results.json\n",
            "[02/24 10:49:53 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:49:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[02/24 10:49:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
            "[02/24 10:49:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:49:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.386\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.388\n",
            "[02/24 10:49:53 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 17.772 | 38.642 | 15.684 |  nan  | 9.697 | 21.615 |\n",
            "[02/24 10:49:53 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "[02/24 10:49:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[02/24 10:49:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "[02/24 10:49:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[02/24 10:49:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.185\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231\n",
            "[02/24 10:49:53 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 9.356 | 27.702 | 6.185  |  nan  | 7.233 | 11.143 |\n",
            "[02/24 10:49:53 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[02/24 10:49:53 d2.engine.defaults]: Evaluation results for my_dataset_val in csv format:\n",
            "[02/24 10:49:53 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[02/24 10:49:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:49:53 d2.evaluation.testing]: copypaste: 17.7716,38.6416,15.6843,nan,9.6974,21.6150\n",
            "[02/24 10:49:53 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[02/24 10:49:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[02/24 10:49:53 d2.evaluation.testing]: copypaste: 9.3559,27.7016,6.1855,nan,7.2333,11.1425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save final model\n",
        "final_model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "torch.save(trainer.model.state_dict(), final_model_path)\n",
        "print(f\"Training complete. Model saved at: {final_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvhx2nCLVVdS",
        "outputId": "b98f673c-4030-4e98-ed51-fc9923f61b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete. Model saved at: /content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/train/output/model_final.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import detectron2\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer, HookBase\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2.model_zoo import get_config_file, get_checkpoint_url\n",
        "import numpy as np\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_folder = \"/content/drive/My Drive/detectron2_training\"  # Change as needed\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "print(\"Training started...\")\n",
        "setup_logger()\n",
        "\n",
        "# Paths\n",
        "dataset_folder = \"/content/dataset\"  # Update this if dataset is elsewhere\n",
        "train_json = os.path.join(dataset_folder, \"train_annotations.json\")\n",
        "val_json = os.path.join(dataset_folder, \"val_annotations.json\")\n",
        "train_images = os.path.join(dataset_folder, \"train\")\n",
        "val_images = os.path.join(dataset_folder, \"val\")\n",
        "output_dir = os.path.join(drive_folder, \"output\")  # Save output to Google Drive\n",
        "\n",
        "# Register datasets\n",
        "register_coco_instances(\"my_dataset_train\", {}, train_json, train_images)\n",
        "register_coco_instances(\"my_dataset_val\", {}, val_json, val_images)\n",
        "\n",
        "# Get metadata\n",
        "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
        "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n",
        "\n",
        "# Configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2  # Reduce for Colab\n",
        "cfg.MODEL.WEIGHTS = get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # Reduce for Colab\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 3750\n",
        "cfg.SOLVER.STEPS = (2500, 3200)\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.TEST.EVAL_PERIOD = 500\n",
        "cfg.OUTPUT_DIR = output_dir\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Early Stopping & Model Saving Hook\n",
        "class EarlyStoppingHook(HookBase):\n",
        "    def __init__(self, patience=3):  # Stop if no improvement for 3 evals\n",
        "        self.patience = patience\n",
        "        self.best_loss = float('inf')\n",
        "        self.counter = 0\n",
        "\n",
        "    def after_step(self):\n",
        "        if self.trainer.iter % cfg.TEST.EVAL_PERIOD == 0:\n",
        "            eval_results = self.trainer.storage.latest()\n",
        "            val_loss = eval_results.get(\"total_loss\", None)\n",
        "            if val_loss is not None:\n",
        "                print(f\"Iteration {self.trainer.iter}: Validation Loss = {val_loss:.4f}\")\n",
        "                model_path = os.path.join(cfg.OUTPUT_DIR, f\"model_iter_{self.trainer.iter}.pth\")\n",
        "                torch.save(self.trainer.model.state_dict(), model_path)\n",
        "                print(f\"Model saved at: {model_path}\")\n",
        "                if val_loss < self.best_loss:\n",
        "                    self.best_loss = val_loss\n",
        "                    self.counter = 0\n",
        "                    # Save the best model\n",
        "                    torch.save(self.trainer.model.state_dict(), os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\"))\n",
        "                else:\n",
        "                    self.counter += 1\n",
        "                    if self.counter >= self.patience:\n",
        "                        print(\"Early stopping triggered. Stopping training.\")\n",
        "                        self.trainer.iter = cfg.SOLVER.MAX_ITER  # Force training to stop\n",
        "\n",
        "# Custom Trainer\n",
        "class CocoTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"eval\")\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
        "\n",
        "    def build_hooks(self):\n",
        "        hooks = super().build_hooks()\n",
        "        hooks.append(EarlyStoppingHook(patience=3))  # Add early stopping & model saving\n",
        "        return hooks\n",
        "\n",
        "# Train\n",
        "trainer = CocoTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n",
        "\n",
        "# Save final model\n",
        "final_model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "torch.save(trainer.model.state_dict(), final_model_path)\n",
        "print(f\"Training complete. Model saved at: {final_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "sEYeyokzT3dq",
        "outputId": "32626404-dc1e-412b-927f-6bd3dc68633f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training started...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Attribute 'json_file' in the metadata of 'my_dataset_train' cannot be set to a different value!\n/content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/train_annotations.coco.json != /content/dataset/train_annotations.json",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-339a2bb75446>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Register datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_dataset_train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_dataset_val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36mregister_coco_instances\u001b[0;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;31m# 2. Optionally, add metadata about this dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;31m# since they might be useful in evaluation, visualization or logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     MetadataCatalog.get(name).set(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mjson_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coco\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/detectron2/data/catalog.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/detectron2/data/catalog.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, key, val)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0moldval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             assert oldval == val, (\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0;34m\"Attribute '{}' in the metadata of '{}' cannot be set \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;34m\"to a different value!\\n{} != {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moldval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Attribute 'json_file' in the metadata of 'my_dataset_train' cannot be set to a different value!\n/content/drive/MyDrive/Colab Notebooks/Datasets/seat_dataset/annotations/train_annotations.coco.json != /content/dataset/train_annotations.json"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import detectron2\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer, HookBase\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2.model_zoo import get_config_file, get_checkpoint_url\n",
        "import numpy as np\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_folder = \"/content/drive/My Drive/detectron2_training\"  # Change as needed\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "print(\"Training started...\")\n",
        "setup_logger()\n",
        "\n",
        "# Paths\n",
        "dataset_folder = \"/content/dataset\"  # Update this if dataset is elsewhere\n",
        "train_json = os.path.join(dataset_folder, \"train_annotations.json\")\n",
        "val_json = os.path.join(dataset_folder, \"val_annotations.json\")\n",
        "train_images = os.path.join(dataset_folder, \"train\")\n",
        "val_images = os.path.join(dataset_folder, \"val\")\n",
        "output_dir = os.path.join(drive_folder, \"output\")  # Save output to Google Drive\n",
        "\n",
        "# Register datasets\n",
        "register_coco_instances(\"my_dataset_train\", {}, train_json, train_images)\n",
        "register_coco_instances(\"my_dataset_val\", {}, val_json, val_images)\n",
        "\n",
        "# Get metadata\n",
        "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
        "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n",
        "\n",
        "# Configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2  # Reduce for Colab\n",
        "cfg.MODEL.WEIGHTS = get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # Reduce for Colab\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 3750\n",
        "cfg.SOLVER.STEPS = (2500, 3200)\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.TEST.EVAL_PERIOD = 500\n",
        "cfg.OUTPUT_DIR = output_dir\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Early Stopping Hook\n",
        "class EarlyStoppingHook(HookBase):\n",
        "    def __init__(self, patience=3):  # Stop if no improvement for 3 evals\n",
        "        self.patience = patience\n",
        "        self.best_loss = float('inf')\n",
        "        self.counter = 0\n",
        "\n",
        "    def after_step(self):\n",
        "        if self.trainer.iter % cfg.TEST.EVAL_PERIOD == 0:\n",
        "            eval_results = self.trainer.storage.latest()\n",
        "            val_loss = eval_results.get(\"total_loss\", None)\n",
        "            if val_loss is not None:\n",
        "                print(f\"Iteration {self.trainer.iter}: Validation Loss = {val_loss:.4f}\")\n",
        "                if val_loss < self.best_loss:\n",
        "                    self.best_loss = val_loss\n",
        "                    self.counter = 0\n",
        "                    # Save the best model\n",
        "                    torch.save(self.trainer.model.state_dict(), os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\"))\n",
        "                else:\n",
        "                    self.counter += 1\n",
        "                    if self.counter >= self.patience:\n",
        "                        print(\"Early stopping triggered. Stopping training.\")\n",
        "                        self.trainer.iter = cfg.SOLVER.MAX_ITER  # Force training to stop\n",
        "\n",
        "# Custom Trainer\n",
        "class CocoTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"eval\")\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
        "\n",
        "    def build_hooks(self):\n",
        "        hooks = super().build_hooks()\n",
        "        hooks.append(EarlyStoppingHook(patience=3))  # Add early stopping\n",
        "        return hooks\n",
        "\n",
        "# Train\n",
        "trainer = CocoTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n",
        "\n",
        "# Save final model\n",
        "final_model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "torch.save(trainer.model.state_dict(), final_model_path)\n",
        "print(f\"Training complete. Model saved at: {final_model_path}\")\n"
      ],
      "metadata": {
        "id": "TSGaOcWvOBJx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}