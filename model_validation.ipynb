{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3468b3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahadabul/mask_rcnn_skyhub/skyenv/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n",
      "\n",
      " BBOX metrics:\n",
      "  mAP (IoU=0.50:0.95): 3.059\n",
      "  mAP50 (IoU=0.50):    9.205\n",
      "  mAP75 (IoU=0.75):    1.369\n",
      "  AP_small:            nan\n",
      "  AP_medium:           0.0\n",
      "  AP_large:            5.812773885361958\n",
      "\n",
      " SEGM metrics:\n",
      "  mAP (IoU=0.50:0.95): 3.450\n",
      "  mAP50 (IoU=0.50):    9.134\n",
      "  mAP75 (IoU=0.75):    2.833\n",
      "  AP_small:            nan\n",
      "  AP_medium:           0.0\n",
      "  AP_large:            6.649637589760619\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.model_zoo import get_config_file\n",
    "\n",
    "INPUT_DIR = \"/home/fahadabul/mask_rcnn_skyhub/test/final\"\n",
    "MODEL_PATH_WRINKLE = \"/home/fahadabul/mask_rcnn_skyhub/latest_image_mask_rcnn_wrinkle/best_model_wrinkle.pth\"\n",
    "OUTPUT_DIR = \"/home/fahadabul/mask_rcnn_skyhub/test/model_eval\"\n",
    "COCO_GT_JSON = \"/home/fahadabul/mask_rcnn_skyhub/test/test.json\"\n",
    "DATASET_NAME = \"wrinkle_eval\"\n",
    "\n",
    "if \"torn_wrinkle_dataset\" not in MetadataCatalog.list():\n",
    "    MetadataCatalog.get(\"torn_wrinkle_dataset\").set(thing_classes=[\"torn\", \"wrinkle\"])\n",
    "metadata = MetadataCatalog.get(\"torn_wrinkle_dataset\")\n",
    "\n",
    "def load_model(model_path, class_names):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(class_names)\n",
    "    cfg.MODEL.WEIGHTS = model_path\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
    "    cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "predictor_wrinkle = load_model(MODEL_PATH_WRINKLE, [\"wrinkle\"])\n",
    "\n",
    "if DATASET_NAME not in DatasetCatalog.list():\n",
    "    register_coco_instances(DATASET_NAME, {}, COCO_GT_JSON, INPUT_DIR)\n",
    "\n",
    "from detectron2.data import build_detection_test_loader\n",
    "val_loader = build_detection_test_loader(predictor_wrinkle.cfg, DATASET_NAME)\n",
    "\n",
    "evaluator = COCOEvaluator(DATASET_NAME, output_dir=OUTPUT_DIR)\n",
    "results = inference_on_dataset(predictor_wrinkle.model, val_loader, evaluator)\n",
    "\n",
    "def print_coco_metrics(results, label=\"\"):\n",
    "    for key in [\"bbox\", \"segm\"]:\n",
    "        if key in results:\n",
    "            print(f\"\\n{label} {key.upper()} metrics:\")\n",
    "            print(f\"  mAP (IoU=0.50:0.95): {results[key].get('AP', 'N/A'):.3f}\")\n",
    "            print(f\"  mAP50 (IoU=0.50):    {results[key].get('AP50', 'N/A'):.3f}\")\n",
    "            print(f\"  mAP75 (IoU=0.75):    {results[key].get('AP75', 'N/A'):.3f}\")\n",
    "            print(f\"  AP_small:            {results[key].get('APs', 'N/A')}\")\n",
    "            print(f\"  AP_medium:           {results[key].get('APm', 'N/A')}\")\n",
    "            print(f\"  AP_large:            {results[key].get('APl', 'N/A')}\")\n",
    "\n",
    "print_coco_metrics(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5435d6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/08/2025 18:37:55 - INFO - detectron2.checkpoint.detection_checkpoint -   [DetectionCheckpointer] Loading from /home/fahadabul/mask_rcnn_skyhub/latest_image_mask_rcnn_wrinkle/best_model_wrinkle.pth ...\n",
      "05/08/2025 18:37:55 - INFO - fvcore.common.checkpoint -   [Checkpointer] Loading from /home/fahadabul/mask_rcnn_skyhub/latest_image_mask_rcnn_wrinkle/best_model_wrinkle.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fahadabul/mask_rcnn_skyhub/skyenv/lib/python3.10/site-packages/detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml not available in Model Zoo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/08/2025 18:37:55 - INFO - detectron2.checkpoint.detection_checkpoint -   [DetectionCheckpointer] Loading from /home/fahadabul/mask_rcnn_skyhub/latest_image_mask_rcnn_wrinkle/best_model_wrinkle.pth ...\n",
      "05/08/2025 18:37:55 - INFO - fvcore.common.checkpoint -   [Checkpointer] Loading from /home/fahadabul/mask_rcnn_skyhub/latest_image_mask_rcnn_wrinkle/best_model_wrinkle.pth ...\n",
      "05/08/2025 18:37:56 - WARNING - fvcore.common.checkpoint -   Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (2, 1024) in the checkpoint but (81, 1024) in the model! You might want to double check if this is expected.\n",
      "05/08/2025 18:37:56 - WARNING - fvcore.common.checkpoint -   Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (2,) in the checkpoint but (81,) in the model! You might want to double check if this is expected.\n",
      "05/08/2025 18:37:56 - WARNING - fvcore.common.checkpoint -   Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (4, 1024) in the checkpoint but (320, 1024) in the model! You might want to double check if this is expected.\n",
      "05/08/2025 18:37:56 - WARNING - fvcore.common.checkpoint -   Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (4,) in the checkpoint but (320,) in the model! You might want to double check if this is expected.\n",
      "05/08/2025 18:37:56 - WARNING - fvcore.common.checkpoint -   Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (1, 256, 1, 1) in the checkpoint but (80, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "05/08/2025 18:37:56 - WARNING - fvcore.common.checkpoint -   Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (1,) in the checkpoint but (80,) in the model! You might want to double check if this is expected.\n",
      "05/08/2025 18:37:56 - WARNING - fvcore.common.checkpoint -   Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n",
      "05/08/2025 18:37:56 - INFO - detectron2.data.datasets.coco -   Loaded 21 images in COCO format from /home/fahadabul/mask_rcnn_skyhub/test/test.json\n",
      "Running SAHI slicing inference:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:   5%|▍         | 1/21 [02:35<51:39, 154.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  10%|▉         | 2/21 [05:29<52:39, 166.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  14%|█▍        | 3/21 [08:25<51:14, 170.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  19%|█▉        | 4/21 [11:14<48:12, 170.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  24%|██▍       | 5/21 [14:18<46:42, 175.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  29%|██▊       | 6/21 [17:28<45:02, 180.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  33%|███▎      | 7/21 [20:23<41:37, 178.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  38%|███▊      | 8/21 [23:25<38:54, 179.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  43%|████▎     | 9/21 [26:24<35:52, 179.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  48%|████▊     | 10/21 [29:33<33:27, 182.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  52%|█████▏    | 11/21 [32:11<29:07, 174.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  57%|█████▋    | 12/21 [34:43<25:12, 168.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 108 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  62%|██████▏   | 13/21 [38:13<24:06, 180.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 108 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  67%|██████▋   | 14/21 [41:40<21:59, 188.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 108 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  71%|███████▏  | 15/21 [45:15<19:40, 196.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 108 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  76%|███████▌  | 16/21 [48:46<16:44, 200.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 60 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  81%|████████  | 17/21 [50:44<11:43, 175.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 60 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  86%|████████▌ | 18/21 [52:42<07:55, 158.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 60 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  90%|█████████ | 19/21 [54:37<04:51, 145.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference:  95%|█████████▌| 20/21 [57:12<02:28, 148.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 80 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running SAHI slicing inference: 100%|██████████| 21/21 [59:50<00:00, 170.96s/it]\n",
      "05/08/2025 19:37:46 - WARNING - detectron2.evaluation.coco_evaluation -   [COCOEvaluator] Did not receive valid predictions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved SAHI predictions to /home/fahadabul/mask_rcnn_skyhub/test/model_eval/sahi_coco_predictions.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.model_zoo import get_config_file\n",
    "\n",
    "from sahi.models.detectron2 import Detectron2DetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "\n",
    "# --- PATHS ---\n",
    "INPUT_DIR = \"/home/fahadabul/mask_rcnn_skyhub/test/final\"\n",
    "MODEL_PATH_WRINKLE = \"/home/fahadabul/mask_rcnn_skyhub/latest_image_mask_rcnn_wrinkle/best_model_wrinkle.pth\"\n",
    "OUTPUT_DIR = \"/home/fahadabul/mask_rcnn_skyhub/test/model_eval\"\n",
    "COCO_GT_JSON = \"/home/fahadabul/mask_rcnn_skyhub/test/test.json\"\n",
    "DATASET_NAME = \"wrinkle_eval\"\n",
    "\n",
    "# --- REGISTER DATASET ---\n",
    "if \"torn_wrinkle_dataset\" not in MetadataCatalog.list():\n",
    "    MetadataCatalog.get(\"torn_wrinkle_dataset\").set(thing_classes=[\"torn\", \"wrinkle\"])\n",
    "metadata = MetadataCatalog.get(\"torn_wrinkle_dataset\")\n",
    "\n",
    "# --- LOAD MODEL FUNCTION ---\n",
    "def load_model(model_path, class_names):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(class_names)\n",
    "    cfg.MODEL.WEIGHTS = model_path\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
    "    cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "# --- LOAD MODEL ---\n",
    "predictor_wrinkle = load_model(MODEL_PATH_WRINKLE, [\"wrinkle\"])\n",
    "\n",
    "# --- REGISTER DATASET IF NOT ALREADY ---\n",
    "if DATASET_NAME not in DatasetCatalog.list():\n",
    "    register_coco_instances(DATASET_NAME, {}, COCO_GT_JSON, INPUT_DIR)\n",
    "\n",
    "# --- WRAP WITH SAHI ---\n",
    "sahi_model = Detectron2DetectionModel(\n",
    "    model_path=MODEL_PATH_WRINKLE,  # your .pth path\n",
    "    config_path=get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"),  # config file path\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    confidence_threshold=0.3,\n",
    ")\n",
    "\n",
    "# --- PERFORM SAHI INFERENCE ON ALL TEST IMAGES ---\n",
    "coco_predictions = []\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(DATASET_NAME)\n",
    "\n",
    "for data in tqdm(dataset_dicts, desc=\"Running SAHI slicing inference\"):\n",
    "    image_path = data[\"file_name\"]\n",
    "    image_id = data[\"image_id\"]\n",
    "\n",
    "    result = get_sliced_prediction(\n",
    "        image=image_path,\n",
    "        detection_model=sahi_model,\n",
    "        slice_height=512,\n",
    "        slice_width=512,\n",
    "        overlap_height_ratio=0.2,\n",
    "        overlap_width_ratio=0.2,\n",
    "    )\n",
    "\n",
    "    for pred in result.object_prediction_list:\n",
    "        bbox = pred.bbox.to_xywh()\n",
    "        coco_predictions.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": pred.category.id,\n",
    "            \"bbox\": [bbox.minx, bbox.miny, bbox.width, bbox.height],\n",
    "            \"score\": pred.score.value,\n",
    "        })\n",
    "\n",
    "# --- SAVE PREDICTIONS ---\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "predictions_path = os.path.join(OUTPUT_DIR, \"sahi_coco_predictions.json\")\n",
    "with open(predictions_path, \"w\") as f:\n",
    "    json.dump(coco_predictions, f)\n",
    "\n",
    "print(f\"\\n✅ Saved SAHI predictions to {predictions_path}\")\n",
    "\n",
    "# --- EVALUATE USING COCOEvaluator ---\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "evaluator = COCOEvaluator(DATASET_NAME, output_dir=OUTPUT_DIR)\n",
    "\n",
    "# To load external predictions, use evaluator.load_json_results\n",
    "# Normally detectron2 expects model inference inside inference_on_dataset()\n",
    "# Since we already have predictions, we trick it using the evaluator directly\n",
    "\n",
    "evaluator._predictions = coco_predictions\n",
    "results = evaluator.evaluate()\n",
    "\n",
    "# --- PRINT RESULTS ---\n",
    "def print_coco_metrics(results, label=\"\"):\n",
    "    for key in [\"bbox\", \"segm\"]:\n",
    "        if key in results:\n",
    "            print(f\"\\n{label} {key.upper()} metrics:\")\n",
    "            print(f\"  mAP (IoU=0.50:0.95): {results[key].get('AP', 'N/A'):.3f}\")\n",
    "            print(f\"  mAP50 (IoU=0.50):    {results[key].get('AP50', 'N/A'):.3f}\")\n",
    "            print(f\"  mAP75 (IoU=0.75):    {results[key].get('AP75', 'N/A'):.3f}\")\n",
    "            print(f\"  AP_small:            {results[key].get('APs', 'N/A')}\")\n",
    "            print(f\"  AP_medium:           {results[key].get('APm', 'N/A')}\")\n",
    "            print(f\"  AP_large:            {results[key].get('APl', 'N/A')}\")\n",
    "\n",
    "print_coco_metrics(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df1f0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47978b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0dd213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7860d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33353406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13761b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO  # YOLOv8\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.model_zoo import get_config_file\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import Instances\n",
    "# Paths\n",
    "INPUT_DIR = \"/home/amruta/Downloads/sky/training_data/set2_input\"\n",
    "OUTPUT_DIR = \"/home/amruta/Downloads/sky/training_data/output_set2_v3_model/\"\n",
    "MODEL_PATH_WRINKLE = \"/home/amruta/Downloads/sky/models/v3_maskrcnn/output/model_final.pth\"\n",
    "\n",
    "# Register metadata\n",
    "if \"torn_wrinkle_dataset\" not in MetadataCatalog.list():\n",
    "    MetadataCatalog.get(\"torn_wrinkle_dataset\").set(thing_classes=[\"torn\", \"wrinkle\"])\n",
    "metadata = MetadataCatalog.get(\"torn_wrinkle_dataset\")\n",
    "\n",
    "\n",
    "\n",
    "# Load Mask R-CNN model\n",
    "def load_model(model_path, class_names):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(class_names)\n",
    "    cfg.MODEL.WEIGHTS = model_path\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
    "    cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "predictor_wrinkle = load_model(MODEL_PATH_WRINKLE, [\"wrinkle\"])\n",
    "\n",
    "def relabel_instances(instances, class_offset):\n",
    "    if len(instances) > 0:\n",
    "        instances.pred_classes += class_offset\n",
    "    return instances\n",
    "\n",
    "def offset_instances(instances, offset_x, offset_y, full_image_shape):\n",
    "    instances = instances.to(\"cpu\")\n",
    "    instances.pred_boxes.tensor += torch.tensor([offset_x, offset_y, offset_x, offset_y])\n",
    "    masks = instances.pred_masks.numpy()\n",
    "    h, w = masks.shape[1:]\n",
    "    padded_masks = np.zeros((len(masks), full_image_shape[0], full_image_shape[1]), dtype=np.uint8)\n",
    "    for i, mask in enumerate(masks):\n",
    "        padded_masks[i, offset_y:offset_y+h, offset_x:offset_x+w] = mask\n",
    "    instances.pred_masks = torch.from_numpy(padded_masks)\n",
    "\n",
    "    # ✅ Set full image size\n",
    "    instances._image_size = full_image_shape[:2]\n",
    "    return instances\n",
    "\n",
    "\n",
    "\n",
    "def process_segmented_images(segmented_dir, output_dir_segmented):\n",
    "    for root, _, files in os.walk(segmented_dir):\n",
    "        for file in files:\n",
    "            if not file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                continue\n",
    "\n",
    "            image_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(root, segmented_dir)\n",
    "            save_dir = os.path.join(output_dir_segmented, relative_path)\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            output_path = os.path.join(save_dir, file)\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Skipping {image_path}: Unable to read image.\")\n",
    "                continue\n",
    "\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            wrinkle_outputs = predictor_wrinkle(image)\n",
    "            # outputs = predictor(image)\n",
    "            all_instances = []\n",
    "\n",
    "            # Wrinkle class (1)\n",
    "            offset_wrinkle = offset_instances(wrinkle_outputs[\"instances\"], 0, 0, image.shape[:2])\n",
    "            offset_wrinkle = relabel_instances(offset_wrinkle, 1)\n",
    "\n",
    "            if len(offset_wrinkle) > 0:\n",
    "                all_instances.append(offset_wrinkle)\n",
    "\n",
    "            if all_instances:\n",
    "                combined_instances = Instances.cat(all_instances)\n",
    "                v = Visualizer(image[:, :, ::-1], metadata=metadata, scale=1.0)\n",
    "                output_image = v.draw_instance_predictions(combined_instances).get_image()[:, :, ::-1]\n",
    "            else:\n",
    "                output_image = image\n",
    "\n",
    "process_segmented_images(INPUT_DIR, OUTPUT_DIR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2e13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a8c20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b999294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91005d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
